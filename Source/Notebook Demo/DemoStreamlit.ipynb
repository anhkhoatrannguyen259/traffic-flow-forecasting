{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40655,"status":"ok","timestamp":1659182903274,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"},"user_tz":-420},"id":"yrr9nqTkVUX1","outputId":"814ad797-adde-401d-b8c5-563e4a1da2c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Dependencies"],"metadata":{"id":"N1hE2Vr2gTlI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2SpdjEaQtvL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1659182958881,"user_tz":-420,"elapsed":51279,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"495e9705-79f3-4bca-fb6d-c7fa2aa8fec7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting streamlit\n","  Downloading streamlit-1.11.1-py2.py3-none-any.whl (9.1 MB)\n","\u001b[K     |████████████████████████████████| 9.1 MB 33.1 MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n","Collecting pympler>=0.9\n","  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.6)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 50.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n","Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n","Requirement already satisfied: attrs>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.4.0)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.1)\n","Collecting watchdog\n","  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 6.4 MB/s \n","\u001b[?25hCollecting blinker>=1.0.0\n","  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n","Collecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 75.2 MB/s \n","\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.13.0)\n","Collecting validators>=0.2\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n","Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.12.0)\n","Collecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n","Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Collecting rich>=10.11.0\n","  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 56.4 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.12.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit) (3.8.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.1->streamlit) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2022.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.12->streamlit) (1.15.0)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.7.1)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.1)\n","Collecting ipykernel>=5.1.2\n","  Downloading ipykernel-6.15.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 74.0 MB/s \n","\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (23.2.0)\n","Collecting jupyter-client>=6.1.12\n","  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 69.2 MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.4.8)\n","Collecting ipython>=7.23.1\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 73.7 MB/s \n","\u001b[?25hCollecting tornado>=5.0\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 69.5 MB/s \n","\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.5.5)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.1)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.30-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 56.7 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.6.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.1.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.11.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (1.24.3)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.4.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.16.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=bcea3d4e4e3cea5eab7a137161aedb56a8a948b23b0af919bf2952f3225b147e\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel, smmap, gitdb, commonmark, watchdog, validators, toml, rich, pympler, pydeck, gitpython, blinker, streamlit\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 5.3.5\n","    Uninstalling jupyter-client-5.3.5:\n","      Successfully uninstalled jupyter-client-5.3.5\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","nbclient 0.6.6 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.30 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n","Successfully installed blinker-1.5 commonmark-0.9.1 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.15.1 ipython-7.34.0 jupyter-client-7.3.4 prompt-toolkit-3.0.30 pydeck-0.7.1 pympler-1.0.1 rich-12.5.1 smmap-5.0.0 streamlit-1.11.1 toml-0.10.2 tornado-6.2 validators-0.20.0 watchdog-2.1.9\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit","tornado"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 34.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=419525aefa0a73851bf7e584427f66bf9e6f9603efa1782af2f9a9891e99d35a\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting leafmap\n","  Downloading leafmap-0.10.3-py2.py3-none-any.whl (161 kB)\n","\u001b[K     |████████████████████████████████| 161 kB 36.6 MB/s \n","\u001b[?25hCollecting geojson\n","  Downloading geojson-2.5.0-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from leafmap) (4.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from leafmap) (3.2.2)\n","Collecting colour\n","  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n","Collecting ipyfilechooser>=0.6.0\n","  Downloading ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from leafmap) (1.21.6)\n","Collecting ipyevents\n","  Downloading ipyevents-2.0.1-py2.py3-none-any.whl (130 kB)\n","\u001b[K     |████████████████████████████████| 130 kB 40.8 MB/s \n","\u001b[?25hCollecting jupyterlab>=3.0.0\n","  Downloading jupyterlab-3.4.4-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from leafmap) (1.3.5)\n","Collecting ipysheet\n","  Downloading ipysheet-0.5.0-py2.py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 61.9 MB/s \n","\u001b[?25hCollecting xyzservices\n","  Downloading xyzservices-2022.6.0-py3-none-any.whl (36 kB)\n","Collecting scooby\n","  Downloading scooby-0.6.0-py3-none-any.whl (14 kB)\n","Collecting pycrs\n","  Downloading PyCRS-1.0.2.tar.gz (36 kB)\n","Collecting bqplot\n","  Downloading bqplot-0.12.33-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 51.4 MB/s \n","\u001b[?25hCollecting ipyleaflet>=0.17.0\n","  Downloading ipyleaflet-0.17.0-py2.py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 38.7 MB/s \n","\u001b[?25hCollecting pystac-client\n","  Downloading pystac_client-0.4.0-py3-none-any.whl (24 kB)\n","Collecting whiteboxgui>=0.6.0\n","  Downloading whiteboxgui-0.7.0-py2.py3-none-any.whl (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 7.9 MB/s \n","\u001b[?25hCollecting folium>=0.11.0\n","  Downloading folium-0.12.1.post1-py2.py3-none-any.whl (95 kB)\n","\u001b[K     |████████████████████████████████| 95 kB 4.3 MB/s \n","\u001b[?25hCollecting pyshp>=2.1.3\n","  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 2.9 MB/s \n","\u001b[?25hCollecting python-box\n","  Downloading python_box-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 35.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->leafmap) (2.23.0)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->leafmap) (0.5.0)\n","Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from folium>=0.11.0->leafmap) (2.11.3)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from ipyfilechooser>=0.6.0->leafmap) (7.7.1)\n","Collecting traittypes<3,>=0.2.1\n","  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (7.34.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (6.15.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (1.1.1)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (5.1.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (3.6.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.2.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (1.5.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (21.3)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (6.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (5.4.8)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (1.0.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (7.3.4)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (23.2.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (57.4.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (3.0.30)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (4.4.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.18.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (2.6.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (4.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->folium>=0.11.0->leafmap) (2.0.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (2.8.2)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (4.11.1)\n","Collecting jupyter-server~=1.16\n","  Downloading jupyter_server-1.18.1-py3-none-any.whl (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 58.4 MB/s \n","\u001b[?25hCollecting nbclassic\n","  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab>=3.0.0->leafmap) (5.3.1)\n","Collecting jupyterlab-server~=2.10\n","  Downloading jupyterlab_server-2.15.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (1.8.0)\n","Collecting nbconvert>=6.4.4\n","  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n","\u001b[K     |████████████████████████████████| 561 kB 71.0 MB/s \n","\u001b[?25hRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (21.3.0)\n","Collecting anyio<4,>=3.1.0\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (5.4.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.14.1)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.13.3)\n","Collecting websocket-client\n","  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (2.10)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (4.1.1)\n","Collecting json5\n","  Downloading json5-0.9.8.tar.gz (22 kB)\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (4.3.3)\n","Collecting jinja2>=2.9\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 69.8 MB/s \n","\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (2.10.3)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (3.8.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (21.4.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (0.18.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (5.0.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.2.2)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (1.1.1)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.6.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (4.6.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.7.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (1.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.8.4)\n","Collecting traitlets>=4.3.1\n","  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (2.16.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (0.2.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->leafmap) (1.15.0)\n","Collecting whitebox\n","  Downloading whitebox-2.1.4-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s \n","\u001b[?25hCollecting ipytree\n","  Downloading ipytree-0.2.1-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 60.0 MB/s \n","\u001b[?25hRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (21.2.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (2.21)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.10->jupyterlab>=3.0.0->leafmap) (2022.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab>=3.0.0->leafmap) (0.5.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown->leafmap) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->leafmap) (3.7.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->leafmap) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->leafmap) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->leafmap) (0.11.0)\n","Collecting notebook-shim>=0.1.0\n","  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 904 kB/s \n","\u001b[?25hCollecting pystac>=1.4.0\n","  Downloading pystac-1.5.0-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 74.7 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->leafmap) (2.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->leafmap) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->leafmap) (2022.6.15)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->folium>=0.11.0->leafmap) (1.7.1)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from whitebox->whiteboxgui>=0.6.0->leafmap) (7.1.2)\n","Building wheels for collected packages: json5, pycrs\n","  Building wheel for json5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for json5: filename=json5-0.9.8-py2.py3-none-any.whl size=18604 sha256=1f14f8e37c9cb7153032760817688c6b78681a2bb1e1fecd401a9fc47dd503c1\n","  Stored in directory: /root/.cache/pip/wheels/ac/9b/de/6e4fd8f159d3dfa42c42ceddf2184fda29ea7fb1e8f5f8371c\n","  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycrs: filename=PyCRS-1.0.2-py3-none-any.whl size=32704 sha256=e03ac48db5a0439aa0c72d07609122311db11af05d05d831f3d0838fa07444e9\n","  Stored in directory: /root/.cache/pip/wheels/3e/ce/32/1ec0aba6b9770681a423e82f0274c57d09ad2c20c2864901f9\n","Successfully built json5 pycrs\n","Installing collected packages: traitlets, jinja2, sniffio, nbconvert, websocket-client, anyio, jupyter-server, requests, notebook-shim, json5, xyzservices, whitebox, traittypes, pystac, nbclassic, jupyterlab-server, ipytree, ipyfilechooser, whiteboxgui, scooby, python-box, pystac-client, pyshp, pycrs, jupyterlab, ipysheet, ipyleaflet, ipyevents, geojson, folium, colour, bqplot, leafmap\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.1.1\n","    Uninstalling traitlets-5.1.1:\n","      Successfully uninstalled traitlets-5.1.1\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: nbconvert\n","    Found existing installation: nbconvert 5.6.1\n","    Uninstalling nbconvert-5.6.1:\n","      Successfully uninstalled nbconvert-5.6.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: folium\n","    Found existing installation: folium 0.8.3\n","    Uninstalling folium-0.8.3:\n","      Successfully uninstalled folium-0.8.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n","flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.12.1.post1 which is incompatible.\u001b[0m\n","Successfully installed anyio-3.6.1 bqplot-0.12.33 colour-0.1.5 folium-0.12.1.post1 geojson-2.5.0 ipyevents-2.0.1 ipyfilechooser-0.6.0 ipyleaflet-0.17.0 ipysheet-0.5.0 ipytree-0.2.1 jinja2-3.1.2 json5-0.9.8 jupyter-server-1.18.1 jupyterlab-3.4.4 jupyterlab-server-2.15.0 leafmap-0.10.3 nbclassic-0.4.3 nbconvert-6.5.0 notebook-shim-0.1.0 pycrs-1.0.2 pyshp-2.3.1 pystac-1.5.0 pystac-client-0.4.0 python-box-6.0.2 requests-2.28.1 scooby-0.6.0 sniffio-1.2.0 traitlets-5.3.0 traittypes-0.2.1 websocket-client-1.3.3 whitebox-2.1.4 whiteboxgui-0.7.0 xyzservices-2022.6.0\n"]}],"source":["!pip install streamlit\n","!pip install pyngrok\n","!pip install leafmap"]},{"cell_type":"code","source":["# Install latest pre-release version of bigdl-chronos \n","# Installing bigdl-chronos from pip will automatically install pyspark, bigdl, and their dependencies.\n","# !pip install --pre --upgrade bigdl-chronos[all]\n","!pip install bigdl-chronos[all]==2.0.0\n","!pip uninstall -y torchtext # uninstall torchtext to avoid version conflict\n","!pip install torchmetrics==0.7.3\n","exit() # restart the runtime to refresh installed pkg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7J1yoxr1gjmu","executionInfo":{"status":"ok","timestamp":1659183196922,"user_tz":-420,"elapsed":233309,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"ad9c2384-d841-4926-9b69-2ee530c3e1c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bigdl-chronos[all]==2.0.0\n","  Downloading bigdl_chronos-2.0.0-py3-none-manylinux1_x86_64.whl (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 30.0 MB/s \n","\u001b[?25hCollecting bigdl-nano[pytorch]\n","  Downloading bigdl_nano-2.0.0-py3-none-manylinux2010_x86_64.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 22.3 MB/s \n","\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from bigdl-chronos[all]==2.0.0) (0.10.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bigdl-chronos[all]==2.0.0) (1.0.2)\n","Collecting bigdl-orca==2.0.0\n","  Downloading bigdl_orca-2.0.0-py3-none-manylinux1_x86_64.whl (23.9 MB)\n","\u001b[K     |████████████████████████████████| 23.9 MB 1.6 MB/s \n","\u001b[?25hCollecting pandas<1.3.0,>=1.0.5\n","  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 59.5 MB/s \n","\u001b[?25hCollecting bigdl-tf==2.0.0\n","  Downloading bigdl_tf-2.0.0-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n","\u001b[K     |████████████████████████████████| 71.0 MB 124 kB/s \n","\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (23.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.7.1)\n","Collecting bigdl-math==2.0.0\n","  Downloading bigdl_math-2.0.0-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n","\u001b[K     |████████████████████████████████| 35.4 MB 393 kB/s \n","\u001b[?25hCollecting conda-pack==0.3.1\n","  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n","Collecting bigdl-dllib==2.0.0\n","  Downloading bigdl_dllib-2.0.0-py3-none-manylinux1_x86_64.whl (101.0 MB)\n","\u001b[K     |████████████████████████████████| 101.0 MB 37 kB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (21.3)\n","Collecting pyspark==2.4.6\n","  Downloading pyspark-2.4.6.tar.gz (218.4 MB)\n","\u001b[K     |████████████████████████████████| 218.4 MB 49 kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.0.0->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.0.0->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.21.6)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting async-timeout==4.0.1\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (5.4.8)\n","Collecting ray[tune]==1.9.2\n","  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n","\u001b[K     |████████████████████████████████| 57.6 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.8.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (2.8.0)\n","Collecting aioredis==1.3.1\n","  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s \n","\u001b[?25hCollecting hiredis==2.0.0\n","  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (2.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (4.1.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.7.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (21.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (57.4.0)\n","Collecting py4j==0.10.7\n","  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n","\u001b[K     |████████████████████████████████| 197 kB 67.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.13)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.47.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.0.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (7.1.2)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.17.3)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n","\u001b[K     |████████████████████████████████| 246 kB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (4.3.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (2.28.1)\n","Collecting py-spy>=0.2.0\n","  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 18.7 MB/s \n","\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.14.1)\n","Collecting aiohttp-cors\n","  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Collecting gpustat>=1.0.0b1\n","  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 8.2 MB/s \n","\u001b[?25hCollecting opencensus\n","  Downloading opencensus-0.10.0-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 69.0 MB/s \n","\u001b[?25hCollecting colorful\n","  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n","\u001b[K     |████████████████████████████████| 201 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (5.2.1)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.8.10)\n","Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n","  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n","Collecting psutil\n","  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[K     |████████████████████████████████| 281 kB 75.5 MB/s \n","\u001b[?25hCollecting blessed>=1.17.1\n","  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.2.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0,>=1.0.5->bigdl-chronos[all]==2.0.0) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0,>=1.0.5->bigdl-chronos[all]==2.0.0) (2.8.2)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (4.12.0)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n","\u001b[K     |████████████████████████████████| 244 kB 72.9 MB/s \n","\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n","\u001b[K     |████████████████████████████████| 244 kB 76.3 MB/s \n","\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 73.6 MB/s \n","\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 74.2 MB/s \n","\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 78.9 MB/s \n","\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 79.9 MB/s \n","\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 73.9 MB/s \n","\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 70.1 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.14.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.0.9)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (2.10)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (2022.1.0)\n","Collecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.5 MB/s \n","\u001b[?25hCollecting onnx\n","  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 47.5 MB/s \n","\u001b[?25hCollecting PyTurboJPEG\n","  Downloading PyTurboJPEG-1.6.7.tar.gz (11 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.12.0-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 52.0 MB/s \n","\u001b[?25hCollecting pytorch-lightning==1.4.2\n","  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n","\u001b[K     |████████████████████████████████| 916 kB 63.0 MB/s \n","\u001b[?25hCollecting opencv-transforms\n","  Downloading opencv_transforms-0.0.6-py3-none-any.whl (18 kB)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n","\u001b[K     |████████████████████████████████| 48.3 MB 89 kB/s \n","\u001b[?25hCollecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.5 kB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 67.3 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 71.2 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.2->bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (4.64.0)\n","Collecting torchmetrics>=0.4.0\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 58.8 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0->bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (7.1.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.2.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.4.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (2022.6.15)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (3.2.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (0.18.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime->bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (2.0)\n","Collecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime->bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (1.7.1)\n","Collecting humanfriendly>=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.0 MB/s \n","\u001b[?25hCollecting opencensus-context>=0.1.2\n","  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.31.6)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[tune]==1.9.2->bigdl-orca==2.0.0->bigdl-chronos[all]==2.0.0) (1.56.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bigdl-chronos[all]==2.0.0) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bigdl-chronos[all]==2.0.0) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bigdl-chronos[all]==2.0.0) (1.1.0)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->bigdl-chronos[all]==2.0.0) (0.5.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime->bigdl-nano[pytorch]->bigdl-chronos[all]==2.0.0) (1.2.1)\n","Building wheels for collected packages: pyspark, gpustat, future, PyTurboJPEG\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814407 sha256=8c89c0f8c689e2ff88f2e9bb6b552c536efe6d2e42f6b423c2a6f37f74e6b37a\n","  Stored in directory: /root/.cache/pip/wheels/f1/42/b0/ba397759613f4feb1611021a2503e60e344e546671b2ae04f8\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=c769123d58e415b0d94bdd841fe2557163ed23a9f42f7ae5b344fabceb232fdc\n","  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=8714e930c39be0dd55bc2f156a897446e0081ba0a131a363176e49e68e0b9b78\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.6.7-py3-none-any.whl size=12168 sha256=d092b3b462c24caf35860313b276c4c1964838bb675b2e45d6f0889206b5541c\n","  Stored in directory: /root/.cache/pip/wheels/71/d6/9a/cce1808661c049dc4b55b3f41001198dd0efd979cb43833f89\n","Successfully built pyspark gpustat future PyTurboJPEG\n","Installing collected packages: async-timeout, torch, py4j, humanfriendly, fsspec, deprecated, torchmetrics, redis, pyyaml, pyspark, pyDeprecate, psutil, opencensus-context, nvidia-ml-py, hiredis, future, coloredlogs, blessed, torchvision, tensorboardX, ray, PyTurboJPEG, pytorch-lightning, py-spy, pandas, opencv-transforms, opencv-python-headless, opencensus, onnxruntime, onnx, gpustat, conda-pack, colorful, bigdl-tf, bigdl-nano, bigdl-math, bigdl-dllib, aioredis, aiohttp-cors, setproctitle, bigdl-orca, bigdl-chronos\n","  Attempting uninstall: async-timeout\n","    Found existing installation: async-timeout 4.0.2\n","    Uninstalling async-timeout-4.0.2:\n","      Successfully uninstalled async-timeout-4.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.0+cu113\n","    Uninstalling torchvision-0.13.0+cu113:\n","      Successfully uninstalled torchvision-0.13.0+cu113\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n","Successfully installed PyTurboJPEG-1.6.7 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-4.0.1 bigdl-chronos-2.0.0 bigdl-dllib-2.0.0 bigdl-math-2.0.0 bigdl-nano-2.0.0 bigdl-orca-2.0.0 bigdl-tf-2.0.0 blessed-1.19.1 coloredlogs-15.0.1 colorful-0.5.4 conda-pack-0.3.1 deprecated-1.2.13 fsspec-2022.7.1 future-0.18.2 gpustat-1.0.0rc1 hiredis-2.0.0 humanfriendly-10.0 nvidia-ml-py-11.495.46 onnx-1.12.0 onnxruntime-1.12.0 opencensus-0.10.0 opencensus-context-0.1.2 opencv-python-headless-4.6.0.66 opencv-transforms-0.0.6 pandas-1.2.5 psutil-5.9.1 py-spy-0.3.12 py4j-0.10.7 pyDeprecate-0.3.1 pyspark-2.4.6 pytorch-lightning-1.4.2 pyyaml-6.0 ray-1.9.2 redis-4.1.4 setproctitle-1.3.0 tensorboardX-2.5.1 torch-1.9.0 torchmetrics-0.9.3 torchvision-0.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found existing installation: torchtext 0.13.0\n","Uninstalling torchtext-0.13.0:\n","  Successfully uninstalled torchtext-0.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics==0.7.3\n","  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n","\u001b[K     |████████████████████████████████| 398 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (1.9.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (21.3)\n","Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (0.3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics==0.7.3) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics==0.7.3) (3.0.9)\n","Installing collected packages: torchmetrics\n","  Attempting uninstall: torchmetrics\n","    Found existing installation: torchmetrics 0.9.3\n","    Uninstalling torchmetrics-0.9.3:\n","      Successfully uninstalled torchmetrics-0.9.3\n","Successfully installed torchmetrics-0.7.3\n"]}]},{"cell_type":"code","source":["%%writefile /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\n","# Copyright The PyTorch Lightning team.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"Trainer to automate the training.\"\"\"\n","import logging\n","import os\n","import traceback\n","import warnings\n","from datetime import timedelta\n","from pathlib import Path\n","from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n","from weakref import proxy\n","\n","import torch\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.accelerators import Accelerator, IPUAccelerator\n","from pytorch_lightning.callbacks import Callback\n","from pytorch_lightning.core.datamodule import LightningDataModule\n","from pytorch_lightning.core.memory import ModelSummary\n","from pytorch_lightning.loggers import LightningLoggerBase\n","from pytorch_lightning.loops import TrainingBatchLoop, TrainingEpochLoop\n","from pytorch_lightning.loops.dataloader.evaluation_loop import EvaluationLoop\n","from pytorch_lightning.loops.dataloader.prediction_loop import PredictionLoop\n","from pytorch_lightning.loops.fit_loop import FitLoop\n","from pytorch_lightning.plugins import Plugin\n","from pytorch_lightning.plugins.environments import ClusterEnvironment\n","from pytorch_lightning.profiler import (\n","    AdvancedProfiler,\n","    BaseProfiler,\n","    PassThroughProfiler,\n","    PyTorchProfiler,\n","    SimpleProfiler,\n","    XLAProfiler,\n",")\n","from pytorch_lightning.trainer.callback_hook import TrainerCallbackHookMixin\n","from pytorch_lightning.trainer.configuration_validator import ConfigValidator\n","from pytorch_lightning.trainer.connectors.accelerator_connector import AcceleratorConnector\n","from pytorch_lightning.trainer.connectors.callback_connector import CallbackConnector\n","from pytorch_lightning.trainer.connectors.checkpoint_connector import CheckpointConnector\n","from pytorch_lightning.trainer.connectors.data_connector import DataConnector\n","from pytorch_lightning.trainer.connectors.debugging_connector import DebuggingConnector\n","from pytorch_lightning.trainer.connectors.env_vars_connector import _defaults_from_env_vars\n","from pytorch_lightning.trainer.connectors.logger_connector import LoggerConnector\n","from pytorch_lightning.trainer.connectors.model_connector import ModelConnector\n","from pytorch_lightning.trainer.connectors.optimizer_connector import OptimizerConnector\n","from pytorch_lightning.trainer.connectors.slurm_connector import SLURMConnector\n","from pytorch_lightning.trainer.connectors.training_trick_connector import TrainingTricksConnector\n","from pytorch_lightning.trainer.data_loading import TrainerDataLoadingMixin\n","from pytorch_lightning.trainer.deprecated_api import DeprecatedTrainerAttributes\n","from pytorch_lightning.trainer.logging import TrainerLoggingMixin\n","from pytorch_lightning.trainer.model_hooks import TrainerModelHooksMixin\n","from pytorch_lightning.trainer.optimizers import TrainerOptimizersMixin\n","from pytorch_lightning.trainer.properties import TrainerProperties\n","from pytorch_lightning.trainer.states import TrainerFn, TrainerState, TrainerStatus\n","from pytorch_lightning.trainer.training_tricks import TrainerTrainingTricksMixin\n","from pytorch_lightning.tuner.auto_gpu_select import pick_multiple_gpus\n","from pytorch_lightning.tuner.lr_finder import _LRFinder\n","from pytorch_lightning.tuner.tuning import Tuner\n","from pytorch_lightning.utilities import (\n","    _IPU_AVAILABLE,\n","    _TPU_AVAILABLE,\n","    device_parser,\n","    DeviceType,\n","    parsing,\n","    rank_zero_deprecation,\n","    rank_zero_info,\n","    rank_zero_warn,\n",")\n","from pytorch_lightning.utilities.debugging import InternalDebugger\n","from pytorch_lightning.utilities.distributed import distributed_available\n","from pytorch_lightning.utilities.exceptions import MisconfigurationException\n","from pytorch_lightning.utilities.imports import _fault_tolerant_enabled\n","from pytorch_lightning.utilities.model_helpers import is_overridden\n","from pytorch_lightning.utilities.seed import reset_seed\n","from pytorch_lightning.utilities.types import _EVALUATE_OUTPUT, _PREDICT_OUTPUT, EVAL_DATALOADERS, TRAIN_DATALOADERS\n","\n","log = logging.getLogger(__name__)\n","# warnings to ignore in trainer\n","warnings.filterwarnings(\n","    \"ignore\", message=\"torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\"\n",")\n","\n","\n","class Trainer(\n","    TrainerProperties,\n","    TrainerCallbackHookMixin,\n","    TrainerModelHooksMixin,\n","    TrainerOptimizersMixin,\n","    TrainerLoggingMixin,\n","    TrainerTrainingTricksMixin,\n","    TrainerDataLoadingMixin,\n","    DeprecatedTrainerAttributes,\n","):\n","    @_defaults_from_env_vars\n","    def __init__(\n","        self,\n","        logger: Union[LightningLoggerBase, Iterable[LightningLoggerBase], bool] = True,\n","        checkpoint_callback: bool = True,\n","        callbacks: Optional[Union[List[Callback], Callback]] = None,\n","        default_root_dir: Optional[str] = None,\n","        gradient_clip_val: float = 0.0,\n","        gradient_clip_algorithm: str = \"norm\",\n","        process_position: int = 0,\n","        num_nodes: int = 1,\n","        num_processes: int = 1,\n","        devices: Optional[Union[List[int], str, int]] = None,\n","        gpus: Optional[Union[List[int], str, int]] = 1,\n","        auto_select_gpus: bool = True,\n","        tpu_cores: Optional[Union[List[int], str, int]] = None,\n","        ipus: Optional[int] = None,\n","        log_gpu_memory: Optional[str] = None,\n","        progress_bar_refresh_rate: Optional[int] = None,\n","        overfit_batches: Union[int, float] = 0.0,\n","        track_grad_norm: Union[int, float, str] = -1,\n","        check_val_every_n_epoch: int = 1,\n","        fast_dev_run: Union[int, bool] = False,\n","        accumulate_grad_batches: Union[int, Dict[int, int], List[list]] = 1,\n","        max_epochs: Optional[int] = None,\n","        min_epochs: Optional[int] = None,\n","        max_steps: Optional[int] = None,\n","        min_steps: Optional[int] = None,\n","        max_time: Optional[Union[str, timedelta, Dict[str, int]]] = None,\n","        limit_train_batches: Union[int, float] = 1.0,\n","        limit_val_batches: Union[int, float] = 1.0,\n","        limit_test_batches: Union[int, float] = 1.0,\n","        limit_predict_batches: Union[int, float] = 1.0,\n","        val_check_interval: Union[int, float] = 1.0,\n","        flush_logs_every_n_steps: int = 100,\n","        log_every_n_steps: int = 50,\n","        accelerator: Optional[Union[str, Accelerator]] = None,\n","        sync_batchnorm: bool = False,\n","        precision: int = 32,\n","        weights_summary: Optional[str] = \"top\",\n","        weights_save_path: Optional[str] = None,\n","        num_sanity_val_steps: int = 2,\n","        truncated_bptt_steps: Optional[int] = None,\n","        resume_from_checkpoint: Optional[Union[Path, str]] = None,\n","        profiler: Optional[Union[BaseProfiler, str]] = None,\n","        benchmark: bool = False,\n","        deterministic: bool = False,\n","        reload_dataloaders_every_n_epochs: int = 0,\n","        reload_dataloaders_every_epoch: bool = False,\n","        auto_lr_find: Union[bool, str] = False,\n","        replace_sampler_ddp: bool = True,\n","        terminate_on_nan: bool = False,\n","        auto_scale_batch_size: Union[str, bool] = False,\n","        prepare_data_per_node: bool = True,\n","        plugins: Optional[Union[List[Union[Plugin, ClusterEnvironment, str]], Plugin, ClusterEnvironment, str]] = None,\n","        amp_backend: str = \"native\",\n","        amp_level: str = \"O2\",\n","        distributed_backend: Optional[str] = None,\n","        move_metrics_to_cpu: bool = False,\n","        multiple_trainloader_mode: str = \"max_size_cycle\",\n","        stochastic_weight_avg: bool = False,\n","    ):\n","        r\"\"\"\n","        Customize every aspect of training via flags\n","\n","        Args:\n","\n","            accelerator: Previously known as distributed_backend (dp, ddp, ddp2, etc...).\n","                Can also take in an accelerator object for custom hardware.\n","\n","            accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.\n","\n","            amp_backend: The mixed precision backend to use (\"native\" or \"apex\")\n","\n","            amp_level: The optimization level to use (O1, O2, etc...).\n","\n","            auto_lr_find: If set to True, will make trainer.tune() run a learning rate finder,\n","                trying to optimize initial learning for faster convergence. trainer.tune() method will\n","                set the suggested learning rate in self.lr or self.learning_rate in the LightningModule.\n","                To use a different key set a string instead of True with the key name.\n","\n","            auto_scale_batch_size: If set to True, will `initially` run a batch size\n","                finder trying to find the largest batch size that fits into memory.\n","                The result will be stored in self.batch_size in the LightningModule.\n","                Additionally, can be set to either `power` that estimates the batch size through\n","                a power search or `binsearch` that estimates the batch size through a binary search.\n","\n","            auto_select_gpus: If enabled and `gpus` is an integer, pick available\n","                gpus automatically. This is especially useful when\n","                GPUs are configured to be in \"exclusive mode\", such\n","                that only one process at a time can access them.\n","\n","            benchmark: If true enables cudnn.benchmark.\n","\n","            callbacks: Add a callback or list of callbacks.\n","\n","            checkpoint_callback: If ``True``, enable checkpointing.\n","                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n","                :paramref:`~pytorch_lightning.trainer.trainer.Trainer.callbacks`.\n","\n","            check_val_every_n_epoch: Check val every n train epochs.\n","\n","            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n","                Default: ``os.getcwd()``.\n","                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n","\n","            deterministic: If true enables cudnn.deterministic.\n","\n","            devices: Will be mapped to either `gpus`, `tpu_cores`, `num_processes` or `ipus`,\n","                based on the accelerator type.\n","\n","            distributed_backend: deprecated. Please use 'accelerator'\n","\n","            fast_dev_run: runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n","                of train, val and test to find any bugs (ie: a sort of unit test).\n","\n","            flush_logs_every_n_steps: How often to flush logs to disk (defaults to every 100 steps).\n","\n","            gpus: number of gpus to train on (int) or which GPUs to train on (list or str) applied per node\n","\n","            gradient_clip_val: 0 means don't clip.\n","\n","            gradient_clip_algorithm: 'value' means clip_by_value, 'norm' means clip_by_norm. Default: 'norm'\n","\n","            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches)\n","\n","            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches)\n","\n","            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches)\n","\n","            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches)\n","\n","            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n","                the default ``TensorBoardLogger``. ``False`` will disable logging. If multiple loggers are\n","                provided and the `save_dir` property of that logger is not set, local files (checkpoints,\n","                profiler traces, etc.) are saved in ``default_root_dir`` rather than in the ``log_dir`` of any\n","                of the individual loggers.\n","\n","            log_gpu_memory: None, 'min_max', 'all'. Might slow performance\n","\n","            log_every_n_steps: How often to log within steps (defaults to every 50 steps).\n","\n","            prepare_data_per_node: If True, each LOCAL_RANK=0 will call prepare data.\n","                Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data\n","\n","            process_position: orders the progress bar when running multiple models on same machine.\n","\n","            progress_bar_refresh_rate: How often to refresh progress bar (in steps). Value ``0`` disables progress bar.\n","                Ignored when a custom progress bar is passed to :paramref:`~Trainer.callbacks`. Default: None, means\n","                a suitable value will be chosen based on the environment (terminal, Google COLAB, etc.).\n","\n","            profiler: To profile individual steps during training and assist in identifying bottlenecks.\n","\n","            overfit_batches: Overfit a fraction of training data (float) or a set number of batches (int).\n","\n","            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n","\n","            precision: Double precision (64), full precision (32) or half precision (16). Can be used on CPU, GPU or\n","                TPUs.\n","\n","            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n","                If both max_epochs and max_steps are not specified, defaults to ``max_epochs`` = 1000.\n","\n","            min_epochs: Force training for at least these many epochs. Disabled by default (None).\n","                If both min_epochs and min_steps are not specified, defaults to ``min_epochs`` = 1.\n","\n","            max_steps: Stop training after this number of steps. Disabled by default (None).\n","\n","            min_steps: Force training for at least these number of steps. Disabled by default (None).\n","\n","            max_time: Stop training after this amount of time has passed. Disabled by default (None).\n","                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n","                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n","                :class:`datetime.timedelta`.\n","\n","            num_nodes: number of GPU nodes for distributed training.\n","\n","            num_processes: number of processes for distributed training with distributed_backend=\"ddp_cpu\"\n","\n","            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n","                Set it to `-1` to run all batches in all validation dataloaders.\n","\n","            reload_dataloaders_every_n_epochs: Set to a non-negative integer to reload dataloaders every n epochs.\n","                Default: 0\n","\n","            reload_dataloaders_every_epoch: Set to True to reload dataloaders every epoch.\n","\n","                .. deprecated:: v1.4\n","                    ``reload_dataloaders_every_epoch`` has been deprecated in v1.4 and will be removed in v1.6.\n","                    Please use ``reload_dataloaders_every_n_epochs``.\n","\n","            replace_sampler_ddp: Explicitly enables or disables sampler replacement. If not specified this\n","                will toggled automatically when DDP is used. By default it will add ``shuffle=True`` for\n","                train sampler and ``shuffle=False`` for val/test sampler. If you want to customize it,\n","                you can set ``replace_sampler_ddp=False`` and add your own distributed sampler.\n","\n","            resume_from_checkpoint: Path/URL of the checkpoint from which training is resumed. If there is\n","                no checkpoint file at the path, start from scratch. If resuming from mid-epoch checkpoint,\n","                training will start from the beginning of the next epoch.\n","\n","            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n","\n","            terminate_on_nan: If set to True, will terminate training (by raising a `ValueError`) at the\n","                end of each training batch, if any of the parameters or the loss are NaN or +/-inf.\n","\n","            tpu_cores: How many TPU cores to train on (1 or 8) / Single TPU to train on [1]\n","\n","            ipus: How many IPUs to train on.\n","\n","            track_grad_norm: -1 no tracking. Otherwise tracks that p-norm. May be set to 'inf' infinity-norm.\n","\n","            truncated_bptt_steps: Deprecated in v1.3 to be removed in 1.5.\n","                Please use :paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps` instead.\n","\n","            val_check_interval: How often to check the validation set. Use float to check within a training epoch,\n","                use int to check every n steps (batches).\n","\n","            weights_summary: Prints a summary of the weights when training begins.\n","\n","            weights_save_path: Where to save weights if specified. Will override default_root_dir\n","                for checkpoints only. Use this if for whatever reason you need the checkpoints\n","                stored in a different place than the logs written in `default_root_dir`.\n","                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n","                Defaults to `default_root_dir`.\n","\n","            move_metrics_to_cpu: Whether to force internal logged metrics to be moved to cpu.\n","                This can save some gpu memory, but can make training slower. Use with attention.\n","\n","            multiple_trainloader_mode: How to loop over the datasets when there are multiple train loaders.\n","                In 'max_size_cycle' mode, the trainer ends one epoch when the largest dataset is traversed,\n","                and smaller datasets reload when running out of their data. In 'min_size' mode, all the datasets\n","                reload when reaching the minimum length of datasets.\n","\n","            stochastic_weight_avg: Whether to use `Stochastic Weight Averaging (SWA)\n","                <https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/>_`\n","\n","        \"\"\"\n","        super().__init__()\n","        Trainer._log_api_event(\"init\")\n","        self.state = TrainerState()\n","\n","        gpu_ids, tpu_cores = self._parse_devices(gpus, auto_select_gpus, tpu_cores)\n","\n","        # init connectors\n","        self.dev_debugger = InternalDebugger(self)\n","        self.config_validator = ConfigValidator(self)\n","        self.data_connector = DataConnector(self, multiple_trainloader_mode)\n","        self.optimizer_connector = OptimizerConnector(self)\n","\n","        self.accelerator_connector = AcceleratorConnector(\n","            num_processes,\n","            devices,\n","            tpu_cores,\n","            ipus,\n","            distributed_backend,\n","            accelerator,\n","            gpus,\n","            gpu_ids,\n","            num_nodes,\n","            sync_batchnorm,\n","            benchmark,\n","            replace_sampler_ddp,\n","            deterministic,\n","            precision,\n","            amp_backend,\n","            amp_level,\n","            plugins,\n","        )\n","        self.logger_connector = LoggerConnector(self, log_gpu_memory)\n","        self.model_connector = ModelConnector(self)\n","        self.callback_connector = CallbackConnector(self)\n","        self.debugging_connector = DebuggingConnector(self)\n","        self.training_tricks_connector = TrainingTricksConnector(self)\n","        self.checkpoint_connector = CheckpointConnector(self, resume_from_checkpoint)\n","        self.slurm_connector = SLURMConnector(self)\n","        self.tuner = Tuner(self)\n","\n","        fit_loop = FitLoop(\n","            min_epochs=(1 if (min_epochs is None and min_steps is None) else min_epochs),\n","            max_epochs=(1000 if (max_epochs is None and max_steps is None) else max_epochs),\n","        )\n","        training_epoch_loop = TrainingEpochLoop(min_steps, max_steps)\n","        training_batch_loop = TrainingBatchLoop()\n","        training_validation_loop = EvaluationLoop()\n","        training_epoch_loop.connect(batch_loop=training_batch_loop, val_loop=training_validation_loop)\n","        fit_loop.connect(epoch_loop=training_epoch_loop)\n","\n","        # default .fit() loop\n","        self.fit_loop = fit_loop\n","\n","        # default .validate() loop\n","        self.validate_loop = EvaluationLoop()\n","\n","        # default .test() loop\n","        self.test_loop = EvaluationLoop()\n","\n","        # default .predict() loop\n","        self.predict_loop = PredictionLoop()\n","\n","        # training state\n","        if weights_summary is not None and weights_summary not in ModelSummary.MODES:\n","            raise MisconfigurationException(\n","                f\"`weights_summary` can be None, {', '.join(ModelSummary.MODES)}, but got {weights_summary}\"\n","            )\n","        self.weights_summary = weights_summary\n","        self.shown_warnings = set()\n","\n","        # init callbacks\n","        # Declare attributes to be set in callback_connector on_trainer_init\n","        self.callback_connector.on_trainer_init(\n","            callbacks,\n","            checkpoint_callback,\n","            progress_bar_refresh_rate,\n","            process_position,\n","            default_root_dir,\n","            weights_save_path,\n","            stochastic_weight_avg,\n","            max_time,\n","        )\n","\n","        # hook\n","        self.on_init_start()\n","\n","        # init optimizer + lr scheduler related flags\n","        self.optimizer_connector.on_trainer_init()\n","\n","        # init data flags\n","        self.data_connector.on_trainer_init(\n","            check_val_every_n_epoch,\n","            reload_dataloaders_every_n_epochs,\n","            reload_dataloaders_every_epoch,\n","            prepare_data_per_node,\n","        )\n","\n","        # init training tricks\n","        self.training_tricks_connector.on_trainer_init(\n","            gradient_clip_val,\n","            gradient_clip_algorithm,\n","            track_grad_norm,\n","            accumulate_grad_batches,\n","            truncated_bptt_steps,\n","            terminate_on_nan,\n","        )\n","        self._setup_on_init(num_sanity_val_steps)\n","\n","        # configure tuner\n","        self.tuner.on_trainer_init(auto_lr_find, auto_scale_batch_size)\n","\n","        # configure profiler\n","        self.__init_profiler(profiler)\n","\n","        # init logger flags\n","        self.logger_connector.on_trainer_init(logger, flush_logs_every_n_steps, log_every_n_steps, move_metrics_to_cpu)\n","\n","        # init debugging flags\n","        self.debugging_connector.on_init_start(\n","            limit_train_batches,\n","            limit_val_batches,\n","            limit_test_batches,\n","            limit_predict_batches,\n","            val_check_interval,\n","            overfit_batches,\n","            fast_dev_run,\n","        )\n","\n","        # Callback system\n","        self.on_init_end()\n","\n","    def _setup_on_init(self, num_sanity_val_steps: int) -> None:\n","        self._log_device_info()\n","\n","        self.should_stop = False\n","        self.state = TrainerState()\n","        self.num_training_batches = 0\n","        self.train_dataloader = None\n","\n","        if num_sanity_val_steps == -1:\n","            self.num_sanity_val_steps = float(\"inf\")\n","        else:\n","            self.num_sanity_val_steps = num_sanity_val_steps\n","\n","        self.num_sanity_val_batches = []\n","        self.num_test_batches = []\n","        self.num_val_batches = []\n","        self.test_dataloaders = None\n","        self.val_dataloaders = None\n","\n","        # .validate() and .test() set this when they load a checkpoint\n","        self.validated_ckpt_path = None\n","        self.tested_ckpt_path = None\n","\n","        # when true, print evaluation results in .validate() and .test()\n","        self.verbose_evaluate = True\n","\n","        self.num_predict_batches = []\n","        self.predicted_ckpt_path = None\n","\n","    def fit(\n","        self,\n","        model: \"pl.LightningModule\",\n","        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, LightningDataModule]] = None,\n","        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        train_dataloader=None,  # noqa TODO: remove with 1.6\n","    ) -> None:\n","        r\"\"\"\n","        Runs the full optimization routine.\n","\n","        Args:\n","            model: Model to fit.\n","\n","            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\n","                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.\n","                In the case of multiple dataloaders, please see this :ref:`page <multiple-training-dataloaders>`.\n","\n","            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","        \"\"\"\n","        Trainer._log_api_event(\"fit\")\n","\n","        self.state.fn = TrainerFn.FITTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.training = True\n","\n","        if train_dataloader is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\"\n","            )\n","            train_dataloaders = train_dataloader\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(train_dataloaders, LightningDataModule):\n","            datamodule = train_dataloaders\n","            train_dataloaders = None\n","        # If you supply a datamodule you can't supply train_dataloader or val_dataloaders\n","        if (train_dataloaders is not None or val_dataloaders is not None) and datamodule is not None:\n","            raise MisconfigurationException(\n","                \"You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.fit(datamodule=...)`\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(\n","            model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders, datamodule=datamodule\n","        )\n","\n","        self.checkpoint_connector.resume_start()\n","\n","        self._run(model)\n","\n","        assert self.state.stopped\n","        self.training = False\n","\n","    def validate(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","        verbose: bool = True,\n","        datamodule: Optional[LightningDataModule] = None,\n","        val_dataloaders=None,  # noqa TODO: remove with 1.6\n","    ) -> _EVALUATE_OUTPUT:\n","        r\"\"\"\n","        Perform one evaluation epoch over the validation set.\n","\n","        Args:\n","            model: The model to validate.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying validation samples.\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to validate.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","            verbose: If True, prints the validation results.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","        Returns:\n","            List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks\n","            like :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step`,\n","            :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_epoch_end`, etc.\n","            The length of the list corresponds to the number of validation dataloaders used.\n","        \"\"\"\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"validate\")\n","        self.verbose_evaluate = verbose\n","\n","        self.state.fn = TrainerFn.VALIDATING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.validating = True\n","\n","        if val_dataloaders is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.validate(val_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.validate(dataloaders)` instead.\"\n","            )\n","            dataloaders = val_dataloaders\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        # If you supply a datamodule you can't supply val_dataloaders\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.validate(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.validate()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, val_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.validated_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        # run validate\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.validating = False\n","\n","        return results\n","\n","    def test(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","        verbose: bool = True,\n","        datamodule: Optional[LightningDataModule] = None,\n","        test_dataloaders=None,  # noqa TODO: remove with 1.6\n","    ) -> _EVALUATE_OUTPUT:\n","        r\"\"\"\n","        Perform one evaluation epoch over the test set. It's separated from\n","        fit to make sure you never run on your test set until you want to.\n","\n","        Args:\n","            model: The model to test.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying test samples.\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to test.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","            verbose: If True, prints the test results.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","        Returns:\n","            List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks\n","            like :meth:`~pytorch_lightning.core.lightning.LightningModule.test_step`,\n","            :meth:`~pytorch_lightning.core.lightning.LightningModule.test_epoch_end`, etc.\n","            The length of the list corresponds to the number of test dataloaders used.\n","        \"\"\"\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"test\")\n","        self.verbose_evaluate = verbose\n","\n","        self.state.fn = TrainerFn.TESTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.testing = True\n","\n","        if test_dataloaders is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.test(dataloaders)` instead.\"\n","            )\n","            dataloaders = test_dataloaders\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        # If you supply a datamodule you can't supply test_dataloaders\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.test(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.test()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, test_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.tested_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        # run test\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.testing = False\n","\n","        return results\n","\n","    def predict(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        return_predictions: Optional[bool] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","    ) -> Optional[_PREDICT_OUTPUT]:\n","        r\"\"\"\n","\n","        Separates from fit to make sure you never run on your predictions set until you want to.\n","        This will call the model forward function to compute predictions.\n","\n","        Args:\n","            model: The model to predict with.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying prediction samples.\n","\n","            datamodule: The datamodule with a predict_dataloader method that returns one or more dataloaders.\n","\n","            return_predictions: Whether to return predictions.\n","                ``True`` by default except when an accelerator that spawns processes is used (not supported).\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to use to predict.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","        Returns:\n","            Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\n","        \"\"\"\n","\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"predict\")\n","\n","        self.state.fn = TrainerFn.PREDICTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.predicting = True\n","\n","        self.predict_loop.return_predictions = return_predictions\n","\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.predict(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.predict()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, predict_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.predicted_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.predicting = False\n","\n","        return results\n","\n","    def tune(\n","        self,\n","        model: \"pl.LightningModule\",\n","        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, LightningDataModule]] = None,\n","        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        scale_batch_size_kwargs: Optional[Dict[str, Any]] = None,\n","        lr_find_kwargs: Optional[Dict[str, Any]] = None,\n","        train_dataloader=None,  # noqa TODO: remove with 1.6\n","    ) -> Dict[str, Optional[Union[int, _LRFinder]]]:\n","        r\"\"\"\n","        Runs routines to tune hyperparameters before training.\n","\n","        Args:\n","            model: Model to tune.\n","\n","            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\n","                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.\n","                In the case of multiple dataloaders, please see this :ref:`page <multiple-training-dataloaders>`.\n","\n","            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","            scale_batch_size_kwargs: Arguments for :func:`~pytorch_lightning.tuner.batch_size_scaling.scale_batch_size`\n","\n","            lr_find_kwargs: Arguments for :func:`~pytorch_lightning.tuner.lr_finder.lr_find`\n","        \"\"\"\n","        Trainer._log_api_event(\"tune\")\n","\n","        self.state.fn = TrainerFn.TUNING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.tuning = True\n","\n","        if train_dataloader is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.tune(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.tune(train_dataloaders)` instead. HINT: added 's'\"\n","            )\n","            train_dataloaders = train_dataloader\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(train_dataloaders, LightningDataModule):\n","            datamodule = train_dataloaders\n","            train_dataloaders = None\n","        # If you supply a datamodule you can't supply train_dataloader or val_dataloaders\n","        if (train_dataloaders is not None or val_dataloaders is not None) and datamodule is not None:\n","            raise MisconfigurationException(\n","                \"You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.tune(datamodule=...)`\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(\n","            model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders, datamodule=datamodule\n","        )\n","\n","        result = self.tuner._tune(model, scale_batch_size_kwargs=scale_batch_size_kwargs, lr_find_kwargs=lr_find_kwargs)\n","\n","        assert self.state.stopped\n","        self.tuning = False\n","\n","        return result\n","\n","    def _run(self, model: \"pl.LightningModule\") -> Optional[Union[_EVALUATE_OUTPUT, _PREDICT_OUTPUT]]:\n","        # clean hparams\n","        if hasattr(model, \"hparams\"):\n","            parsing.clean_namespace(model.hparams)\n","\n","        self.config_validator.verify_loop_configurations(model)\n","\n","        # attach model log function to callback\n","        self.callback_connector.attach_model_logging_functions(model)\n","\n","        # hook\n","        self.data_connector.prepare_data(model)\n","        self.callback_connector._attach_model_callbacks(model, self)\n","\n","        # ----------------------------\n","        # SET UP TRAINING\n","        # ----------------------------\n","        self.call_hook(\"on_before_accelerator_backend_setup\", model)\n","        self.accelerator.connect(model)\n","        self.accelerator.setup_environment()\n","        self._call_setup_hook(model)  # allow user to setup lightning_module in accelerator environment\n","\n","        # restore modules after setup\n","        self.checkpoint_connector.restore_datamodule()\n","        self.checkpoint_connector.restore_model()\n","        # restore callback states\n","        self.checkpoint_connector.restore_callbacks()\n","\n","        self._call_configure_sharded_model(model)  # allow user to setup in model sharded environment\n","        self.accelerator.setup(self, model)  # note: this sets up self.lightning_module\n","\n","        # ----------------------------\n","        # INSPECT THE CORE LOOPS\n","        # ----------------------------\n","        fr\"\"\"\n","             Lightning internal flow looks like this:\n","        {Trainer.fit} or {Trainer.test} or {Trainer.predict}  ||\n","                                |                             ||\n","                        create accelerator                    ||\n","                                |                             ||\n","                         {self._dispatch}                     ||\n","                                |                             ||  LIGHTNING\n","                  {self.accelerator.start_training}           ||\n","                or {self.accelerator.start_evaluating}        ||\n","                or {self.accelerator.start_predicting}        ||  FLOW\n","                                |                             ||\n","                         {self.run_stage}                     ||\n","                                |                             ||  DIRECTION\n","                        {self._run_train}                     ||\n","                     or {self._run_evaluate}                  ||\n","                     or {self._run_predict}                   ||\n","                                |                             ||\n","                             results                          \\/\n","        This is used to guide readers to the core loops: train, test, predict.\n","        {self._run_predict} is the simplest to understand, use `Go to Definition` to read it :)\n","        Search for `start_training` or `start_evaluating` or `start_predicting` in\n","        `pytorch_lightning/plugins/training_type_plugin` to find accelerator dispatch functions.\n","        \"\"\"  # noqa: W605\n","\n","        # ----------------------------\n","        # TRAIN\n","        # ----------------------------\n","        # hook\n","        if self.state.fn == TrainerFn.FITTING:\n","            self.call_hook(\"on_fit_start\")\n","\n","        # plugin will setup fitting (e.g. ddp will launch child processes)\n","        self._pre_dispatch()\n","\n","        # restore optimizers, etc.\n","        self.checkpoint_connector.restore_training_state()\n","\n","        # dispatch `start_training` or `start_evaluating` or `start_predicting`\n","        self._dispatch()\n","\n","        # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\n","        self._post_dispatch()\n","\n","        # ----------------------------\n","        # POST-Training CLEAN UP\n","        # ----------------------------\n","        # hook\n","        if self.state.fn == TrainerFn.FITTING:\n","            self.call_hook(\"on_fit_end\")\n","\n","        # teardown\n","        self._call_teardown_hook(model)\n","\n","        if self.state.status != TrainerStatus.INTERRUPTED:\n","            self.state.status = TrainerStatus.FINISHED\n","        self.state.stage = None\n","\n","        return self.accelerator.results\n","\n","    def _pre_dispatch(self):\n","        self.accelerator.pre_dispatch(self)\n","        self._log_hyperparams()\n","\n","    def _log_hyperparams(self):\n","        # log hyper-parameters\n","        hparams_initial = None\n","\n","        if self.logger is not None:\n","            # save exp to get started (this is where the first experiment logs are written)\n","            datamodule_log_hyperparams = self.datamodule._log_hyperparams if self.datamodule is not None else False\n","\n","            if self.lightning_module._log_hyperparams and datamodule_log_hyperparams:\n","                datamodule_hparams = self.datamodule.hparams_initial\n","                lightning_hparams = self.lightning_module.hparams_initial\n","\n","                colliding_keys = lightning_hparams.keys() & datamodule_hparams.keys()\n","                if colliding_keys:\n","                    raise MisconfigurationException(\n","                        f\"Error while merging hparams: the keys {colliding_keys} are present \"\n","                        \"in both the LightningModule's and LightningDataModule's hparams.\"\n","                    )\n","                hparams_initial = {**lightning_hparams, **datamodule_hparams}\n","            elif self.lightning_module._log_hyperparams:\n","                hparams_initial = self.lightning_module.hparams_initial\n","            elif datamodule_log_hyperparams:\n","                hparams_initial = self.datamodule.hparams_initial\n","\n","            if hparams_initial is not None:\n","                self.logger.log_hyperparams(hparams_initial)\n","            self.logger.log_graph(self.lightning_module)\n","            self.logger.save()\n","\n","    def _post_dispatch(self):\n","        self.accelerator.post_dispatch(self)\n","        # these `teardown` calls are here instead of in `_call_teardown_hook` since they are internal teardowns\n","        # which need to happen before.\n","        self.accelerator.teardown()\n","        self._active_loop.teardown()\n","        self.logger_connector.teardown()\n","\n","    def _dispatch(self):\n","        if self.evaluating:\n","            self.accelerator.start_evaluating(self)\n","        elif self.predicting:\n","            self.accelerator.start_predicting(self)\n","        else:\n","            self.accelerator.start_training(self)\n","\n","    def run_stage(self):\n","        self.accelerator.dispatch(self)\n","        self.__setup_profiler()\n","\n","        if self.evaluating:\n","            return self._run_evaluate()\n","        if self.predicting:\n","            return self._run_predict()\n","        return self._run_train()\n","\n","    def _pre_training_routine(self):\n","        # wait for all to join if on distributed\n","        self.accelerator.barrier(\"setup_training\")\n","\n","        # register auto-resubmit when on SLURM\n","        self.slurm_connector.register_slurm_signal_handlers()\n","\n","        self.checkpoint_connector.resume_end()\n","\n","        # --------------------------\n","        # Pre-train\n","        # --------------------------\n","        # on pretrain routine start\n","        ref_model = self.lightning_module\n","\n","        self.on_pretrain_routine_start()\n","        ref_model.on_pretrain_routine_start()\n","\n","        # print model summary\n","        if self.is_global_zero and self.weights_summary is not None and not self.testing:\n","            max_depth = ModelSummary.MODES[self.weights_summary]\n","            ref_model.summarize(max_depth=max_depth)\n","\n","        # on pretrain routine end\n","        self.on_pretrain_routine_end()\n","        ref_model.on_pretrain_routine_end()\n","\n","    def _run_train(self) -> None:\n","        self._pre_training_routine()\n","\n","        if not self.is_global_zero and self.progress_bar_callback is not None:\n","            self.progress_bar_callback.disable()\n","\n","        self._run_sanity_check(self.lightning_module)\n","\n","        # enable train mode\n","        self.model.train()\n","        torch.set_grad_enabled(True)\n","\n","        # reload data when needed\n","        model = self.lightning_module\n","\n","        self.reset_train_val_dataloaders(model)\n","\n","        try:\n","            # reset trainer on this loop and all child loops in case user connected a custom loop\n","            self.fit_loop.trainer = self\n","            self.fit_loop.run()\n","        except KeyboardInterrupt:\n","            rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","            # user could press Ctrl+c many times... only shutdown once\n","            if not self.interrupted:\n","                self.state.status = TrainerStatus.INTERRUPTED\n","                self.on_keyboard_interrupt()\n","                # same treatment as below\n","                self.accelerator.on_train_end()\n","        except BaseException:\n","            self.state.status = TrainerStatus.INTERRUPTED\n","            if distributed_available() and self.world_size > 1:\n","                # try syncing remaing processes, kill otherwise\n","                self.training_type_plugin.reconciliate_processes(traceback.format_exc())\n","            # give accelerators a chance to finish\n","            self.accelerator.on_train_end()\n","            self._on_expection()\n","            # reset bookkeeping\n","            self.state.stage = None\n","            raise\n","\n","    def _run_evaluate(self) -> _EVALUATE_OUTPUT:\n","        if not self.is_global_zero and self.progress_bar_callback is not None:\n","            self.progress_bar_callback.disable()\n","\n","        assert self.evaluating\n","\n","        # reload dataloaders\n","        self._evaluation_loop.reload_evaluation_dataloaders()\n","\n","        # reset trainer on this loop and all child loops in case user connected a custom loop\n","        self._evaluation_loop.trainer = self\n","\n","        with self.profiler.profile(f\"run_{self.state.stage}_evaluation\"), torch.no_grad():\n","            eval_loop_results = self._evaluation_loop.run()\n","\n","        # remove the tensors from the eval results\n","        for i, result in enumerate(eval_loop_results):\n","            if isinstance(result, dict):\n","                for k, v in result.items():\n","                    if isinstance(v, torch.Tensor):\n","                        result[k] = v.cpu().item()\n","\n","        return eval_loop_results\n","\n","    def _run_predict(self) -> Optional[_PREDICT_OUTPUT]:\n","        self.reset_predict_dataloader(self.lightning_module)\n","        # reset trainer on this loop and all child loops in case user connected a custom loop\n","        self.predict_loop.trainer = self\n","        with torch.no_grad():\n","            return self.predict_loop.run()\n","\n","    def _run_sanity_check(self, ref_model):\n","        using_val_step = ref_model.val_dataloader is not None and is_overridden(\"validation_step\", ref_model)\n","        should_sanity_check = using_val_step and self.num_sanity_val_steps > 0 and self.limit_val_batches > 0\n","\n","        # run tiny validation (if validation defined)\n","        # to make sure program won't crash during val\n","        if should_sanity_check:\n","            stage = self.state.stage\n","            self.sanity_checking = True\n","\n","            # hook and callback\n","            self.on_sanity_check_start()\n","\n","            # reload dataloaders\n","            self._evaluation_loop.reload_evaluation_dataloaders()\n","\n","            # run eval step\n","            with torch.no_grad():\n","                self._evaluation_loop.run()\n","\n","            self.on_sanity_check_end()\n","\n","            # reset validation metrics\n","            self.logger_connector.reset()\n","\n","            # reset the seed to what it was before sanity check\n","            # prevents sanity check to affect random sampling in training\n","            reset_seed()\n","\n","            # restore the previous stage when the sanity check if finished\n","            self.state.stage = stage\n","\n","    def __load_ckpt_weights(self, ckpt_path: Optional[str]) -> Optional[str]:\n","        if ckpt_path is None:\n","            return\n","\n","        fn = self.state.fn.value\n","\n","        if ckpt_path == \"best\":\n","            # if user requests the best checkpoint but we don't have it, error\n","            if not self.checkpoint_callback.best_model_path:\n","                if self.fast_dev_run:\n","                    raise MisconfigurationException(\n","                        f\"You cannot execute `.{fn}()` with `fast_dev_run=True` unless you do\"\n","                        f\" `.{fn}(ckpt_path=PATH)` as no checkpoint path was generated during fitting.\"\n","                    )\n","                raise MisconfigurationException(\n","                    f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.'\n","                )\n","            # load best weights\n","            ckpt_path = self.checkpoint_callback.best_model_path\n","\n","        if not ckpt_path:\n","            raise MisconfigurationException(\n","                f'`.{fn}()` found no path for the best weights: \"{ckpt_path}\". Please'\n","                f\" specify a path for a checkpoint `.{fn}(ckpt_path=PATH)`\"\n","            )\n","\n","        # only one process running at this point for TPUs, as spawn isn't triggered yet\n","        # todo: move this logic internally within the barrier.\n","        if not self._device_type == DeviceType.TPU:\n","            self.training_type_plugin.barrier()\n","\n","        self.checkpoint_connector.restore_model_weights(ckpt_path)\n","        return ckpt_path\n","\n","    def _call_setup_hook(self, model: \"pl.LightningModule\") -> None:\n","        fn = self.state.fn._setup_fn\n","\n","        self.accelerator.barrier(\"pre_setup\")\n","\n","        if self.datamodule is not None:\n","            self.datamodule.setup(stage=fn)\n","        self.setup(model, stage=fn)\n","        model.setup(stage=fn)\n","\n","        self.accelerator.barrier(\"post_setup\")\n","\n","    def _call_configure_sharded_model(self, model: \"pl.LightningModule\") -> None:\n","        # Call configure sharded model hook if accelerator requests. In some cases\n","        # we will not call the hook; the hook has initialized the sharded model for example.\n","\n","        # used on the model if the user re-create a trainer with resume_from_checkpoint\n","        model_call_configure_sharded_model_hook = getattr(model, \"call_configure_sharded_model_hook\", False)\n","        if self.accelerator.call_configure_sharded_model_hook and not model_call_configure_sharded_model_hook:\n","            with self.accelerator.model_sharded_context():\n","                model.configure_sharded_model()\n","                self.configure_sharded_model(model)\n","            model.call_configure_sharded_model_hook = True\n","            self.accelerator.call_configure_sharded_model_hook = False\n","\n","    def _call_teardown_hook(self, model: \"pl.LightningModule\") -> None:\n","        fn = self.state.fn._setup_fn\n","\n","        if self.datamodule is not None:\n","            self.datamodule.teardown(stage=fn)\n","        self.profiler.teardown(stage=fn)\n","        self.teardown(stage=fn)\n","        model.teardown(stage=fn)\n","\n","        model._current_fx_name = None\n","        model._current_dataloader_idx = None\n","        # these could have become stale if metrics are defined in `setup`\n","        model._metric_attributes = None\n","\n","    def call_hook(self, hook_name: str, *args, **kwargs) -> Any:\n","        # Note this implementation is copy/pasted into the TrainLoop class in TrainingEpochLoop._on_train_epoch_end_hook\n","        # This was done to manage the deprecation of the `outputs` argument to on_train_epoch_end\n","        # If making changes to this function, ensure that those changes are also made to\n","        # TrainingEpochLoop._on_train_epoch_end_hook\n","        if self.lightning_module:\n","            prev_fx_name = self.lightning_module._current_fx_name\n","            self.lightning_module._current_fx_name = hook_name\n","\n","        # always profile hooks\n","        with self.profiler.profile(hook_name):\n","\n","            # first call trainer hook\n","            if hasattr(self, hook_name):\n","                trainer_hook = getattr(self, hook_name)\n","                trainer_hook(*args, **kwargs)\n","\n","            # next call hook in lightningModule\n","            output = None\n","            model_ref = self.lightning_module\n","            if is_overridden(hook_name, model_ref):\n","                hook_fx = getattr(model_ref, hook_name)\n","                output = hook_fx(*args, **kwargs)\n","\n","            # call the accelerator hook\n","            if hasattr(self.accelerator, hook_name):\n","                accelerator_hook = getattr(self.accelerator, hook_name)\n","                accelerator_output = accelerator_hook(*args, **kwargs)\n","                # Rely on the accelerator output if lightningModule hook returns nothing\n","                # Required for cases such as DataParallel where we reduce the output for the user\n","                # todo: move this data parallel logic into the data parallel plugin\n","                output = accelerator_output if output is None else output\n","\n","        if self.lightning_module:\n","            # restore current_fx when nested context\n","            self.lightning_module._current_fx_name = prev_fx_name\n","\n","        return output\n","\n","    def _parse_devices(\n","        self,\n","        gpus: Optional[Union[List[int], str, int]],\n","        auto_select_gpus: bool,\n","        tpu_cores: Optional[Union[List[int], str, int]],\n","    ) -> Tuple[Optional[List[int]], Optional[Union[List[int], int]]]:\n","        if auto_select_gpus and isinstance(gpus, int):\n","            gpus = pick_multiple_gpus(gpus)\n","\n","        # TODO (@seannaren, @kaushikb11): Include IPU parsing logic here\n","        gpu_ids = device_parser.parse_gpu_ids(gpus)\n","        tpu_cores = device_parser.parse_tpu_cores(tpu_cores)\n","        return gpu_ids, tpu_cores\n","\n","    @staticmethod\n","    def _log_api_event(event: str) -> None:\n","        torch._C._log_api_usage_once(\"lightning.trainer.\" + event)\n","\n","    def __init_profiler(self, profiler: Optional[Union[BaseProfiler, str]]) -> None:\n","        if isinstance(profiler, str):\n","            PROFILERS = {\n","                \"simple\": SimpleProfiler,\n","                \"advanced\": AdvancedProfiler,\n","                \"pytorch\": PyTorchProfiler,\n","                \"xla\": XLAProfiler,\n","            }\n","            profiler = profiler.lower()\n","            if profiler not in PROFILERS:\n","                raise MisconfigurationException(\n","                    \"When passing string value for the `profiler` parameter of `Trainer`,\"\n","                    f\" it can only be one of {list(PROFILERS.keys())}\"\n","                )\n","            profiler_class = PROFILERS[profiler]\n","            profiler = profiler_class()\n","        self.profiler: BaseProfiler = profiler or PassThroughProfiler()\n","\n","    def __setup_profiler(self) -> None:\n","        local_rank = self.local_rank if self.world_size > 1 else None\n","        self.profiler._lightning_module = proxy(self.lightning_module)\n","        self.profiler.setup(stage=self.state.fn._setup_fn, local_rank=local_rank, log_dir=self.log_dir)\n","\n","    def _log_device_info(self) -> None:\n","        rank_zero_info(f\"GPU available: {torch.cuda.is_available()}, used: {self._device_type == DeviceType.GPU}\")\n","\n","        num_tpu_cores = self.tpu_cores if self.tpu_cores is not None and self._device_type == DeviceType.TPU else 0\n","        rank_zero_info(f\"TPU available: {_TPU_AVAILABLE}, using: {num_tpu_cores} TPU cores\")\n","\n","        num_ipus = self.ipus if self.ipus is not None else 0\n","        rank_zero_info(f\"IPU available: {_IPU_AVAILABLE}, using: {num_ipus} IPUs\")\n","\n","        if torch.cuda.is_available() and self._device_type != DeviceType.GPU:\n","            rank_zero_warn(\n","                \"GPU available but not used. Set the gpus flag in your trainer\"\n","                \" `Trainer(gpus=1)` or script `--gpus=1`.\"\n","            )\n","\n","        if _TPU_AVAILABLE and self._device_type != DeviceType.TPU:\n","            rank_zero_warn(\n","                \"TPU available but not used. Set the `tpu_cores` flag in your trainer\"\n","                \" `Trainer(tpu_cores=8)` or script `--tpu_cores=8`.\"\n","            )\n","\n","        if _IPU_AVAILABLE and self._device_type != DeviceType.IPU and not isinstance(self.accelerator, IPUAccelerator):\n","            rank_zero_warn(\n","                \"IPU available but not used. Set the `ipus` flag in your trainer\"\n","                \" `Trainer(ipus=8)` or script `--ipus=8`.\"\n","            )\n","\n","    def _on_expection(self):\n","        if not self.is_global_zero or not _fault_tolerant_enabled():\n","            return\n","        # save a checkpoint for fault tolerant training. we don't use `log_dir` to minimize the chances of failure.\n","        file_path = os.path.join(self.default_root_dir, \".pl_auto_save.ckpt\")\n","        self.save_checkpoint(file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7K9LGUAvIpV","executionInfo":{"status":"ok","timestamp":1659183263599,"user_tz":-420,"elapsed":919,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"c610f71b-4291-4fdd-a0e7-0d647a9b5be3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\n"]}]},{"cell_type":"markdown","source":["# Build Forecast System"],"metadata":{"id":"dy4kGKYQg__z"}},{"cell_type":"code","source":["%%writefile app.py\n","\n","# import necesary libraries and modules\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import leafmap.foliumap as leafmap\n","from time import sleep\n","from bigdl.orca import init_orca_context, stop_orca_context\n","from bigdl.orca import OrcaContext\n","from bigdl.chronos.data import TSDataset\n","from bigdl.chronos.forecaster.lstm_forecaster import LSTMForecaster\n","from bigdl.orca.automl.metrics import Evaluator\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from PIL import Image\n","\n","\n","st.set_page_config(\n","     page_title=\"Demo Khóa luận tốt nghiệp\",\n","     page_icon=\"✅\",\n","     layout=\"wide\",\n","     initial_sidebar_state=\"expanded\"\n"," )\n","\n","title = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 38px; text-align:center;\">DEMO HỆ THỐNG DỰ BÁO LUỒNG GIAO THÔNG VỚI MÔ HÌNH CHUỖI THỜI GIAN ĐA BIẾN SỬ DỤNG BIGDL</p>'\n","st.markdown(title, unsafe_allow_html=True)\n","\n","# Nội dung lề trái\n","with st.sidebar:\n","  col1, col2, col3 = st.columns([2, 4, 2])\n","\n","  with col1:\n","      st.write('')\n","\n","  with col2:\n","    image_path='/content/drive/MyDrive/Khoá luận tốt nghiệp/Notebook/Notebook Demo/Logo_UIT_Web_Transparent.png'\n","    #image_path='/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Notebook/Notebook Demo/Logo_UIT_Web_Transparent.png'\n","    image = Image.open(image_path)\n","    st.image(image, width=145, output_format=\"PNG\")\n","\n","  with col3:\n","      st.write('')\n","\n","  # Thêm tên bên lề trái\n","  st.text(\"\")\n","  st.text(\"\")\n","  st.text(\"\")\n","  original_title1 = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 17px; text-align:center; background-color:#90ee90;\">Sinh viên thực hiện</p>'\n","  st.markdown(original_title1, unsafe_allow_html=True)\n","\n","  # Sinh viên thực hiện\n","  original_name1 = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\">Trịnh Ngọc Pháp - 18521227</p>'\n","  st.markdown(\"- \" + original_name1, unsafe_allow_html=True)\n","  # original_mail1 = '<p style=\"font-family:Nunito; font-weight:normal; color:Blue; font-size: 15px; text-align:left;\">18521227@gm.uit.edu.vn</p>'\n","  # st.markdown(original_mail1, unsafe_allow_html=True)\n","\n","  original_name2 = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\">Trần Nguyễn Anh Khoa - 18520938</p>'\n","  st.markdown(\"- \" + original_name2, unsafe_allow_html=True)\n","\n","  # Giảng viên hướng dẫn  \n","  st.text(\"\")\n","  original_title2 = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 17px; text-align:center; background-color:#f4a460;\">Giảng viên hướng dẫn</p>'\n","  st.markdown(original_title2, unsafe_allow_html=True)\n","\n","  original_name3 = '<p style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\">TS. Đỗ Trọng Hợp</p>'\n","  st.markdown(\"- \" + original_name3, unsafe_allow_html=True)\n","\n","#submit = st.button('Load model')\n","col1, col2, col3 , col4, col5 = st.columns(5)\n","\n","with col1:\n","    pass\n","with col2:\n","    pass\n","with col4:\n","    pass\n","with col5:\n","    pass\n","with col3 :\n","    submit = st.button('Load model')\n","if submit:\n","  placeholder = st.empty()\n","  with placeholder.container():\n","    st.info('Loading...')\n","  #df = pd.read_csv(\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Dataset/final_data_6.csv\")\n","  df = pd.read_csv(\"/content/drive/MyDrive/Khoá luận tốt nghiệp/Dataset/final_data_6.csv\")\n","\n","  # recommended to set it to True when running bigdl-chronos in Jupyter notebook \n","  OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n","  init_orca_context(cluster_mode=\"local\", cores=4, init_ray_on_spark=True)\n","\n","  # create list feature\n","  location_ft = ['lat', 'long']\n","  link_ft = ['20223', 'GL1', '1255', '1405', '1404', '1403', 'GL2', '1271','1253', '1401', 'GL3', '1283', '1258', '1256']\n","  weather_ft = ['rhum', 'sun', 'vis']\n","\n","  # components to make a evaluate table\n","  def s_mape(a, f):\n","    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f)))\n","\n","\n","  tsdata_train, _, tsdata_test = TSDataset.from_pandas(df, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft , with_split=True, val_ratio=0.1, test_ratio=0.1)\n","\n","  minmax_scaler = MinMaxScaler()\n","\n","  for tsdata in [tsdata_train, tsdata_test]:\n","      tsdata.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","\n","  X_train, y_train = tsdata_train.to_numpy()\n","  X_test, y_test = tsdata_test.to_numpy()\n","  #X_train.shape, y_train.shape, X_test.shape, y_test.shape\n","\n","  feature_dim = X_train.shape[-1]\n","  target_dim = 1\n","  learning_rate = 0.01\n","  batch_size = 128\n","  epochs = 3\n","\n","  # build model\n","  forecaster = LSTMForecaster(past_seq_len=X_train.shape[1],\n","                              input_feature_num=feature_dim,\n","                              output_feature_num=target_dim,\n","                              hidden_dim=32,\n","                              lr=learning_rate, layer_num=2, dropout=0.2,\n","                              seed=17)\n","\n","  forecaster.load(checkpoint_file=\"/content/drive/MyDrive/Khoá luận tốt nghiệp/Notebook/Notebook Model/Saved_Pipelines/multivariate_forecaster_lstm.ckpt\", quantize_checkpoint_file=None)\n","  #forecaster.load(checkpoint_file=\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Notebook/Notebook Model/Saved_Pipelines/multivariate_forecaster_lstm.ckpt\", quantize_checkpoint_file=None)\n","  placeholder.empty()\n","  st.success('Success loading!')\n","  y_pred = forecaster.predict(X_test)\n","  y_pred_unscale = tsdata_test.unscale_numpy(y_pred)\n","  y_test_unscale = tsdata_test.unscale_numpy(y_test)\n","\n","  rmse =  Evaluator.evaluate(\"rmse\", y_test_unscale, y_pred_unscale, multioutput='raw_values')[0][0]\n","  smape = s_mape(y_test_unscale.reshape(-1), y_pred_unscale.reshape(-1))\n","  print(\"Current - rmse: \" + str(rmse) + \"\\tsmape: \" + str(smape))\n","\n","  df_demo = pd.read_csv(\"/content/drive/MyDrive/Khoá luận tốt nghiệp/Dataset/final_data_demo_17_6_21_6.csv\")\n","  #df_demo = pd.read_csv(\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Dataset/final_data_demo_17_6_21_6.csv\")\n","\n","  colors = ['blue', 'lime', 'red']\n","  vmin = df_demo.value.min()\n","  vmax = df_demo.value.max()\n","\n","  list_id = ['000000001253A',\n","  '000000001253B',\n","  '000000001255A',\n","  '000000001255B',\n","  '000000001256A',\n","  '000000001256B',\n","  '000000001258A',\n","  '000000001258B',\n","  '000000001271A',\n","  '000000001271B',\n","  '000000001283A',\n","  '000000001283B',\n","  '000000001401A',\n","  '000000001401B',\n","  '000000001403A',\n","  '000000001403B',\n","  '000000001404A',\n","  '000000001404B',\n","  '000000001405A',\n","  '000000001405B',\n","  '000000020223A',\n","  '000000020223B']\n","\n","  with st.empty():\n","    for i in range(60):\n","      df_demo_batch = pd.DataFrame()\n","      df_input = pd.DataFrame()\n","      for id in list_id:\n","        df_filter = df_demo[df_demo['id'] == id].iloc[i:51+i,:]\n","        df_demo_batch = pd.concat([df_demo_batch, df_filter], ignore_index=True)\n","\n","        df_filter_2 = df_demo[df_demo['id'] == id].iloc[i:50+i,:]\n","        df_input = pd.concat([df_input, df_filter_2], ignore_index=True)\n","\n","      current_time = df_demo_batch.iloc[-2,:].datetime\n","      forecast_time = df_demo_batch.iloc[-1,:].datetime\n","\n","      tsdata_demo = TSDataset.from_pandas(df_demo_batch, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft, with_split=False)\n","      tsdata_demo.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","      X_demo, y_demo = tsdata_demo.to_numpy()\n","      y_pred_demo = forecaster.predict(X_demo)\n","\n","      y_pred_demo_unscale = tsdata_demo.unscale_numpy(y_pred_demo)\n","      print(y_pred_demo_unscale.reshape(-1))\n","      # y_demo_unscale = tsdata_demo.unscale_numpy(y_demo)\n","      \n","      df_visualize = tsdata_demo.unscale().to_pandas()\n","\n","      result = pd.DataFrame()\n","      for id in list_id:\n","        df_filter = df_visualize[df_visualize['id'] == id].iloc[50:,:]\n","        result = pd.concat([result, df_filter])\n","\n","      result['pred'] = y_pred_demo_unscale.reshape(-1)\n","\n","      m = leafmap.Map(center=[51.872913, -8.477261], zoom=12.3, tiles='stamentoner')\n","      m.add_heatmap(\n","          result,\n","          latitude=\"lat\",\n","          longitude='long',\n","          value=\"pred\",\n","          name=\"Heat map\",\n","          radius=30,\n","      )\n","\n","      m.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)\n","      m.add_title(f\"Current time:   {current_time}\", font_size=\"16px\", align=\"left\")\n","      m.add_title(f\"Forecast time: {forecast_time}\", font_size=\"16px\", align=\"left\")\n","\n","      with st.container():\n","        st.subheader(\"Heatmap\")\n","        m.to_streamlit()\n","\n","        st.subheader(\"Input\")\n","        st.dataframe(df_input)\n","\n","        st.subheader(\"Output\")\n","        st.dataframe(result[['id', 'datetime', 'pred']])\n","\n","      sleep(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdtRPRjO1lJ8","executionInfo":{"status":"ok","timestamp":1659183777034,"user_tz":-420,"elapsed":11,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"d33a23bf-720b-4c35-ecd7-d5e2cba9dd80"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["a = 1\n","b = 2\n","print(f\"abc  {a}\\n{b}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QD9CPkiCzZkX","executionInfo":{"status":"ok","timestamp":1656260286230,"user_tz":-420,"elapsed":287,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"28bc1f1c-846f-41a4-eda3-f44c306d6ac6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["abc  1\n","2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df_demo = pd.read_csv(\"/content/drive/MyDrive/Khoá luận tốt nghiệp/Dataset/final_data_demo_17_6_21_6.csv\")\n","df_demo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"rSOXVDv0kOm4","executionInfo":{"status":"ok","timestamp":1656224547429,"user_tz":-420,"elapsed":402,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"444211b9-e527-4379-d289-992368e244ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 id             datetime  value  20223  GL1  1255  1405  1404  \\\n","0     000000001253A  2022-06-17 00:00:00    305      0    0     0     0     0   \n","1     000000001253B  2022-06-17 00:00:00    212      0    0     0     0     0   \n","2     000000001255A  2022-06-17 00:00:00    111      0    1     1     0     0   \n","3     000000001255B  2022-06-17 00:00:00     87      0    0     1     1     0   \n","4     000000001256A  2022-06-17 00:00:00    130      0    0     0     0     0   \n","...             ...                  ...    ...    ...  ...   ...   ...   ...   \n","2635  000000001404B  2022-06-21 23:00:00    257      0    0     0     0     1   \n","2636  000000001405A  2022-06-21 23:00:00    166      0    0     0     1     1   \n","2637  000000001405B  2022-06-21 23:00:00    225      0    0     1     1     0   \n","2638  000000020223A  2022-06-21 23:00:00     78      1    1     0     0     0   \n","2639  000000020223B  2022-06-21 23:00:00     84      1    0     0     0     0   \n","\n","      1403  GL2  ...  1401  GL3  1283  1258  1256       lat     long    vis  \\\n","0        0    0  ...     1    0     0     0     0  51.87488 -8.44783  17000   \n","1        0    1  ...     0    0     0     0     0  51.87488 -8.44783  17000   \n","2        0    0  ...     0    0     0     0     0  51.87636 -8.56072  17000   \n","3        0    0  ...     0    0     0     0     0  51.87636 -8.56072  17000   \n","4        0    0  ...     0    0     0     1     1  51.88825 -8.39061  17000   \n","...    ...  ...  ...   ...  ...   ...   ...   ...       ...      ...    ...   \n","2635     1    0  ...     0    0     0     0     0  51.87567 -8.51047  10000   \n","2636     0    0  ...     0    0     0     0     0  51.87281 -8.53436  10000   \n","2637     0    0  ...     0    0     0     0     0  51.87281 -8.53436  10000   \n","2638     0    0  ...     0    0     0     0     0  51.88714 -8.56911  10000   \n","2639     0    0  ...     0    0     0     0     0  51.88714 -8.56911  10000   \n","\n","      rhum  sun  \n","0       94  0.0  \n","1       94  0.0  \n","2       94  0.0  \n","3       94  0.0  \n","4       94  0.0  \n","...    ...  ...  \n","2635    82  0.0  \n","2636    82  0.0  \n","2637    82  0.0  \n","2638    82  0.0  \n","2639    82  0.0  \n","\n","[2640 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-f796d6d6-065e-4741-babe-f453d83cbf16\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>datetime</th>\n","      <th>value</th>\n","      <th>20223</th>\n","      <th>GL1</th>\n","      <th>1255</th>\n","      <th>1405</th>\n","      <th>1404</th>\n","      <th>1403</th>\n","      <th>GL2</th>\n","      <th>...</th>\n","      <th>1401</th>\n","      <th>GL3</th>\n","      <th>1283</th>\n","      <th>1258</th>\n","      <th>1256</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>vis</th>\n","      <th>rhum</th>\n","      <th>sun</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 00:00:00</td>\n","      <td>305</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000</td>\n","      <td>94</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000000001253B</td>\n","      <td>2022-06-17 00:00:00</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000</td>\n","      <td>94</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000000001255A</td>\n","      <td>2022-06-17 00:00:00</td>\n","      <td>111</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87636</td>\n","      <td>-8.56072</td>\n","      <td>17000</td>\n","      <td>94</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000000001255B</td>\n","      <td>2022-06-17 00:00:00</td>\n","      <td>87</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87636</td>\n","      <td>-8.56072</td>\n","      <td>17000</td>\n","      <td>94</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000000001256A</td>\n","      <td>2022-06-17 00:00:00</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>51.88825</td>\n","      <td>-8.39061</td>\n","      <td>17000</td>\n","      <td>94</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2635</th>\n","      <td>000000001404B</td>\n","      <td>2022-06-21 23:00:00</td>\n","      <td>257</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87567</td>\n","      <td>-8.51047</td>\n","      <td>10000</td>\n","      <td>82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2636</th>\n","      <td>000000001405A</td>\n","      <td>2022-06-21 23:00:00</td>\n","      <td>166</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87281</td>\n","      <td>-8.53436</td>\n","      <td>10000</td>\n","      <td>82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2637</th>\n","      <td>000000001405B</td>\n","      <td>2022-06-21 23:00:00</td>\n","      <td>225</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.87281</td>\n","      <td>-8.53436</td>\n","      <td>10000</td>\n","      <td>82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2638</th>\n","      <td>000000020223A</td>\n","      <td>2022-06-21 23:00:00</td>\n","      <td>78</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>10000</td>\n","      <td>82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2639</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-21 23:00:00</td>\n","      <td>84</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>10000</td>\n","      <td>82</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2640 rows × 22 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f796d6d6-065e-4741-babe-f453d83cbf16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f796d6d6-065e-4741-babe-f453d83cbf16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f796d6d6-065e-4741-babe-f453d83cbf16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df_demo.iloc[-1,:].datetime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8rlpSyZTrQgL","executionInfo":{"status":"ok","timestamp":1656224680444,"user_tz":-420,"elapsed":419,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"78cb5efe-4abf-46b8-ab69-bc7a1566f766"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2022-06-21 23:00:00'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["list_id = ['000000001253A',\n"," '000000001253B',\n"," '000000001255A',\n"," '000000001255B',\n"," '000000001256A',\n"," '000000001256B',\n"," '000000001258A',\n"," '000000001258B',\n"," '000000001271A',\n"," '000000001271B',\n"," '000000001283A',\n"," '000000001283B',\n"," '000000001401A',\n"," '000000001401B',\n"," '000000001403A',\n"," '000000001403B',\n"," '000000001404A',\n"," '000000001404B',\n"," '000000001405A',\n"," '000000001405B',\n"," '000000020223A',\n"," '000000020223B']\n","\n","for i in range(60):\n","  df_demo_batch = pd.DataFrame()\n","  for id in list_id:\n","    df_filter = df_demo[df_demo['id'] == id].iloc[i:51+i,:]\n","    df_demo_batch = pd.concat([df_demo_batch, df_filter], ignore_index=True)\n","\n","  tsdata_demo = TSDataset.from_pandas(df_demo_batch, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft, with_split=False)\n","  tsdata_demo.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","  X_demo, y_demo = tsdata_demo.to_numpy()\n","  y_pred_demo = forecaster.predict(X_demo)\n","\n","  y_pred_demo_unscale = tsdata_demo.unscale_numpy(y_pred_demo)\n","  # print(y_pred_demo_unscale.reshape(-1))\n","  # y_demo_unscale = tsdata_demo.unscale_numpy(y_demo)\n","  # sleep(5)\n","\n","  df_visualize = tsdata_demo.unscale().to_pandas()\n","\n","  result = pd.DataFrame()\n","  for id in list_id:\n","    df_filter = df_visualize[df_visualize['id'] == id].iloc[50:,:]\n","    result = pd.concat([result, df_filter])\n","\n","  result['pred'] = y_pred_demo_unscale.reshape(-1)\n","\n","  m = leafmap.Map(center=[51.872913, -8.477261], zoom=12.3, tiles='stamentoner')\n","  m.add_heatmap(\n","      result,\n","      latitude=\"lat\",\n","      longitude='long',\n","      value=\"pred\",\n","      name=\"Heat map\",\n","      radius=20,\n","  )\n","\n","  # colors = ['blue', 'lime', 'red']\n","  # vmin = result.pred.min()\n","  # vmax = result.pred.max()\n","  # m.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)\n","  m.add_title(\"World Population Heat Map\", font_size=\"20px\", align=\"center\")\n","\n","  m\n","\n","  sleep(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"kcM8SSpImVIZ","executionInfo":{"status":"error","timestamp":1656008874813,"user_tz":-420,"elapsed":21935,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"0fd4a422-41ab-4bcf-c470-0692769b9186"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_533/3396322203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["tsdata_demo = TSDataset.from_pandas(df_demo_batch, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft, with_split=False)\n","tsdata_demo.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","X_demo, y_demo = tsdata_demo.to_numpy()\n","y_pred_demo = forecaster.predict(X_demo)\n","\n","y_pred_demo_unscale = tsdata_demo.unscale_numpy(y_pred_demo)\n","y_demo_unscale = tsdata_demo.unscale_numpy(y_demo)\n","\n","# rmse =  Evaluator.evaluate(\"rmse\", y_test_unscale_2, y_pred_unscale_2, multioutput='raw_values')[0][0]\n","# smape = s_mape(y_test_unscale_2.reshape(-1), y_pred_unscale_2.reshape(-1))\n","# print(\"Current - rmse: \" + str(rmse) + \"\\tsmape: \" + str(smape))"],"metadata":{"id":"4sIxoO-KlCq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_visualize = tsdata_demo.unscale().to_pandas()"],"metadata":{"id":"mq62C4f_ukdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_visualize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Hi4CQ11Lu0lW","executionInfo":{"status":"ok","timestamp":1656007382618,"user_tz":-420,"elapsed":699,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"f48b6e71-b5c6-456a-ff14-d46d840a740f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 id             datetime   value  20223  GL1  1255  1405  \\\n","0     000000001253A  2022-06-17 03:00:00   102.0    0.0  0.0   0.0   0.0   \n","1     000000001253A  2022-06-17 04:00:00   163.0    0.0  0.0   0.0   0.0   \n","2     000000001253A  2022-06-17 05:00:00   440.0    0.0  0.0   0.0   0.0   \n","3     000000001253A  2022-06-17 06:00:00  1558.0    0.0  0.0   0.0   0.0   \n","4     000000001253A  2022-06-17 07:00:00  2722.0    0.0  0.0   0.0   0.0   \n","...             ...                  ...     ...    ...  ...   ...   ...   \n","1117  000000020223B  2022-06-19 01:00:00    43.0    1.0  0.0   0.0   0.0   \n","1118  000000020223B  2022-06-19 02:00:00    40.0    1.0  0.0   0.0   0.0   \n","1119  000000020223B  2022-06-19 03:00:00    28.0    1.0  0.0   0.0   0.0   \n","1120  000000020223B  2022-06-19 04:00:00    18.0    1.0  0.0   0.0   0.0   \n","1121  000000020223B  2022-06-19 05:00:00    11.0    1.0  0.0   0.0   0.0   \n","\n","      1404  1403  GL2  ...  1401  GL3  1283  1258  1256       lat     long  \\\n","0      0.0   0.0  0.0  ...   1.0  0.0   0.0   0.0   0.0  51.87488 -8.44783   \n","1      0.0   0.0  0.0  ...   1.0  0.0   0.0   0.0   0.0  51.87488 -8.44783   \n","2      0.0   0.0  0.0  ...   1.0  0.0   0.0   0.0   0.0  51.87488 -8.44783   \n","3      0.0   0.0  0.0  ...   1.0  0.0   0.0   0.0   0.0  51.87488 -8.44783   \n","4      0.0   0.0  0.0  ...   1.0  0.0   0.0   0.0   0.0  51.87488 -8.44783   \n","...    ...   ...  ...  ...   ...  ...   ...   ...   ...       ...      ...   \n","1117   0.0   0.0  0.0  ...   0.0  0.0   0.0   0.0   0.0  51.88714 -8.56911   \n","1118   0.0   0.0  0.0  ...   0.0  0.0   0.0   0.0   0.0  51.88714 -8.56911   \n","1119   0.0   0.0  0.0  ...   0.0  0.0   0.0   0.0   0.0  51.88714 -8.56911   \n","1120   0.0   0.0  0.0  ...   0.0  0.0   0.0   0.0   0.0  51.88714 -8.56911   \n","1121   0.0   0.0  0.0  ...   0.0  0.0   0.0   0.0   0.0  51.88714 -8.56911   \n","\n","          vis  rhum  sun  \n","0     17000.0  94.0  0.0  \n","1     17000.0  93.0  0.8  \n","2     17000.0  94.0  1.0  \n","3     17000.0  94.0  1.0  \n","4     17000.0  98.0  1.0  \n","...       ...   ...  ...  \n","1117  20500.0  81.0  0.0  \n","1118  20500.0  82.0  0.0  \n","1119  20500.0  82.0  0.0  \n","1120  20500.0  82.0  0.8  \n","1121  18700.0  82.0  1.0  \n","\n","[1122 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-19775aab-bcf6-4130-8610-37876131c201\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>datetime</th>\n","      <th>value</th>\n","      <th>20223</th>\n","      <th>GL1</th>\n","      <th>1255</th>\n","      <th>1405</th>\n","      <th>1404</th>\n","      <th>1403</th>\n","      <th>GL2</th>\n","      <th>...</th>\n","      <th>1401</th>\n","      <th>GL3</th>\n","      <th>1283</th>\n","      <th>1258</th>\n","      <th>1256</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>vis</th>\n","      <th>rhum</th>\n","      <th>sun</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 03:00:00</td>\n","      <td>102.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000.0</td>\n","      <td>94.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 04:00:00</td>\n","      <td>163.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000.0</td>\n","      <td>93.0</td>\n","      <td>0.8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 05:00:00</td>\n","      <td>440.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000.0</td>\n","      <td>94.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 06:00:00</td>\n","      <td>1558.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000.0</td>\n","      <td>94.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-17 07:00:00</td>\n","      <td>2722.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>17000.0</td>\n","      <td>98.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1117</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 01:00:00</td>\n","      <td>43.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>20500.0</td>\n","      <td>81.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1118</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 02:00:00</td>\n","      <td>40.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>20500.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1119</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 03:00:00</td>\n","      <td>28.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>20500.0</td>\n","      <td>82.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1120</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 04:00:00</td>\n","      <td>18.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>20500.0</td>\n","      <td>82.0</td>\n","      <td>0.8</td>\n","    </tr>\n","    <tr>\n","      <th>1121</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1122 rows × 22 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19775aab-bcf6-4130-8610-37876131c201')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-19775aab-bcf6-4130-8610-37876131c201 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-19775aab-bcf6-4130-8610-37876131c201');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["result = pd.DataFrame()\n","for id in list_id:\n","  df_filter = df_visualize[df_visualize['id'] == id].iloc[50:,:]\n","  result = pd.concat([result, df_filter])\n","\n","result['pred'] = y_pred_demo_unscale.reshape(-1)\n","result"],"metadata":{"id":"aOOzHxONwnFw","colab":{"base_uri":"https://localhost:8080/","height":769},"executionInfo":{"status":"ok","timestamp":1656007886347,"user_tz":-420,"elapsed":381,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}},"outputId":"761b86af-292c-4ab9-d264-112f807eea2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 id             datetime  value  20223  GL1  1255  1405  1404  \\\n","50    000000001253A  2022-06-19 05:00:00  168.0    0.0  0.0   0.0   0.0   0.0   \n","101   000000001253B  2022-06-19 05:00:00  187.0    0.0  0.0   0.0   0.0   0.0   \n","152   000000001255A  2022-06-19 05:00:00   46.0    0.0  1.0   1.0   0.0   0.0   \n","203   000000001255B  2022-06-19 05:00:00   81.0    0.0  0.0   1.0   1.0   0.0   \n","254   000000001256A  2022-06-19 05:00:00  157.0    0.0  0.0   0.0   0.0   0.0   \n","305   000000001256B  2022-06-19 05:00:00  132.0    0.0  0.0   0.0   0.0   0.0   \n","356   000000001258A  2022-06-19 05:00:00  142.0    0.0  0.0   0.0   0.0   0.0   \n","407   000000001258B  2022-06-19 05:00:00  160.0    0.0  0.0   0.0   0.0   0.0   \n","458   000000001271A  2022-06-19 05:00:00  103.0    0.0  0.0   0.0   0.0   0.0   \n","509   000000001271B  2022-06-19 05:00:00  156.0    0.0  0.0   0.0   0.0   0.0   \n","560   000000001283A  2022-06-19 05:00:00   99.0    0.0  0.0   0.0   0.0   0.0   \n","611   000000001283B  2022-06-19 05:00:00   85.0    0.0  0.0   0.0   0.0   0.0   \n","662   000000001401A  2022-06-19 05:00:00  164.0    0.0  0.0   0.0   0.0   0.0   \n","713   000000001401B  2022-06-19 05:00:00  133.0    0.0  0.0   0.0   0.0   0.0   \n","764   000000001403A  2022-06-19 05:00:00  141.0    0.0  0.0   0.0   0.0   0.0   \n","815   000000001403B  2022-06-19 05:00:00  136.0    0.0  0.0   0.0   0.0   1.0   \n","866   000000001404A  2022-06-19 05:00:00  106.0    0.0  0.0   0.0   1.0   1.0   \n","917   000000001404B  2022-06-19 05:00:00  109.0    0.0  0.0   0.0   0.0   1.0   \n","968   000000001405A  2022-06-19 05:00:00   78.0    0.0  0.0   0.0   1.0   1.0   \n","1019  000000001405B  2022-06-19 05:00:00   49.0    0.0  0.0   1.0   1.0   0.0   \n","1070  000000020223A  2022-06-19 05:00:00   25.0    1.0  1.0   0.0   0.0   0.0   \n","1121  000000020223B  2022-06-19 05:00:00   11.0    1.0  0.0   0.0   0.0   0.0   \n","\n","      1403  GL2  ...  GL3  1283  1258  1256       lat     long      vis  rhum  \\\n","50     0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87488 -8.44783  18700.0  82.0   \n","101    0.0  1.0  ...  0.0   0.0   0.0   0.0  51.87488 -8.44783  18700.0  82.0   \n","152    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87636 -8.56072  18700.0  82.0   \n","203    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87636 -8.56072  18700.0  82.0   \n","254    0.0  0.0  ...  0.0   0.0   1.0   1.0  51.88825 -8.39061  18700.0  82.0   \n","305    0.0  0.0  ...  0.0   0.0   0.0   1.0  51.88825 -8.39061  18700.0  82.0   \n","356    0.0  0.0  ...  1.0   0.0   1.0   0.0  51.88229 -8.40760  18700.0  82.0   \n","407    0.0  0.0  ...  0.0   0.0   1.0   1.0  51.88229 -8.40760  18700.0  82.0   \n","458    0.0  1.0  ...  0.0   0.0   0.0   0.0  51.86242 -8.47908  18700.0  82.0   \n","509    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.86242 -8.47908  18700.0  82.0   \n","560    0.0  0.0  ...  1.0   1.0   0.0   0.0  51.87578 -8.41266  18700.0  82.0   \n","611    0.0  0.0  ...  0.0   1.0   0.0   0.0  51.87578 -8.41266  18700.0  82.0   \n","662    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87942 -8.43249  18700.0  82.0   \n","713    0.0  0.0  ...  1.0   0.0   0.0   0.0  51.87942 -8.43249  18700.0  82.0   \n","764    1.0  1.0  ...  0.0   0.0   0.0   0.0  51.87619 -8.49964  18700.0  82.0   \n","815    1.0  0.0  ...  0.0   0.0   0.0   0.0  51.87619 -8.49964  18700.0  82.0   \n","866    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87567 -8.51047  18700.0  82.0   \n","917    1.0  0.0  ...  0.0   0.0   0.0   0.0  51.87567 -8.51047  18700.0  82.0   \n","968    0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87281 -8.53436  18700.0  82.0   \n","1019   0.0  0.0  ...  0.0   0.0   0.0   0.0  51.87281 -8.53436  18700.0  82.0   \n","1070   0.0  0.0  ...  0.0   0.0   0.0   0.0  51.88714 -8.56911  18700.0  82.0   \n","1121   0.0  0.0  ...  0.0   0.0   0.0   0.0  51.88714 -8.56911  18700.0  82.0   \n","\n","      sun        pred  \n","50    1.0  145.733780  \n","101   1.0  172.166779  \n","152   1.0  105.440735  \n","203   1.0  216.807755  \n","254   1.0  373.806976  \n","305   1.0  144.187057  \n","356   1.0  186.561920  \n","407   1.0  340.341400  \n","458   1.0  134.249832  \n","509   1.0  197.278030  \n","560   1.0  108.726418  \n","611   1.0   95.776863  \n","662   1.0  151.429123  \n","713   1.0  153.904678  \n","764   1.0  273.437225  \n","815   1.0  193.826828  \n","866   1.0  197.185074  \n","917   1.0  214.554398  \n","968   1.0  185.038483  \n","1019  1.0  156.419006  \n","1070  1.0   84.833778  \n","1121  1.0   65.909729  \n","\n","[22 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-f584552d-2b63-4439-8423-3d26b4375890\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>datetime</th>\n","      <th>value</th>\n","      <th>20223</th>\n","      <th>GL1</th>\n","      <th>1255</th>\n","      <th>1405</th>\n","      <th>1404</th>\n","      <th>1403</th>\n","      <th>GL2</th>\n","      <th>...</th>\n","      <th>GL3</th>\n","      <th>1283</th>\n","      <th>1258</th>\n","      <th>1256</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>vis</th>\n","      <th>rhum</th>\n","      <th>sun</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>50</th>\n","      <td>000000001253A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>168.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>145.733780</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>000000001253B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>187.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87488</td>\n","      <td>-8.44783</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>172.166779</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>000000001255A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>46.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87636</td>\n","      <td>-8.56072</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>105.440735</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>000000001255B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>81.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87636</td>\n","      <td>-8.56072</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>216.807755</td>\n","    </tr>\n","    <tr>\n","      <th>254</th>\n","      <td>000000001256A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>157.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>51.88825</td>\n","      <td>-8.39061</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>373.806976</td>\n","    </tr>\n","    <tr>\n","      <th>305</th>\n","      <td>000000001256B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>132.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>51.88825</td>\n","      <td>-8.39061</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>144.187057</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>000000001258A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>142.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>51.88229</td>\n","      <td>-8.40760</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>186.561920</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>000000001258B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>160.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>51.88229</td>\n","      <td>-8.40760</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>340.341400</td>\n","    </tr>\n","    <tr>\n","      <th>458</th>\n","      <td>000000001271A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>103.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.86242</td>\n","      <td>-8.47908</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>134.249832</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>000000001271B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>156.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.86242</td>\n","      <td>-8.47908</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>197.278030</td>\n","    </tr>\n","    <tr>\n","      <th>560</th>\n","      <td>000000001283A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>99.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87578</td>\n","      <td>-8.41266</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>108.726418</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>000000001283B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>85.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87578</td>\n","      <td>-8.41266</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>95.776863</td>\n","    </tr>\n","    <tr>\n","      <th>662</th>\n","      <td>000000001401A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>164.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87942</td>\n","      <td>-8.43249</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>151.429123</td>\n","    </tr>\n","    <tr>\n","      <th>713</th>\n","      <td>000000001401B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>133.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87942</td>\n","      <td>-8.43249</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>153.904678</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>000000001403A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>141.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87619</td>\n","      <td>-8.49964</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>273.437225</td>\n","    </tr>\n","    <tr>\n","      <th>815</th>\n","      <td>000000001403B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>136.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87619</td>\n","      <td>-8.49964</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>193.826828</td>\n","    </tr>\n","    <tr>\n","      <th>866</th>\n","      <td>000000001404A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>106.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87567</td>\n","      <td>-8.51047</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>197.185074</td>\n","    </tr>\n","    <tr>\n","      <th>917</th>\n","      <td>000000001404B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>109.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87567</td>\n","      <td>-8.51047</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>214.554398</td>\n","    </tr>\n","    <tr>\n","      <th>968</th>\n","      <td>000000001405A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>78.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87281</td>\n","      <td>-8.53436</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>185.038483</td>\n","    </tr>\n","    <tr>\n","      <th>1019</th>\n","      <td>000000001405B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>49.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.87281</td>\n","      <td>-8.53436</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>156.419006</td>\n","    </tr>\n","    <tr>\n","      <th>1070</th>\n","      <td>000000020223A</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>25.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>84.833778</td>\n","    </tr>\n","    <tr>\n","      <th>1121</th>\n","      <td>000000020223B</td>\n","      <td>2022-06-19 05:00:00</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>51.88714</td>\n","      <td>-8.56911</td>\n","      <td>18700.0</td>\n","      <td>82.0</td>\n","      <td>1.0</td>\n","      <td>65.909729</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>22 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f584552d-2b63-4439-8423-3d26b4375890')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f584552d-2b63-4439-8423-3d26b4375890 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f584552d-2b63-4439-8423-3d26b4375890');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import leafmap.foliumap as leafmap\n","\n","m = leafmap.Map(center=[51.872913, -8.477261], zoom=12.3, tiles='stamentoner')\n","m.add_heatmap(\n","    result,\n","    latitude=\"lat\",\n","    longitude='long',\n","    value=\"pred\",\n","    name=\"Heat map\",\n","    radius=20,\n",")\n","\n","# colors = ['blue', 'lime', 'red']\n","# vmin = result.pred.min()\n","# vmax = result.pred.max()\n","# m.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)\n","m.add_title(\"World Population Heat Map\", font_size=\"20px\", align=\"center\")\n","\n","m"],"metadata":{"id":"BIws1z8czfF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_demo_unscale.reshape(-1) - y_demo_unscale.reshape(-1)"],"metadata":{"id":"GxKVZVvund3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Design App"],"metadata":{"id":"jz2sfigRLg34"}},{"cell_type":"code","source":["%%writefile app.py\n","\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import leafmap.foliumap as leafmap\n","from time import sleep\n","df_demo = pd.read_csv(\"/content/drive/MyDrive/Khoá luận tốt nghiệp/Dataset/final_data_demo_17_6_21_6.csv\")\n","\n","list_id = ['000000001253A',\n"," '000000001253B',\n"," '000000001255A',\n"," '000000001255B',\n"," '000000001256A',\n"," '000000001256B',\n"," '000000001258A',\n"," '000000001258B',\n"," '000000001271A',\n"," '000000001271B',\n"," '000000001283A',\n"," '000000001283B',\n"," '000000001401A',\n"," '000000001401B',\n"," '000000001403A',\n"," '000000001403B',\n"," '000000001404A',\n"," '000000001404B',\n"," '000000001405A',\n"," '000000001405B',\n"," '000000020223A',\n"," '000000020223B']\n","\n","st.write(\"abcddfdf\")\n","for i in range(10):\n","  st.write(i)\n","  sleep(2)\n","submit = st.button('submit')\n","\n","# Initialization\n","if 'button_pressed' not in st.session_state:\n","    st.session_state['button_pressed'] = False\n","\n","# Changes if calculated button is pressed  \n","if submit:\n","    st.session_state['button_pressed'] = True\n","\n","# Conditional on session_state instead\n","if st.session_state['button_pressed']:\n","\n","  with st.empty():\n","    for i in range(60):\n","      df_demo_batch = pd.DataFrame()\n","      for id in list_id:\n","        df_filter = df_demo[df_demo['id'] == id].iloc[i:1+i,:]\n","        df_demo_batch = pd.concat([df_demo_batch, df_filter], ignore_index=True)\n","      m = leafmap.Map(center=[51.872913, -8.477261], zoom=12.3, tiles='stamentoner')\n","      m.add_heatmap(\n","          df_demo_batch,\n","          latitude=\"lat\",\n","          longitude='long',\n","          value=\"value\",\n","          name=\"Heat map\",\n","          radius=20,\n","      )\n","\n","\n","      m.add_title(f\"Current time:   {i} {i}\", font_size=\"20px\", align=\"left\")\n","      m.add_title(f\"Forecast time: {i} {i}\", font_size=\"20px\", align=\"left\")\n","\n","      with st.container():\n","        st.header('This is a header')\n","        m.to_streamlit(width=1000, height=600, responsive=True, scrolling=False, add_layer_control=False, bidirectional=False)\n","\n","        st.header(\"This is sefdf the container\")\n","        st.dataframe(df_demo_batch)\n","        \n","        st.header(\"This is sefdf the container\")\n","        st.dataframe(df_demo_batch)\n","\n","      sleep(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCvJ6u6GMzLH","executionInfo":{"status":"ok","timestamp":1659182538041,"user_tz":-420,"elapsed":650,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"}},"outputId":"a8e9fb71-9545-4056-fb9f-d8f63d2184de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"markdown","source":["# Run App"],"metadata":{"id":"xcGWyklwgOc9"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1JZD7DPXF29","outputId":"2b87f662-daa9-4721-a4a6-ebb5e0b4f2f5","executionInfo":{"status":"ok","timestamp":1659183910022,"user_tz":-420,"elapsed":121316,"user":{"displayName":"Phap Trinh Ngoc","userId":"14322905838532495488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["NgrokTunnel: \"http://5a90-34-124-174-248.ngrok.io\" -> \"http://localhost:80\"\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.124.174.248:80\u001b[0m\n","\u001b[0m\n","2022-07-30 12:23:42.966 Prepending /usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\n","Initializing orca context\n","Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n","Start to getOrCreate SparkContext\n","pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.0.0-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.0.0-jar-with-dependencies.jar pyspark-shell \n","[main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","[Thread-3] WARN  org.apache.spark.util.Utils  - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.11-2.4.6.jar) to method java.nio.Bits.unaligned()\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n","2022-07-30 12:24:03,946 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-07-30 12:24:03,949 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-07-30 12:24:03,951 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-07-30 12:24:03,952 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","22-07-30 12:24:03 [Thread-3] INFO  Engine$:121 - Auto detect executor number and executor cores number\n","22-07-30 12:24:03 [Thread-3] INFO  Engine$:123 - Executor number is 1 and executor cores number is 4\n","\n","User settings:\n","\n","   KMP_AFFINITY=granularity=fine,compact,1,0\n","   KMP_BLOCKTIME=0\n","   KMP_DUPLICATE_LIB_OK=True\n","   KMP_INIT_AT_FORK=FALSE\n","   KMP_SETTINGS=1\n","   OMP_NUM_THREADS=1\n","\n","Effective settings:\n","\n","   KMP_ABORT_DELAY=0\n","   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n","   KMP_ALIGN_ALLOC=64\n","   KMP_ALL_THREADPRIVATE=128\n","   KMP_ATOMIC_MODE=2\n","   KMP_BLOCKTIME=0\n","   KMP_CPUINFO_FILE: value is not defined\n","   KMP_DETERMINISTIC_REDUCTION=false\n","   KMP_DEVICE_THREAD_LIMIT=2147483647\n","   KMP_DISP_HAND_THREAD=false\n","   KMP_DISP_NUM_BUFFERS=7\n","   KMP_DUPLICATE_LIB_OK=true\n","   KMP_FORCE_REDUCTION: value is not defined\n","   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n","   KMP_FORKJOIN_BARRIER='2,2'\n","   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n","   KMP_FORKJOIN_FRAMES=true\n","   KMP_FORKJOIN_FRAMES_MODE=3\n","   KMP_GTID_MODE=3\n","   KMP_HANDLE_SIGNALS=false\n","   KMP_HOT_TEAMS_MAX_LEVEL=1\n","   KMP_HOT_TEAMS_MODE=0\n","   KMP_INIT_AT_FORK=true\n","   KMP_ITT_PREPARE_DELAY=0\n","   KMP_LIBRARY=throughput\n","   KMP_LOCK_KIND=queuing\n","   KMP_MALLOC_POOL_INCR=1M\n","   KMP_MWAIT_HINTS=0\n","   KMP_NUM_LOCKS_IN_BLOCK=1\n","   KMP_PLAIN_BARRIER='2,2'\n","   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n","   KMP_REDUCTION_BARRIER='1,1'\n","   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n","   KMP_SCHEDULE='static,balanced;guided,iterative'\n","   KMP_SETTINGS=true\n","   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n","   KMP_STACKOFFSET=64\n","   KMP_STACKPAD=0\n","   KMP_STACKSIZE=8M\n","   KMP_STORAGE_MAP=false\n","   KMP_TASKING=2\n","   KMP_TASKLOOP_MIN_TASKS=0\n","   KMP_TASK_STEALING_CONSTRAINT=1\n","   KMP_TEAMS_THREAD_LIMIT=2\n","   KMP_TOPOLOGY_METHOD=all\n","   KMP_USER_LEVEL_MWAIT=false\n","   KMP_USE_YIELD=1\n","   KMP_VERSION=false\n","   KMP_WARNINGS=true\n","   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n","   OMP_ALLOCATOR=omp_default_mem_alloc\n","   OMP_CANCELLATION=false\n","   OMP_DEBUG=disabled\n","   OMP_DEFAULT_DEVICE=0\n","   OMP_DISPLAY_AFFINITY=false\n","   OMP_DISPLAY_ENV=false\n","   OMP_DYNAMIC=false\n","   OMP_MAX_ACTIVE_LEVELS=2147483647\n","   OMP_MAX_TASK_PRIORITY=0\n","   OMP_NESTED=false\n","   OMP_NUM_THREADS='1'\n","   OMP_PLACES: value is not defined\n","   OMP_PROC_BIND='intel'\n","   OMP_SCHEDULE='static'\n","   OMP_STACKSIZE=8M\n","   OMP_TARGET_OFFLOAD=DEFAULT\n","   OMP_THREAD_LIMIT=2147483647\n","   OMP_TOOL=enabled\n","   OMP_TOOL_LIBRARIES: value is not defined\n","   OMP_WAIT_POLICY=PASSIVE\n","   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n","\n","22-07-30 12:24:04 [Thread-3] INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 16\n","[Thread-3] WARN  org.apache.spark.SparkContext  - Using an existing SparkContext; some configuration may not take effect.\n","22-07-30 12:24:04 [Thread-3] INFO  Engine$:446 - Find existing spark context. Checking the spark conf...\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.Sample\n","BigDLBasePickler registering: bigdl.dllib.utils.common  Sample\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.EvaluatedResult\n","BigDLBasePickler registering: bigdl.dllib.utils.common  EvaluatedResult\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JTensor\n","BigDLBasePickler registering: bigdl.dllib.utils.common  JTensor\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JActivity\n","BigDLBasePickler registering: bigdl.dllib.utils.common  JActivity\n","Successfully got a SparkContext\n","2022-07-30 12:24:05.049 Failed to set SIGTERM handler, processes mightnot be cleaned up properly on exit.\n","2022-07-30 12:24:08,246\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n","{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-07-30_12-24-05_085527_772/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-30_12-24-05_085527_772/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-07-30_12-24-05_085527_772', 'metrics_export_port': 56826, 'node_id': '170ccc81a36d37e9c3130e8cd13609f49a4dd30a7b1eb678127f26e7'}\n","2022-07-30 12:24:16.691 Global seed set to 17\n","Current - rmse: 121.68792863825587\tsmape: 0.21307325835257448\n","[225.41191101 205.02703857  99.65496063  56.92583847 147.240448\n"," 123.22531891 160.87075806 149.25160217  43.92776108  13.27688313\n","  94.44584656  81.64414978 138.67526245 176.75830078 140.36550903\n"," 193.04351807 183.79420471 111.37934113  71.6651535  113.63848877\n","  53.57184601  35.89027786]\n","[140.9793396  129.28567505  58.71998978  30.84440804  44.72618484\n","  85.66932678 134.87071228  76.38288879  41.22337341  19.11067772\n","  73.89661407  47.57675552  62.22636414 106.88049316  85.33971405\n"," 124.65931702  98.73029327  62.69411469  55.63476944  58.43251801\n","  64.42237091  40.2940979 ]\n","[126.2676239  173.60015869  17.71733284  72.09815979 135.34991455\n","  59.46630096 114.59092712 155.69155884  71.78421021 123.79088593\n","  74.00282288  36.0815773  137.08821106 110.47071838 181.94720459\n","  66.01079559  54.46644592 149.86352539  99.45549011  11.41968727\n","  50.95471573  32.18053055]\n","[145.73377991 172.16677856 105.44076538 216.80809021 373.80703735\n"," 144.18699646 186.56192017 340.34143066 134.24980164 197.27799988\n"," 108.72638702  95.77692413 151.42909241 153.90461731 273.43734741\n"," 193.826828   197.18516541 214.55436707 185.03851318 156.4190979\n","  84.83383942  65.90975952]\n","[187.67503357 333.60238647  80.90969849 182.75428772 234.31312561\n"," 243.70463562 237.25706482 275.36584473 146.64778137 168.06315613\n"," 174.4163208   50.99004745 284.45013428 154.53912354 238.67127991\n"," 163.44810486 118.55947876 183.8870697  140.40435791  73.88896942\n"," 106.10575867  78.13666534]\n","2022-07-30 12:25:02,409\tERROR worker.py:1247 -- listen_error_messages_raylet: Connection closed by server.\n","2022-07-30 12:25:02,411\tERROR worker.py:478 -- print_logs: Connection closed by server.\n","2022-07-30 12:25:02,411\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n","\u001b[34m  Stopping...\u001b[0m\n","\u001b[34m  Stopping...\u001b[0m\n","\u001b[0mStopping orca context\n"]}],"source":["from pyngrok import ngrok\n","ngrok.set_auth_token(\"2AmJisrnaxPzbUIbd3wBsboq4TJ_5NKxMJqNdMHTSJzN6RWKi\") #phap\n","# ngrok.set_auth_token(\"2B3iiliqK9Am9l2P7Nd2n1cr3iz_zLr4PBzMofF7Z8fiTfXK\")  #khoa\n","public_url = ngrok.connect(port='80')\n","print(public_url)\n","\n","!streamlit run --theme.base \"light\" --server.port 80 app.py"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DemoStreamlit.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}