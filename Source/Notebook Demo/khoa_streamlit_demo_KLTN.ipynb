{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57726,"status":"ok","timestamp":1659488926032,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"},"user_tz":-420},"id":"yrr9nqTkVUX1","outputId":"99fe099b-1e66-46a1-ec1a-bfcdf04655dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"N1hE2Vr2gTlI"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":50557,"status":"ok","timestamp":1659488981954,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"},"user_tz":-420},"id":"I2SpdjEaQtvL","outputId":"f3b64844-d4e0-4a66-fe6f-ccc75f46bd6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting streamlit\n","  Downloading streamlit-1.11.1-py2.py3-none-any.whl (9.1 MB)\n","\u001b[K     |████████████████████████████████| 9.1 MB 20.6 MB/s \n","\u001b[?25hCollecting watchdog\n","  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: altair\u003e=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n","Requirement already satisfied: pandas\u003e=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n","Collecting pydeck\u003e=0.1.dev5\n","  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 44.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.6)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.13.0)\n","Requirement already satisfied: protobuf\u003c4,\u003e=3.12 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n","Requirement already satisfied: tzlocal\u003e=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n","Requirement already satisfied: attrs\u003e=16.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (22.1.0)\n","Collecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging\u003e=14.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n","Collecting pympler\u003e=0.9\n","  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 63.5 MB/s \n","\u001b[?25hRequirement already satisfied: cachetools\u003e=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n","Requirement already satisfied: importlib-metadata\u003e=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.12.0)\n","Requirement already satisfied: tornado\u003e=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n","Requirement already satisfied: requests\u003e=2.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n","Collecting rich\u003e=10.11.0\n","  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 76.1 MB/s \n","\u001b[?25hRequirement already satisfied: click\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Collecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions\u003e=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.1)\n","Collecting blinker\u003e=1.0.0\n","  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: pyarrow\u003e=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Collecting validators\u003e=0.2\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair\u003e=3.2.0-\u003estreamlit) (0.12.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair\u003e=3.2.0-\u003estreamlit) (0.4)\n","Requirement already satisfied: jsonschema\u003e=3.0 in /usr/local/lib/python3.7/dist-packages (from altair\u003e=3.2.0-\u003estreamlit) (4.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair\u003e=3.2.0-\u003estreamlit) (2.11.3)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap\u003c6,\u003e=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=1.4-\u003estreamlit) (3.8.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,\u003e=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003e=3.2.0-\u003estreamlit) (0.18.1)\n","Requirement already satisfied: importlib-resources\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003e=3.2.0-\u003estreamlit) (5.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=14.1-\u003estreamlit) (3.0.9)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.21.0-\u003estreamlit) (2022.1)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf\u003c4,\u003e=3.12-\u003estreamlit) (1.15.0)\n","Requirement already satisfied: ipywidgets\u003e=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck\u003e=0.1.dev5-\u003estreamlit) (7.7.1)\n","Collecting ipykernel\u003e=5.1.2\n","  Downloading ipykernel-6.15.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 74.8 MB/s \n","\u001b[?25hRequirement already satisfied: traitlets\u003e=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck\u003e=0.1.dev5-\u003estreamlit) (5.1.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (1.5.5)\n","Collecting ipython\u003e=7.23.1\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib-inline\u003e=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.1.3)\n","Collecting jupyter-client\u003e=6.1.12\n","  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 75.9 MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (5.4.8)\n","Requirement already satisfied: pyzmq\u003e=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (23.2.0)\n","Collecting tornado\u003e=5.0\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: debugpy\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (1.0.0)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.2.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0\n","  Downloading prompt_toolkit-3.0.30-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 69.8 MB/s \n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.7.5)\n","Requirement already satisfied: jedi\u003e=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.18.1)\n","Requirement already satisfied: setuptools\u003e=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (57.4.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (3.6.1)\n","Requirement already satisfied: jupyterlab-widgets\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (1.1.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.2.0)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi\u003e=0.16-\u003eipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.8.3)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-\u003ealtair\u003e=3.2.0-\u003estreamlit) (2.0.1)\n","Requirement already satisfied: jupyter-core\u003e=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client\u003e=6.1.12-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (4.11.1)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect\u003e4.3-\u003eipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0-\u003eipython\u003e=7.23.1-\u003eipykernel\u003e=5.1.2-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.2.5)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.4-\u003estreamlit) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.4-\u003estreamlit) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.4-\u003estreamlit) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.4-\u003estreamlit) (1.24.3)\n","Collecting commonmark\u003c0.10.0,\u003e=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: notebook\u003e=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (5.6.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (5.4.0)\n","Requirement already satisfied: terminado\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (1.8.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.6.0)\n","Requirement already satisfied: mistune\u003c2,\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.7.1)\n","Requirement already satisfied: pandocfilters\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (1.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (5.0.1)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (2.16.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach-\u003enbconvert-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets\u003e=7.0.0-\u003epydeck\u003e=0.1.dev5-\u003estreamlit) (0.5.1)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=4f954e592d6343145740ad6d2716ff0cc731faaedca95aa230140685772e4de3\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel, smmap, gitdb, commonmark, watchdog, validators, toml, rich, pympler, pydeck, gitpython, blinker, streamlit\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 5.3.5\n","    Uninstalling jupyter-client-5.3.5:\n","      Successfully uninstalled jupyter-client-5.3.5\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","nbclient 0.6.6 requires traitlets\u003e=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit\u003c2.0.0,\u003e=1.0.0, but you have prompt-toolkit 3.0.30 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n","Successfully installed blinker-1.5 commonmark-0.9.1 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.15.1 ipython-7.34.0 jupyter-client-7.3.4 prompt-toolkit-3.0.30 pydeck-0.7.1 pympler-1.0.1 rich-12.5.1 smmap-5.0.0 streamlit-1.11.1 toml-0.10.2 tornado-6.2 validators-0.20.0 watchdog-2.1.9\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit","tornado"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 31.5 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=2dd146e9a35a7e1990010ab4c968c344c6ab0139042bfbcecaa29ab3a4448574\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting leafmap\n","  Downloading leafmap-0.10.3-py2.py3-none-any.whl (161 kB)\n","\u001b[K     |████████████████████████████████| 161 kB 37.9 MB/s \n","\u001b[?25hCollecting jupyterlab\u003e=3.0.0\n","  Downloading jupyterlab-3.4.4-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 56.8 MB/s \n","\u001b[?25hCollecting ipyevents\n","  Downloading ipyevents-2.0.1-py2.py3-none-any.whl (130 kB)\n","\u001b[K     |████████████████████████████████| 130 kB 72.6 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from leafmap) (3.2.2)\n","Collecting ipyleaflet\u003e=0.17.0\n","  Downloading ipyleaflet-0.17.0-py2.py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 53.6 MB/s \n","\u001b[?25hCollecting ipysheet\n","  Downloading ipysheet-0.5.0-py2.py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 65.1 MB/s \n","\u001b[?25hCollecting xyzservices\n","  Downloading xyzservices-2022.6.0-py3-none-any.whl (36 kB)\n","Collecting pycrs\n","  Downloading PyCRS-1.0.2.tar.gz (36 kB)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from leafmap) (4.4.0)\n","Collecting scooby\n","  Downloading scooby-0.6.0-py3-none-any.whl (14 kB)\n","Collecting whiteboxgui\u003e=0.6.0\n","  Downloading whiteboxgui-0.7.0-py2.py3-none-any.whl (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 10.7 MB/s \n","\u001b[?25hCollecting geojson\n","  Downloading geojson-2.5.0-py2.py3-none-any.whl (14 kB)\n","Collecting ipyfilechooser\u003e=0.6.0\n","  Downloading ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from leafmap) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from leafmap) (1.21.6)\n","Collecting pyshp\u003e=2.1.3\n","  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: folium\u003e=0.11.0 in /usr/local/lib/python3.7/dist-packages (from leafmap) (0.12.1.post1)\n","Collecting bqplot\n","  Downloading bqplot-0.12.33-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 76.0 MB/s \n","\u001b[?25hCollecting pystac-client\n","  Downloading pystac_client-0.4.0-py3-none-any.whl (24 kB)\n","Collecting python-box\n","  Downloading python_box-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 73.5 MB/s \n","\u001b[?25hCollecting colour\n","  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium\u003e=0.11.0-\u003eleafmap) (2.23.0)\n","Requirement already satisfied: branca\u003e=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium\u003e=0.11.0-\u003eleafmap) (0.5.0)\n","Requirement already satisfied: jinja2\u003e=2.9 in /usr/local/lib/python3.7/dist-packages (from folium\u003e=0.11.0-\u003eleafmap) (2.11.3)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from ipyfilechooser\u003e=0.6.0-\u003eleafmap) (7.7.1)\n","Collecting traittypes\u003c3,\u003e=0.2.1\n","  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (3.6.1)\n","Requirement already satisfied: jupyterlab-widgets\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (1.1.1)\n","Requirement already satisfied: traitlets\u003e=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (5.1.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.2.0)\n","Requirement already satisfied: ipykernel\u003e=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (6.15.1)\n","Requirement already satisfied: ipython\u003e=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (7.34.0)\n","Requirement already satisfied: matplotlib-inline\u003e=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.1.3)\n","Requirement already satisfied: debugpy\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (1.0.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (1.5.5)\n","Requirement already satisfied: jupyter-client\u003e=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (7.3.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (21.3)\n","Requirement already satisfied: pyzmq\u003e=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (23.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (5.4.8)\n","Requirement already satisfied: tornado\u003e=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (6.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.7.5)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (4.4.2)\n","Requirement already satisfied: setuptools\u003e=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (57.4.0)\n","Requirement already satisfied: jedi\u003e=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.18.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (3.0.30)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.2.0)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi\u003e=0.16-\u003eipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.8.3)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2\u003e=2.9-\u003efolium\u003e=0.11.0-\u003eleafmap) (2.0.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client\u003e=6.1.12-\u003eipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.4)\n","Requirement already satisfied: jupyter-core\u003e=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client\u003e=6.1.12-\u003eipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (4.11.1)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client\u003e=6.1.12-\u003eipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (2.8.2)\n","Collecting jupyterlab-server~=2.10\n","  Downloading jupyterlab_server-2.15.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s \n","\u001b[?25hCollecting jupyter-server~=1.16\n","  Downloading jupyter_server-1.18.1-py3-none-any.whl (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 71.0 MB/s \n","\u001b[?25hRequirement already satisfied: notebook\u003c7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab\u003e=3.0.0-\u003eleafmap) (5.3.1)\n","Collecting nbclassic\n","  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 52.6 MB/s \n","\u001b[?25hCollecting nbconvert\u003e=6.4.4\n","  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n","\u001b[K     |████████████████████████████████| 561 kB 65.7 MB/s \n","\u001b[?25hCollecting websocket-client\n","  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n","\u001b[?25hCollecting anyio\u003c4,\u003e=3.1.0\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s \n","\u001b[?25hRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (21.3.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.14.1)\n","Requirement already satisfied: terminado\u003e=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (1.8.0)\n","Requirement already satisfied: nbformat\u003e=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (5.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio\u003c4,\u003e=3.1.0-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (4.1.1)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio\u003c4,\u003e=3.1.0-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (2.10)\n","Collecting sniffio\u003e=1.1\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Collecting json5\n","  Downloading json5-0.9.9-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (2.10.3)\n","Collecting jinja2\u003e=2.9\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 77.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata\u003e=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (4.12.0)\n","Requirement already satisfied: jsonschema\u003e=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (4.3.3)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=3.6-\u003ejupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (3.8.1)\n","Requirement already satisfied: importlib-resources\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema\u003e=3.0.1-\u003ejupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,\u003e=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema\u003e=3.0.1-\u003ejupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.18.1)\n","Requirement already satisfied: attrs\u003e=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema\u003e=3.0.1-\u003ejupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (22.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (4.6.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.7.1)\n","Requirement already satisfied: nbclient\u003e=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.6.6)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (1.1.1)\n","Requirement already satisfied: mistune\u003c2,\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (5.0.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.2.2)\n","Requirement already satisfied: pandocfilters\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (1.5.0)\n","Collecting traitlets\u003e=4.3.1\n","  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 77.4 MB/s \n","\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat\u003e=5.2.0-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (2.16.1)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect\u003e4.3-\u003eipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0-\u003eipython\u003e=4.0.0-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (0.2.5)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.8.2-\u003ejupyter-client\u003e=6.1.12-\u003eipykernel\u003e=4.5.1-\u003eipywidgets-\u003eipyfilechooser\u003e=0.6.0-\u003eleafmap) (1.15.0)\n","Collecting ipytree\n","  Downloading ipytree-0.2.1-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 64.7 MB/s \n","\u001b[?25hCollecting whitebox\n","  Downloading whitebox-2.1.4-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (21.2.0)\n","Requirement already satisfied: cffi\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings-\u003eargon2-cffi-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi\u003e=1.0.1-\u003eargon2-cffi-bindings-\u003eargon2-cffi-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (2.21)\n","Requirement already satisfied: pytz\u003e=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel-\u003ejupyterlab-server~=2.10-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (2022.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach-\u003enbconvert\u003e=6.4.4-\u003ejupyter-server~=1.16-\u003ejupyterlab\u003e=3.0.0-\u003eleafmap) (0.5.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown-\u003eleafmap) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown-\u003eleafmap) (3.7.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eleafmap) (3.0.9)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eleafmap) (1.4.4)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eleafmap) (0.11.0)\n","Collecting notebook-shim\u003e=0.1.0\n","  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n","\u001b[?25hCollecting pystac\u003e=1.4.0\n","  Downloading pystac-1.5.0-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 76.7 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c3,\u003e=2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efolium\u003e=0.11.0-\u003eleafmap) (2.1.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efolium\u003e=0.11.0-\u003eleafmap) (2022.6.15)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efolium\u003e=0.11.0-\u003eleafmap) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,\u003e=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efolium\u003e=0.11.0-\u003eleafmap) (1.7.1)\n","Requirement already satisfied: Click\u003e=6.0 in /usr/local/lib/python3.7/dist-packages (from whitebox-\u003ewhiteboxgui\u003e=0.6.0-\u003eleafmap) (7.1.2)\n","Building wheels for collected packages: pycrs\n","  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycrs: filename=PyCRS-1.0.2-py3-none-any.whl size=32704 sha256=c86516f997401f55e58bc6b3beb06d8eeb288012ee8bc5fd8b9b2a8235af3eaa\n","  Stored in directory: /root/.cache/pip/wheels/3e/ce/32/1ec0aba6b9770681a423e82f0274c57d09ad2c20c2864901f9\n","Successfully built pycrs\n","Installing collected packages: traitlets, jinja2, sniffio, nbconvert, websocket-client, anyio, jupyter-server, requests, notebook-shim, json5, xyzservices, whitebox, traittypes, pystac, nbclassic, jupyterlab-server, ipytree, ipyfilechooser, whiteboxgui, scooby, python-box, pystac-client, pyshp, pycrs, jupyterlab, ipysheet, ipyleaflet, ipyevents, geojson, colour, bqplot, leafmap\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.1.1\n","    Uninstalling traitlets-5.1.1:\n","      Successfully uninstalled traitlets-5.1.1\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: nbconvert\n","    Found existing installation: nbconvert 5.6.1\n","    Uninstalling nbconvert-5.6.1:\n","      Successfully uninstalled nbconvert-5.6.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n","flask 1.1.4 requires Jinja2\u003c3.0,\u003e=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n","Successfully installed anyio-3.6.1 bqplot-0.12.33 colour-0.1.5 geojson-2.5.0 ipyevents-2.0.1 ipyfilechooser-0.6.0 ipyleaflet-0.17.0 ipysheet-0.5.0 ipytree-0.2.1 jinja2-3.1.2 json5-0.9.9 jupyter-server-1.18.1 jupyterlab-3.4.4 jupyterlab-server-2.15.0 leafmap-0.10.3 nbclassic-0.4.3 nbconvert-6.5.0 notebook-shim-0.1.0 pycrs-1.0.2 pyshp-2.3.1 pystac-1.5.0 pystac-client-0.4.0 python-box-6.0.2 requests-2.28.1 scooby-0.6.0 sniffio-1.2.0 traitlets-5.3.0 traittypes-0.2.1 websocket-client-1.3.3 whitebox-2.1.4 whiteboxgui-0.7.0 xyzservices-2022.6.0\n"]}],"source":["!pip install streamlit\n","!pip install pyngrok\n","!pip install leafmap"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":221347,"status":"ok","timestamp":1659489203284,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"},"user_tz":-420},"id":"7J1yoxr1gjmu","outputId":"26136280-c999-4691-83b8-b439acb4016f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bigdl-chronos[all]==2.0.0\n","  Downloading bigdl_chronos-2.0.0-py3-none-manylinux1_x86_64.whl (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 17.9 MB/s \n","\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from bigdl-chronos[all]==2.0.0) (0.10.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bigdl-chronos[all]==2.0.0) (1.0.2)\n","Collecting pandas\u003c1.3.0,\u003e=1.0.5\n","  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 63.8 MB/s \n","\u001b[?25hCollecting bigdl-nano[pytorch]\n","  Downloading bigdl_nano-2.0.0-py3-none-manylinux2010_x86_64.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n","\u001b[?25hCollecting bigdl-orca==2.0.0\n","  Downloading bigdl_orca-2.0.0-py3-none-manylinux1_x86_64.whl (23.9 MB)\n","\u001b[K     |████████████████████████████████| 23.9 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (21.3)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (23.2.0)\n","Collecting conda-pack==0.3.1\n","  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n","Collecting bigdl-dllib==2.0.0\n","  Downloading bigdl_dllib-2.0.0-py3-none-manylinux1_x86_64.whl (101.0 MB)\n","\u001b[K     |████████████████████████████████| 101.0 MB 38 kB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.7.1)\n","Collecting bigdl-math==2.0.0\n","  Downloading bigdl_math-2.0.0-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n","\u001b[K     |████████████████████████████████| 35.4 MB 488 kB/s \n","\u001b[?25hCollecting bigdl-tf==2.0.0\n","  Downloading bigdl_tf-2.0.0-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n","\u001b[K     |████████████████████████████████| 71.0 MB 73.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.0.0-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.21.6)\n","Collecting pyspark==2.4.6\n","  Downloading pyspark-2.4.6.tar.gz (218.4 MB)\n","\u001b[K     |████████████████████████████████| 218.4 MB 61 kB/s \n","\u001b[?25hRequirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.0.0-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.15.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (5.4.8)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.8.1)\n","Collecting hiredis==2.0.0\n","  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.6 MB/s \n","\u001b[?25hCollecting aioredis==1.3.1\n","  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from bigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (2.8.0)\n","Collecting ray[default]==1.9.2\n","  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n","\u001b[K     |████████████████████████████████| 57.6 MB 1.2 MB/s \n","\u001b[?25hCollecting async-timeout==4.0.1\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.7.2)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (22.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.13.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (6.0.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.3.0)\n","Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (4.1.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (57.4.0)\n","Collecting py4j==0.10.7\n","  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n","\u001b[K     |████████████████████████████████| 197 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio\u003e=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.47.0)\n","Requirement already satisfied: protobuf\u003e=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.17.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (4.3.3)\n","Requirement already satisfied: click\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (7.1.2)\n","Requirement already satisfied: msgpack\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.0.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.13)\n","Collecting redis\u003e=3.5.0\n","  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n","\u001b[K     |████████████████████████████████| 246 kB 73.2 MB/s \n","\u001b[?25hCollecting colorful\n","  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n","\u001b[K     |████████████████████████████████| 201 kB 79.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (2.28.1)\n","Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (5.2.1)\n","Collecting py-spy\u003e=0.2.0\n","  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 59.5 MB/s \n","\u001b[?25hCollecting aiohttp-cors\n","  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Collecting opencensus\n","  Downloading opencensus-0.10.0-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 78.8 MB/s \n","\u001b[?25hRequirement already satisfied: prometheus-client\u003e=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.14.1)\n","Collecting gpustat\u003e=1.0.0b1\n","  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 10.1 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.8.10)\n","Collecting tensorboardX\u003e=1.9\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 59.9 MB/s \n","\u001b[?25hCollecting nvidia-ml-py\u003c=11.495.46,\u003e=11.450.129\n","  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n","Collecting psutil\n","  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[K     |████████████████████████████████| 281 kB 71.5 MB/s \n","\u001b[?25hCollecting blessed\u003e=1.17.1\n","  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth\u003e=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed\u003e=1.17.1-\u003egpustat\u003e=1.0.0b1-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.2.5)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003c1.3.0,\u003e=1.0.5-\u003ebigdl-chronos[all]==2.0.0) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003c1.3.0,\u003e=1.0.5-\u003ebigdl-chronos[all]==2.0.0) (2022.1)\n","Requirement already satisfied: importlib-metadata\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from redis\u003e=3.5.0-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (4.12.0)\n","Collecting deprecated\u003e=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting redis\u003e=3.5.0\n","  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n","\u001b[K     |████████████████████████████████| 244 kB 77.7 MB/s \n","\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n","\u001b[K     |████████████████████████████████| 244 kB 77.0 MB/s \n","\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 81.4 MB/s \n","\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 79.9 MB/s \n","\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 71.4 MB/s \n","\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 79.4 MB/s \n","\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 79.2 MB/s \n","\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 75.0 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt\u003c2,\u003e=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated\u003e=1.2.3-\u003eredis\u003e=3.5.0-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.14.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=1.0-\u003eredis\u003e=3.5.0-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.0.9)\n","Requirement already satisfied: idna\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl\u003c2.0,\u003e=1.0-\u003eaiohttp==3.8.1-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (2.10)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from bigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (2022.1.0)\n","Collecting pytorch-lightning==1.4.2\n","  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n","\u001b[K     |████████████████████████████████| 916 kB 67.9 MB/s \n","\u001b[?25hCollecting onnx\n","  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 66.5 MB/s \n","\u001b[?25hCollecting PyTurboJPEG\n","  Downloading PyTurboJPEG-1.6.7.tar.gz (11 kB)\n","Collecting opencv-transforms\n","  Downloading opencv_transforms-0.0.6-py3-none-any.whl (18 kB)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n","\u001b[?25hCollecting onnxruntime\n","  Downloading onnxruntime-1.12.0-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 44.4 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from bigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (4.6.0.66)\n","Collecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 63.2 MB/s \n","\u001b[?25hCollecting torchmetrics\u003e=0.4.0\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 72.8 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Collecting future\u003e=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.4.2-\u003ebigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (4.64.0)\n","Collecting fsspec[http]!=2021.06.0,\u003e=2021.05.0\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 66.7 MB/s \n","\u001b[?25hRequirement already satisfied: pillow\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0-\u003ebigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (7.1.2)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.35.0)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.6.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.4.1)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.2.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.8.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (4.9)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.3.1)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.4.8)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (2022.6.15)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (3.2.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,\u003e=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (0.18.1)\n","Requirement already satisfied: importlib-resources\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (5.9.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime-\u003ebigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (2.0)\n","Collecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime-\u003ebigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (1.7.1)\n","Collecting humanfriendly\u003e=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-core\u003c3.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.31.6)\n","Collecting opencensus-context\u003e=0.1.2\n","  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c3.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]==1.9.2-\u003ebigdl-orca==2.0.0-\u003ebigdl-chronos[all]==2.0.0) (1.56.4)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003ebigdl-chronos[all]==2.0.0) (1.1.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003ebigdl-chronos[all]==2.0.0) (3.1.0)\n","Requirement already satisfied: scipy\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003ebigdl-chronos[all]==2.0.0) (1.7.3)\n","Requirement already satisfied: patsy\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels-\u003ebigdl-chronos[all]==2.0.0) (0.5.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy-\u003eonnxruntime-\u003ebigdl-nano[pytorch]-\u003ebigdl-chronos[all]==2.0.0) (1.2.1)\n","Building wheels for collected packages: pyspark, gpustat, future, PyTurboJPEG\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814407 sha256=1a154d2bfa67a598ccf23e51b83f2af57e13dc0e1e53f6e291eb41432abc25e3\n","  Stored in directory: /root/.cache/pip/wheels/f1/42/b0/ba397759613f4feb1611021a2503e60e344e546671b2ae04f8\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=feae5e7248d248123807680b62fa0246b78b64637c33b6543662d0c5a62256a1\n","  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=a1218c57b6e16504708f46d85f87bebac40bfd73f2dab30e54274caad9e2d72f\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.6.7-py3-none-any.whl size=12168 sha256=eab2ede055ed4088790e46658e39de9c6831981e921d4960424ceabee9ec0260\n","  Stored in directory: /root/.cache/pip/wheels/71/d6/9a/cce1808661c049dc4b55b3f41001198dd0efd979cb43833f89\n","Successfully built pyspark gpustat future PyTurboJPEG\n","Installing collected packages: async-timeout, torch, py4j, humanfriendly, fsspec, deprecated, torchmetrics, redis, pyyaml, pyspark, pyDeprecate, psutil, opencensus-context, nvidia-ml-py, hiredis, future, coloredlogs, blessed, torchvision, tensorboardX, ray, PyTurboJPEG, pytorch-lightning, py-spy, pandas, opencv-transforms, opencensus, onnxruntime, onnx, gpustat, conda-pack, colorful, bigdl-tf, bigdl-nano, bigdl-math, bigdl-dllib, aioredis, aiohttp-cors, setproctitle, bigdl-orca, bigdl-chronos\n","  Attempting uninstall: async-timeout\n","    Found existing installation: async-timeout 4.0.2\n","    Uninstalling async-timeout-4.0.2:\n","      Successfully uninstalled async-timeout-4.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.0+cu113\n","    Uninstalling torchvision-0.13.0+cu113:\n","      Successfully uninstalled torchvision-0.13.0+cu113\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n","Successfully installed PyTurboJPEG-1.6.7 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-4.0.1 bigdl-chronos-2.0.0 bigdl-dllib-2.0.0 bigdl-math-2.0.0 bigdl-nano-2.0.0 bigdl-orca-2.0.0 bigdl-tf-2.0.0 blessed-1.19.1 coloredlogs-15.0.1 colorful-0.5.4 conda-pack-0.3.1 deprecated-1.2.13 fsspec-2022.7.1 future-0.18.2 gpustat-1.0.0rc1 hiredis-2.0.0 humanfriendly-10.0 nvidia-ml-py-11.495.46 onnx-1.12.0 onnxruntime-1.12.0 opencensus-0.10.0 opencensus-context-0.1.2 opencv-transforms-0.0.6 pandas-1.2.5 psutil-5.9.1 py-spy-0.3.12 py4j-0.10.7 pyDeprecate-0.3.1 pyspark-2.4.6 pytorch-lightning-1.4.2 pyyaml-6.0 ray-1.9.2 redis-4.1.4 setproctitle-1.3.0 tensorboardX-2.5.1 torch-1.9.0 torchmetrics-0.9.3 torchvision-0.10.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Found existing installation: torchtext 0.13.0\n","Uninstalling torchtext-0.13.0:\n","  Successfully uninstalled torchtext-0.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics==0.7.3\n","  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n","\u001b[K     |████████████████████████████████| 398 kB 31.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (21.3)\n","Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (0.3.1)\n","Requirement already satisfied: torch\u003e=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.7.3) (1.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.3.1-\u003etorchmetrics==0.7.3) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etorchmetrics==0.7.3) (3.0.9)\n","Installing collected packages: torchmetrics\n","  Attempting uninstall: torchmetrics\n","    Found existing installation: torchmetrics 0.9.3\n","    Uninstalling torchmetrics-0.9.3:\n","      Successfully uninstalled torchmetrics-0.9.3\n","Successfully installed torchmetrics-0.7.3\n"]}],"source":["# Install latest pre-release version of bigdl-chronos \n","# Installing bigdl-chronos from pip will automatically install pyspark, bigdl, and their dependencies.\n","# !pip install --pre --upgrade bigdl-chronos[all]\n","!pip install bigdl-chronos[all]==2.0.0\n","!pip uninstall -y torchtext # uninstall torchtext to avoid version conflict\n","!pip install torchmetrics==0.7.3\n","exit() # restart the runtime to refresh installed pkg"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":623,"status":"ok","timestamp":1659489354558,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"},"user_tz":-420},"id":"d7K9LGUAvIpV","outputId":"722e403f-91b9-41a7-d9e7-1c4550f7c916"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\n"]}],"source":["%%writefile /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\n","# Copyright The PyTorch Lightning team.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"Trainer to automate the training.\"\"\"\n","import logging\n","import os\n","import traceback\n","import warnings\n","from datetime import timedelta\n","from pathlib import Path\n","from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n","from weakref import proxy\n","\n","import torch\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.accelerators import Accelerator, IPUAccelerator\n","from pytorch_lightning.callbacks import Callback\n","from pytorch_lightning.core.datamodule import LightningDataModule\n","from pytorch_lightning.core.memory import ModelSummary\n","from pytorch_lightning.loggers import LightningLoggerBase\n","from pytorch_lightning.loops import TrainingBatchLoop, TrainingEpochLoop\n","from pytorch_lightning.loops.dataloader.evaluation_loop import EvaluationLoop\n","from pytorch_lightning.loops.dataloader.prediction_loop import PredictionLoop\n","from pytorch_lightning.loops.fit_loop import FitLoop\n","from pytorch_lightning.plugins import Plugin\n","from pytorch_lightning.plugins.environments import ClusterEnvironment\n","from pytorch_lightning.profiler import (\n","    AdvancedProfiler,\n","    BaseProfiler,\n","    PassThroughProfiler,\n","    PyTorchProfiler,\n","    SimpleProfiler,\n","    XLAProfiler,\n",")\n","from pytorch_lightning.trainer.callback_hook import TrainerCallbackHookMixin\n","from pytorch_lightning.trainer.configuration_validator import ConfigValidator\n","from pytorch_lightning.trainer.connectors.accelerator_connector import AcceleratorConnector\n","from pytorch_lightning.trainer.connectors.callback_connector import CallbackConnector\n","from pytorch_lightning.trainer.connectors.checkpoint_connector import CheckpointConnector\n","from pytorch_lightning.trainer.connectors.data_connector import DataConnector\n","from pytorch_lightning.trainer.connectors.debugging_connector import DebuggingConnector\n","from pytorch_lightning.trainer.connectors.env_vars_connector import _defaults_from_env_vars\n","from pytorch_lightning.trainer.connectors.logger_connector import LoggerConnector\n","from pytorch_lightning.trainer.connectors.model_connector import ModelConnector\n","from pytorch_lightning.trainer.connectors.optimizer_connector import OptimizerConnector\n","from pytorch_lightning.trainer.connectors.slurm_connector import SLURMConnector\n","from pytorch_lightning.trainer.connectors.training_trick_connector import TrainingTricksConnector\n","from pytorch_lightning.trainer.data_loading import TrainerDataLoadingMixin\n","from pytorch_lightning.trainer.deprecated_api import DeprecatedTrainerAttributes\n","from pytorch_lightning.trainer.logging import TrainerLoggingMixin\n","from pytorch_lightning.trainer.model_hooks import TrainerModelHooksMixin\n","from pytorch_lightning.trainer.optimizers import TrainerOptimizersMixin\n","from pytorch_lightning.trainer.properties import TrainerProperties\n","from pytorch_lightning.trainer.states import TrainerFn, TrainerState, TrainerStatus\n","from pytorch_lightning.trainer.training_tricks import TrainerTrainingTricksMixin\n","from pytorch_lightning.tuner.auto_gpu_select import pick_multiple_gpus\n","from pytorch_lightning.tuner.lr_finder import _LRFinder\n","from pytorch_lightning.tuner.tuning import Tuner\n","from pytorch_lightning.utilities import (\n","    _IPU_AVAILABLE,\n","    _TPU_AVAILABLE,\n","    device_parser,\n","    DeviceType,\n","    parsing,\n","    rank_zero_deprecation,\n","    rank_zero_info,\n","    rank_zero_warn,\n",")\n","from pytorch_lightning.utilities.debugging import InternalDebugger\n","from pytorch_lightning.utilities.distributed import distributed_available\n","from pytorch_lightning.utilities.exceptions import MisconfigurationException\n","from pytorch_lightning.utilities.imports import _fault_tolerant_enabled\n","from pytorch_lightning.utilities.model_helpers import is_overridden\n","from pytorch_lightning.utilities.seed import reset_seed\n","from pytorch_lightning.utilities.types import _EVALUATE_OUTPUT, _PREDICT_OUTPUT, EVAL_DATALOADERS, TRAIN_DATALOADERS\n","\n","log = logging.getLogger(__name__)\n","# warnings to ignore in trainer\n","warnings.filterwarnings(\n","    \"ignore\", message=\"torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\"\n",")\n","\n","\n","class Trainer(\n","    TrainerProperties,\n","    TrainerCallbackHookMixin,\n","    TrainerModelHooksMixin,\n","    TrainerOptimizersMixin,\n","    TrainerLoggingMixin,\n","    TrainerTrainingTricksMixin,\n","    TrainerDataLoadingMixin,\n","    DeprecatedTrainerAttributes,\n","):\n","    @_defaults_from_env_vars\n","    def __init__(\n","        self,\n","        logger: Union[LightningLoggerBase, Iterable[LightningLoggerBase], bool] = True,\n","        checkpoint_callback: bool = True,\n","        callbacks: Optional[Union[List[Callback], Callback]] = None,\n","        default_root_dir: Optional[str] = None,\n","        gradient_clip_val: float = 0.0,\n","        gradient_clip_algorithm: str = \"norm\",\n","        process_position: int = 0,\n","        num_nodes: int = 1,\n","        num_processes: int = 1,\n","        devices: Optional[Union[List[int], str, int]] = None,\n","        gpus: Optional[Union[List[int], str, int]] = 1,\n","        auto_select_gpus: bool = True,\n","        tpu_cores: Optional[Union[List[int], str, int]] = None,\n","        ipus: Optional[int] = None,\n","        log_gpu_memory: Optional[str] = None,\n","        progress_bar_refresh_rate: Optional[int] = None,\n","        overfit_batches: Union[int, float] = 0.0,\n","        track_grad_norm: Union[int, float, str] = -1,\n","        check_val_every_n_epoch: int = 1,\n","        fast_dev_run: Union[int, bool] = False,\n","        accumulate_grad_batches: Union[int, Dict[int, int], List[list]] = 1,\n","        max_epochs: Optional[int] = None,\n","        min_epochs: Optional[int] = None,\n","        max_steps: Optional[int] = None,\n","        min_steps: Optional[int] = None,\n","        max_time: Optional[Union[str, timedelta, Dict[str, int]]] = None,\n","        limit_train_batches: Union[int, float] = 1.0,\n","        limit_val_batches: Union[int, float] = 1.0,\n","        limit_test_batches: Union[int, float] = 1.0,\n","        limit_predict_batches: Union[int, float] = 1.0,\n","        val_check_interval: Union[int, float] = 1.0,\n","        flush_logs_every_n_steps: int = 100,\n","        log_every_n_steps: int = 50,\n","        accelerator: Optional[Union[str, Accelerator]] = None,\n","        sync_batchnorm: bool = False,\n","        precision: int = 32,\n","        weights_summary: Optional[str] = \"top\",\n","        weights_save_path: Optional[str] = None,\n","        num_sanity_val_steps: int = 2,\n","        truncated_bptt_steps: Optional[int] = None,\n","        resume_from_checkpoint: Optional[Union[Path, str]] = None,\n","        profiler: Optional[Union[BaseProfiler, str]] = None,\n","        benchmark: bool = False,\n","        deterministic: bool = False,\n","        reload_dataloaders_every_n_epochs: int = 0,\n","        reload_dataloaders_every_epoch: bool = False,\n","        auto_lr_find: Union[bool, str] = False,\n","        replace_sampler_ddp: bool = True,\n","        terminate_on_nan: bool = False,\n","        auto_scale_batch_size: Union[str, bool] = False,\n","        prepare_data_per_node: bool = True,\n","        plugins: Optional[Union[List[Union[Plugin, ClusterEnvironment, str]], Plugin, ClusterEnvironment, str]] = None,\n","        amp_backend: str = \"native\",\n","        amp_level: str = \"O2\",\n","        distributed_backend: Optional[str] = None,\n","        move_metrics_to_cpu: bool = False,\n","        multiple_trainloader_mode: str = \"max_size_cycle\",\n","        stochastic_weight_avg: bool = False,\n","    ):\n","        r\"\"\"\n","        Customize every aspect of training via flags\n","\n","        Args:\n","\n","            accelerator: Previously known as distributed_backend (dp, ddp, ddp2, etc...).\n","                Can also take in an accelerator object for custom hardware.\n","\n","            accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.\n","\n","            amp_backend: The mixed precision backend to use (\"native\" or \"apex\")\n","\n","            amp_level: The optimization level to use (O1, O2, etc...).\n","\n","            auto_lr_find: If set to True, will make trainer.tune() run a learning rate finder,\n","                trying to optimize initial learning for faster convergence. trainer.tune() method will\n","                set the suggested learning rate in self.lr or self.learning_rate in the LightningModule.\n","                To use a different key set a string instead of True with the key name.\n","\n","            auto_scale_batch_size: If set to True, will `initially` run a batch size\n","                finder trying to find the largest batch size that fits into memory.\n","                The result will be stored in self.batch_size in the LightningModule.\n","                Additionally, can be set to either `power` that estimates the batch size through\n","                a power search or `binsearch` that estimates the batch size through a binary search.\n","\n","            auto_select_gpus: If enabled and `gpus` is an integer, pick available\n","                gpus automatically. This is especially useful when\n","                GPUs are configured to be in \"exclusive mode\", such\n","                that only one process at a time can access them.\n","\n","            benchmark: If true enables cudnn.benchmark.\n","\n","            callbacks: Add a callback or list of callbacks.\n","\n","            checkpoint_callback: If ``True``, enable checkpointing.\n","                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n","                :paramref:`~pytorch_lightning.trainer.trainer.Trainer.callbacks`.\n","\n","            check_val_every_n_epoch: Check val every n train epochs.\n","\n","            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n","                Default: ``os.getcwd()``.\n","                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n","\n","            deterministic: If true enables cudnn.deterministic.\n","\n","            devices: Will be mapped to either `gpus`, `tpu_cores`, `num_processes` or `ipus`,\n","                based on the accelerator type.\n","\n","            distributed_backend: deprecated. Please use 'accelerator'\n","\n","            fast_dev_run: runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n","                of train, val and test to find any bugs (ie: a sort of unit test).\n","\n","            flush_logs_every_n_steps: How often to flush logs to disk (defaults to every 100 steps).\n","\n","            gpus: number of gpus to train on (int) or which GPUs to train on (list or str) applied per node\n","\n","            gradient_clip_val: 0 means don't clip.\n","\n","            gradient_clip_algorithm: 'value' means clip_by_value, 'norm' means clip_by_norm. Default: 'norm'\n","\n","            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches)\n","\n","            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches)\n","\n","            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches)\n","\n","            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches)\n","\n","            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n","                the default ``TensorBoardLogger``. ``False`` will disable logging. If multiple loggers are\n","                provided and the `save_dir` property of that logger is not set, local files (checkpoints,\n","                profiler traces, etc.) are saved in ``default_root_dir`` rather than in the ``log_dir`` of any\n","                of the individual loggers.\n","\n","            log_gpu_memory: None, 'min_max', 'all'. Might slow performance\n","\n","            log_every_n_steps: How often to log within steps (defaults to every 50 steps).\n","\n","            prepare_data_per_node: If True, each LOCAL_RANK=0 will call prepare data.\n","                Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data\n","\n","            process_position: orders the progress bar when running multiple models on same machine.\n","\n","            progress_bar_refresh_rate: How often to refresh progress bar (in steps). Value ``0`` disables progress bar.\n","                Ignored when a custom progress bar is passed to :paramref:`~Trainer.callbacks`. Default: None, means\n","                a suitable value will be chosen based on the environment (terminal, Google COLAB, etc.).\n","\n","            profiler: To profile individual steps during training and assist in identifying bottlenecks.\n","\n","            overfit_batches: Overfit a fraction of training data (float) or a set number of batches (int).\n","\n","            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n","\n","            precision: Double precision (64), full precision (32) or half precision (16). Can be used on CPU, GPU or\n","                TPUs.\n","\n","            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n","                If both max_epochs and max_steps are not specified, defaults to ``max_epochs`` = 1000.\n","\n","            min_epochs: Force training for at least these many epochs. Disabled by default (None).\n","                If both min_epochs and min_steps are not specified, defaults to ``min_epochs`` = 1.\n","\n","            max_steps: Stop training after this number of steps. Disabled by default (None).\n","\n","            min_steps: Force training for at least these number of steps. Disabled by default (None).\n","\n","            max_time: Stop training after this amount of time has passed. Disabled by default (None).\n","                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n","                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n","                :class:`datetime.timedelta`.\n","\n","            num_nodes: number of GPU nodes for distributed training.\n","\n","            num_processes: number of processes for distributed training with distributed_backend=\"ddp_cpu\"\n","\n","            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n","                Set it to `-1` to run all batches in all validation dataloaders.\n","\n","            reload_dataloaders_every_n_epochs: Set to a non-negative integer to reload dataloaders every n epochs.\n","                Default: 0\n","\n","            reload_dataloaders_every_epoch: Set to True to reload dataloaders every epoch.\n","\n","                .. deprecated:: v1.4\n","                    ``reload_dataloaders_every_epoch`` has been deprecated in v1.4 and will be removed in v1.6.\n","                    Please use ``reload_dataloaders_every_n_epochs``.\n","\n","            replace_sampler_ddp: Explicitly enables or disables sampler replacement. If not specified this\n","                will toggled automatically when DDP is used. By default it will add ``shuffle=True`` for\n","                train sampler and ``shuffle=False`` for val/test sampler. If you want to customize it,\n","                you can set ``replace_sampler_ddp=False`` and add your own distributed sampler.\n","\n","            resume_from_checkpoint: Path/URL of the checkpoint from which training is resumed. If there is\n","                no checkpoint file at the path, start from scratch. If resuming from mid-epoch checkpoint,\n","                training will start from the beginning of the next epoch.\n","\n","            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n","\n","            terminate_on_nan: If set to True, will terminate training (by raising a `ValueError`) at the\n","                end of each training batch, if any of the parameters or the loss are NaN or +/-inf.\n","\n","            tpu_cores: How many TPU cores to train on (1 or 8) / Single TPU to train on [1]\n","\n","            ipus: How many IPUs to train on.\n","\n","            track_grad_norm: -1 no tracking. Otherwise tracks that p-norm. May be set to 'inf' infinity-norm.\n","\n","            truncated_bptt_steps: Deprecated in v1.3 to be removed in 1.5.\n","                Please use :paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps` instead.\n","\n","            val_check_interval: How often to check the validation set. Use float to check within a training epoch,\n","                use int to check every n steps (batches).\n","\n","            weights_summary: Prints a summary of the weights when training begins.\n","\n","            weights_save_path: Where to save weights if specified. Will override default_root_dir\n","                for checkpoints only. Use this if for whatever reason you need the checkpoints\n","                stored in a different place than the logs written in `default_root_dir`.\n","                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n","                Defaults to `default_root_dir`.\n","\n","            move_metrics_to_cpu: Whether to force internal logged metrics to be moved to cpu.\n","                This can save some gpu memory, but can make training slower. Use with attention.\n","\n","            multiple_trainloader_mode: How to loop over the datasets when there are multiple train loaders.\n","                In 'max_size_cycle' mode, the trainer ends one epoch when the largest dataset is traversed,\n","                and smaller datasets reload when running out of their data. In 'min_size' mode, all the datasets\n","                reload when reaching the minimum length of datasets.\n","\n","            stochastic_weight_avg: Whether to use `Stochastic Weight Averaging (SWA)\n","                \u003chttps://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/\u003e_`\n","\n","        \"\"\"\n","        super().__init__()\n","        Trainer._log_api_event(\"init\")\n","        self.state = TrainerState()\n","\n","        gpu_ids, tpu_cores = self._parse_devices(gpus, auto_select_gpus, tpu_cores)\n","\n","        # init connectors\n","        self.dev_debugger = InternalDebugger(self)\n","        self.config_validator = ConfigValidator(self)\n","        self.data_connector = DataConnector(self, multiple_trainloader_mode)\n","        self.optimizer_connector = OptimizerConnector(self)\n","\n","        self.accelerator_connector = AcceleratorConnector(\n","            num_processes,\n","            devices,\n","            tpu_cores,\n","            ipus,\n","            distributed_backend,\n","            accelerator,\n","            gpus,\n","            gpu_ids,\n","            num_nodes,\n","            sync_batchnorm,\n","            benchmark,\n","            replace_sampler_ddp,\n","            deterministic,\n","            precision,\n","            amp_backend,\n","            amp_level,\n","            plugins,\n","        )\n","        self.logger_connector = LoggerConnector(self, log_gpu_memory)\n","        self.model_connector = ModelConnector(self)\n","        self.callback_connector = CallbackConnector(self)\n","        self.debugging_connector = DebuggingConnector(self)\n","        self.training_tricks_connector = TrainingTricksConnector(self)\n","        self.checkpoint_connector = CheckpointConnector(self, resume_from_checkpoint)\n","        self.slurm_connector = SLURMConnector(self)\n","        self.tuner = Tuner(self)\n","\n","        fit_loop = FitLoop(\n","            min_epochs=(1 if (min_epochs is None and min_steps is None) else min_epochs),\n","            max_epochs=(1000 if (max_epochs is None and max_steps is None) else max_epochs),\n","        )\n","        training_epoch_loop = TrainingEpochLoop(min_steps, max_steps)\n","        training_batch_loop = TrainingBatchLoop()\n","        training_validation_loop = EvaluationLoop()\n","        training_epoch_loop.connect(batch_loop=training_batch_loop, val_loop=training_validation_loop)\n","        fit_loop.connect(epoch_loop=training_epoch_loop)\n","\n","        # default .fit() loop\n","        self.fit_loop = fit_loop\n","\n","        # default .validate() loop\n","        self.validate_loop = EvaluationLoop()\n","\n","        # default .test() loop\n","        self.test_loop = EvaluationLoop()\n","\n","        # default .predict() loop\n","        self.predict_loop = PredictionLoop()\n","\n","        # training state\n","        if weights_summary is not None and weights_summary not in ModelSummary.MODES:\n","            raise MisconfigurationException(\n","                f\"`weights_summary` can be None, {', '.join(ModelSummary.MODES)}, but got {weights_summary}\"\n","            )\n","        self.weights_summary = weights_summary\n","        self.shown_warnings = set()\n","\n","        # init callbacks\n","        # Declare attributes to be set in callback_connector on_trainer_init\n","        self.callback_connector.on_trainer_init(\n","            callbacks,\n","            checkpoint_callback,\n","            progress_bar_refresh_rate,\n","            process_position,\n","            default_root_dir,\n","            weights_save_path,\n","            stochastic_weight_avg,\n","            max_time,\n","        )\n","\n","        # hook\n","        self.on_init_start()\n","\n","        # init optimizer + lr scheduler related flags\n","        self.optimizer_connector.on_trainer_init()\n","\n","        # init data flags\n","        self.data_connector.on_trainer_init(\n","            check_val_every_n_epoch,\n","            reload_dataloaders_every_n_epochs,\n","            reload_dataloaders_every_epoch,\n","            prepare_data_per_node,\n","        )\n","\n","        # init training tricks\n","        self.training_tricks_connector.on_trainer_init(\n","            gradient_clip_val,\n","            gradient_clip_algorithm,\n","            track_grad_norm,\n","            accumulate_grad_batches,\n","            truncated_bptt_steps,\n","            terminate_on_nan,\n","        )\n","        self._setup_on_init(num_sanity_val_steps)\n","\n","        # configure tuner\n","        self.tuner.on_trainer_init(auto_lr_find, auto_scale_batch_size)\n","\n","        # configure profiler\n","        self.__init_profiler(profiler)\n","\n","        # init logger flags\n","        self.logger_connector.on_trainer_init(logger, flush_logs_every_n_steps, log_every_n_steps, move_metrics_to_cpu)\n","\n","        # init debugging flags\n","        self.debugging_connector.on_init_start(\n","            limit_train_batches,\n","            limit_val_batches,\n","            limit_test_batches,\n","            limit_predict_batches,\n","            val_check_interval,\n","            overfit_batches,\n","            fast_dev_run,\n","        )\n","\n","        # Callback system\n","        self.on_init_end()\n","\n","    def _setup_on_init(self, num_sanity_val_steps: int) -\u003e None:\n","        self._log_device_info()\n","\n","        self.should_stop = False\n","        self.state = TrainerState()\n","        self.num_training_batches = 0\n","        self.train_dataloader = None\n","\n","        if num_sanity_val_steps == -1:\n","            self.num_sanity_val_steps = float(\"inf\")\n","        else:\n","            self.num_sanity_val_steps = num_sanity_val_steps\n","\n","        self.num_sanity_val_batches = []\n","        self.num_test_batches = []\n","        self.num_val_batches = []\n","        self.test_dataloaders = None\n","        self.val_dataloaders = None\n","\n","        # .validate() and .test() set this when they load a checkpoint\n","        self.validated_ckpt_path = None\n","        self.tested_ckpt_path = None\n","\n","        # when true, print evaluation results in .validate() and .test()\n","        self.verbose_evaluate = True\n","\n","        self.num_predict_batches = []\n","        self.predicted_ckpt_path = None\n","\n","    def fit(\n","        self,\n","        model: \"pl.LightningModule\",\n","        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, LightningDataModule]] = None,\n","        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        train_dataloader=None,  # noqa TODO: remove with 1.6\n","    ) -\u003e None:\n","        r\"\"\"\n","        Runs the full optimization routine.\n","\n","        Args:\n","            model: Model to fit.\n","\n","            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\n","                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.\n","                In the case of multiple dataloaders, please see this :ref:`page \u003cmultiple-training-dataloaders\u003e`.\n","\n","            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","        \"\"\"\n","        Trainer._log_api_event(\"fit\")\n","\n","        self.state.fn = TrainerFn.FITTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.training = True\n","\n","        if train_dataloader is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\"\n","            )\n","            train_dataloaders = train_dataloader\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(train_dataloaders, LightningDataModule):\n","            datamodule = train_dataloaders\n","            train_dataloaders = None\n","        # If you supply a datamodule you can't supply train_dataloader or val_dataloaders\n","        if (train_dataloaders is not None or val_dataloaders is not None) and datamodule is not None:\n","            raise MisconfigurationException(\n","                \"You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.fit(datamodule=...)`\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(\n","            model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders, datamodule=datamodule\n","        )\n","\n","        self.checkpoint_connector.resume_start()\n","\n","        self._run(model)\n","\n","        assert self.state.stopped\n","        self.training = False\n","\n","    def validate(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","        verbose: bool = True,\n","        datamodule: Optional[LightningDataModule] = None,\n","        val_dataloaders=None,  # noqa TODO: remove with 1.6\n","    ) -\u003e _EVALUATE_OUTPUT:\n","        r\"\"\"\n","        Perform one evaluation epoch over the validation set.\n","\n","        Args:\n","            model: The model to validate.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying validation samples.\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to validate.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","            verbose: If True, prints the validation results.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","        Returns:\n","            List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks\n","            like :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step`,\n","            :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_epoch_end`, etc.\n","            The length of the list corresponds to the number of validation dataloaders used.\n","        \"\"\"\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"validate\")\n","        self.verbose_evaluate = verbose\n","\n","        self.state.fn = TrainerFn.VALIDATING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.validating = True\n","\n","        if val_dataloaders is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.validate(val_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.validate(dataloaders)` instead.\"\n","            )\n","            dataloaders = val_dataloaders\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        # If you supply a datamodule you can't supply val_dataloaders\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.validate(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.validate()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, val_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.validated_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        # run validate\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.validating = False\n","\n","        return results\n","\n","    def test(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","        verbose: bool = True,\n","        datamodule: Optional[LightningDataModule] = None,\n","        test_dataloaders=None,  # noqa TODO: remove with 1.6\n","    ) -\u003e _EVALUATE_OUTPUT:\n","        r\"\"\"\n","        Perform one evaluation epoch over the test set. It's separated from\n","        fit to make sure you never run on your test set until you want to.\n","\n","        Args:\n","            model: The model to test.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying test samples.\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to test.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","            verbose: If True, prints the test results.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","        Returns:\n","            List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks\n","            like :meth:`~pytorch_lightning.core.lightning.LightningModule.test_step`,\n","            :meth:`~pytorch_lightning.core.lightning.LightningModule.test_epoch_end`, etc.\n","            The length of the list corresponds to the number of test dataloaders used.\n","        \"\"\"\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"test\")\n","        self.verbose_evaluate = verbose\n","\n","        self.state.fn = TrainerFn.TESTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.testing = True\n","\n","        if test_dataloaders is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.test(dataloaders)` instead.\"\n","            )\n","            dataloaders = test_dataloaders\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        # If you supply a datamodule you can't supply test_dataloaders\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.test(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.test()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, test_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.tested_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        # run test\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.testing = False\n","\n","        return results\n","\n","    def predict(\n","        self,\n","        model: Optional[\"pl.LightningModule\"] = None,\n","        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        return_predictions: Optional[bool] = None,\n","        ckpt_path: Optional[str] = \"best\",\n","    ) -\u003e Optional[_PREDICT_OUTPUT]:\n","        r\"\"\"\n","\n","        Separates from fit to make sure you never run on your predictions set until you want to.\n","        This will call the model forward function to compute predictions.\n","\n","        Args:\n","            model: The model to predict with.\n","\n","            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,\n","                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying prediction samples.\n","\n","            datamodule: The datamodule with a predict_dataloader method that returns one or more dataloaders.\n","\n","            return_predictions: Whether to return predictions.\n","                ``True`` by default except when an accelerator that spawns processes is used (not supported).\n","\n","            ckpt_path: Either ``best`` or path to the checkpoint you wish to use to predict.\n","                If ``None``, use the current weights of the model.\n","                When the model is given as argument, this parameter will not apply.\n","\n","        Returns:\n","            Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\n","        \"\"\"\n","\n","        # --------------------\n","        # SETUP HOOK\n","        # --------------------\n","        Trainer._log_api_event(\"predict\")\n","\n","        self.state.fn = TrainerFn.PREDICTING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.predicting = True\n","\n","        self.predict_loop.return_predictions = return_predictions\n","\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(dataloaders, LightningDataModule):\n","            datamodule = dataloaders\n","            dataloaders = None\n","        if dataloaders is not None and datamodule:\n","            raise MisconfigurationException(\"You cannot pass both `trainer.predict(dataloaders=..., datamodule=...)`\")\n","\n","        model_provided = model is not None\n","        model = model or self.lightning_module\n","        if model is None:\n","            raise MisconfigurationException(\n","                \"`model` must be provided to `trainer.predict()` when it hasn't been passed in a previous run\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(model, predict_dataloaders=dataloaders, datamodule=datamodule)\n","\n","        if not model_provided:\n","            self.predicted_ckpt_path = self.__load_ckpt_weights(ckpt_path)\n","\n","        results = self._run(model)\n","\n","        assert self.state.stopped\n","        self.predicting = False\n","\n","        return results\n","\n","    def tune(\n","        self,\n","        model: \"pl.LightningModule\",\n","        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, LightningDataModule]] = None,\n","        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\n","        datamodule: Optional[LightningDataModule] = None,\n","        scale_batch_size_kwargs: Optional[Dict[str, Any]] = None,\n","        lr_find_kwargs: Optional[Dict[str, Any]] = None,\n","        train_dataloader=None,  # noqa TODO: remove with 1.6\n","    ) -\u003e Dict[str, Optional[Union[int, _LRFinder]]]:\n","        r\"\"\"\n","        Runs routines to tune hyperparameters before training.\n","\n","        Args:\n","            model: Model to tune.\n","\n","            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\n","                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.\n","                In the case of multiple dataloaders, please see this :ref:`page \u003cmultiple-training-dataloaders\u003e`.\n","\n","            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\n","\n","            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\n","\n","            scale_batch_size_kwargs: Arguments for :func:`~pytorch_lightning.tuner.batch_size_scaling.scale_batch_size`\n","\n","            lr_find_kwargs: Arguments for :func:`~pytorch_lightning.tuner.lr_finder.lr_find`\n","        \"\"\"\n","        Trainer._log_api_event(\"tune\")\n","\n","        self.state.fn = TrainerFn.TUNING\n","        self.state.status = TrainerStatus.RUNNING\n","        self.tuning = True\n","\n","        if train_dataloader is not None:\n","            rank_zero_deprecation(\n","                \"`trainer.tune(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n","                \" Use `trainer.tune(train_dataloaders)` instead. HINT: added 's'\"\n","            )\n","            train_dataloaders = train_dataloader\n","        # if a datamodule comes in as the second arg, then fix it for the user\n","        if isinstance(train_dataloaders, LightningDataModule):\n","            datamodule = train_dataloaders\n","            train_dataloaders = None\n","        # If you supply a datamodule you can't supply train_dataloader or val_dataloaders\n","        if (train_dataloaders is not None or val_dataloaders is not None) and datamodule is not None:\n","            raise MisconfigurationException(\n","                \"You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.tune(datamodule=...)`\"\n","            )\n","\n","        # links data to the trainer\n","        self.data_connector.attach_data(\n","            model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders, datamodule=datamodule\n","        )\n","\n","        result = self.tuner._tune(model, scale_batch_size_kwargs=scale_batch_size_kwargs, lr_find_kwargs=lr_find_kwargs)\n","\n","        assert self.state.stopped\n","        self.tuning = False\n","\n","        return result\n","\n","    def _run(self, model: \"pl.LightningModule\") -\u003e Optional[Union[_EVALUATE_OUTPUT, _PREDICT_OUTPUT]]:\n","        # clean hparams\n","        if hasattr(model, \"hparams\"):\n","            parsing.clean_namespace(model.hparams)\n","\n","        self.config_validator.verify_loop_configurations(model)\n","\n","        # attach model log function to callback\n","        self.callback_connector.attach_model_logging_functions(model)\n","\n","        # hook\n","        self.data_connector.prepare_data(model)\n","        self.callback_connector._attach_model_callbacks(model, self)\n","\n","        # ----------------------------\n","        # SET UP TRAINING\n","        # ----------------------------\n","        self.call_hook(\"on_before_accelerator_backend_setup\", model)\n","        self.accelerator.connect(model)\n","        self.accelerator.setup_environment()\n","        self._call_setup_hook(model)  # allow user to setup lightning_module in accelerator environment\n","\n","        # restore modules after setup\n","        self.checkpoint_connector.restore_datamodule()\n","        self.checkpoint_connector.restore_model()\n","        # restore callback states\n","        self.checkpoint_connector.restore_callbacks()\n","\n","        self._call_configure_sharded_model(model)  # allow user to setup in model sharded environment\n","        self.accelerator.setup(self, model)  # note: this sets up self.lightning_module\n","\n","        # ----------------------------\n","        # INSPECT THE CORE LOOPS\n","        # ----------------------------\n","        fr\"\"\"\n","             Lightning internal flow looks like this:\n","        {Trainer.fit} or {Trainer.test} or {Trainer.predict}  ||\n","                                |                             ||\n","                        create accelerator                    ||\n","                                |                             ||\n","                         {self._dispatch}                     ||\n","                                |                             ||  LIGHTNING\n","                  {self.accelerator.start_training}           ||\n","                or {self.accelerator.start_evaluating}        ||\n","                or {self.accelerator.start_predicting}        ||  FLOW\n","                                |                             ||\n","                         {self.run_stage}                     ||\n","                                |                             ||  DIRECTION\n","                        {self._run_train}                     ||\n","                     or {self._run_evaluate}                  ||\n","                     or {self._run_predict}                   ||\n","                                |                             ||\n","                             results                          \\/\n","        This is used to guide readers to the core loops: train, test, predict.\n","        {self._run_predict} is the simplest to understand, use `Go to Definition` to read it :)\n","        Search for `start_training` or `start_evaluating` or `start_predicting` in\n","        `pytorch_lightning/plugins/training_type_plugin` to find accelerator dispatch functions.\n","        \"\"\"  # noqa: W605\n","\n","        # ----------------------------\n","        # TRAIN\n","        # ----------------------------\n","        # hook\n","        if self.state.fn == TrainerFn.FITTING:\n","            self.call_hook(\"on_fit_start\")\n","\n","        # plugin will setup fitting (e.g. ddp will launch child processes)\n","        self._pre_dispatch()\n","\n","        # restore optimizers, etc.\n","        self.checkpoint_connector.restore_training_state()\n","\n","        # dispatch `start_training` or `start_evaluating` or `start_predicting`\n","        self._dispatch()\n","\n","        # plugin will finalized fitting (e.g. ddp_spawn will load trained model)\n","        self._post_dispatch()\n","\n","        # ----------------------------\n","        # POST-Training CLEAN UP\n","        # ----------------------------\n","        # hook\n","        if self.state.fn == TrainerFn.FITTING:\n","            self.call_hook(\"on_fit_end\")\n","\n","        # teardown\n","        self._call_teardown_hook(model)\n","\n","        if self.state.status != TrainerStatus.INTERRUPTED:\n","            self.state.status = TrainerStatus.FINISHED\n","        self.state.stage = None\n","\n","        return self.accelerator.results\n","\n","    def _pre_dispatch(self):\n","        self.accelerator.pre_dispatch(self)\n","        self._log_hyperparams()\n","\n","    def _log_hyperparams(self):\n","        # log hyper-parameters\n","        hparams_initial = None\n","\n","        if self.logger is not None:\n","            # save exp to get started (this is where the first experiment logs are written)\n","            datamodule_log_hyperparams = self.datamodule._log_hyperparams if self.datamodule is not None else False\n","\n","            if self.lightning_module._log_hyperparams and datamodule_log_hyperparams:\n","                datamodule_hparams = self.datamodule.hparams_initial\n","                lightning_hparams = self.lightning_module.hparams_initial\n","\n","                colliding_keys = lightning_hparams.keys() \u0026 datamodule_hparams.keys()\n","                if colliding_keys:\n","                    raise MisconfigurationException(\n","                        f\"Error while merging hparams: the keys {colliding_keys} are present \"\n","                        \"in both the LightningModule's and LightningDataModule's hparams.\"\n","                    )\n","                hparams_initial = {**lightning_hparams, **datamodule_hparams}\n","            elif self.lightning_module._log_hyperparams:\n","                hparams_initial = self.lightning_module.hparams_initial\n","            elif datamodule_log_hyperparams:\n","                hparams_initial = self.datamodule.hparams_initial\n","\n","            if hparams_initial is not None:\n","                self.logger.log_hyperparams(hparams_initial)\n","            self.logger.log_graph(self.lightning_module)\n","            self.logger.save()\n","\n","    def _post_dispatch(self):\n","        self.accelerator.post_dispatch(self)\n","        # these `teardown` calls are here instead of in `_call_teardown_hook` since they are internal teardowns\n","        # which need to happen before.\n","        self.accelerator.teardown()\n","        self._active_loop.teardown()\n","        self.logger_connector.teardown()\n","\n","    def _dispatch(self):\n","        if self.evaluating:\n","            self.accelerator.start_evaluating(self)\n","        elif self.predicting:\n","            self.accelerator.start_predicting(self)\n","        else:\n","            self.accelerator.start_training(self)\n","\n","    def run_stage(self):\n","        self.accelerator.dispatch(self)\n","        self.__setup_profiler()\n","\n","        if self.evaluating:\n","            return self._run_evaluate()\n","        if self.predicting:\n","            return self._run_predict()\n","        return self._run_train()\n","\n","    def _pre_training_routine(self):\n","        # wait for all to join if on distributed\n","        self.accelerator.barrier(\"setup_training\")\n","\n","        # register auto-resubmit when on SLURM\n","        self.slurm_connector.register_slurm_signal_handlers()\n","\n","        self.checkpoint_connector.resume_end()\n","\n","        # --------------------------\n","        # Pre-train\n","        # --------------------------\n","        # on pretrain routine start\n","        ref_model = self.lightning_module\n","\n","        self.on_pretrain_routine_start()\n","        ref_model.on_pretrain_routine_start()\n","\n","        # print model summary\n","        if self.is_global_zero and self.weights_summary is not None and not self.testing:\n","            max_depth = ModelSummary.MODES[self.weights_summary]\n","            ref_model.summarize(max_depth=max_depth)\n","\n","        # on pretrain routine end\n","        self.on_pretrain_routine_end()\n","        ref_model.on_pretrain_routine_end()\n","\n","    def _run_train(self) -\u003e None:\n","        self._pre_training_routine()\n","\n","        if not self.is_global_zero and self.progress_bar_callback is not None:\n","            self.progress_bar_callback.disable()\n","\n","        self._run_sanity_check(self.lightning_module)\n","\n","        # enable train mode\n","        self.model.train()\n","        torch.set_grad_enabled(True)\n","\n","        # reload data when needed\n","        model = self.lightning_module\n","\n","        self.reset_train_val_dataloaders(model)\n","\n","        try:\n","            # reset trainer on this loop and all child loops in case user connected a custom loop\n","            self.fit_loop.trainer = self\n","            self.fit_loop.run()\n","        except KeyboardInterrupt:\n","            rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","            # user could press Ctrl+c many times... only shutdown once\n","            if not self.interrupted:\n","                self.state.status = TrainerStatus.INTERRUPTED\n","                self.on_keyboard_interrupt()\n","                # same treatment as below\n","                self.accelerator.on_train_end()\n","        except BaseException:\n","            self.state.status = TrainerStatus.INTERRUPTED\n","            if distributed_available() and self.world_size \u003e 1:\n","                # try syncing remaing processes, kill otherwise\n","                self.training_type_plugin.reconciliate_processes(traceback.format_exc())\n","            # give accelerators a chance to finish\n","            self.accelerator.on_train_end()\n","            self._on_expection()\n","            # reset bookkeeping\n","            self.state.stage = None\n","            raise\n","\n","    def _run_evaluate(self) -\u003e _EVALUATE_OUTPUT:\n","        if not self.is_global_zero and self.progress_bar_callback is not None:\n","            self.progress_bar_callback.disable()\n","\n","        assert self.evaluating\n","\n","        # reload dataloaders\n","        self._evaluation_loop.reload_evaluation_dataloaders()\n","\n","        # reset trainer on this loop and all child loops in case user connected a custom loop\n","        self._evaluation_loop.trainer = self\n","\n","        with self.profiler.profile(f\"run_{self.state.stage}_evaluation\"), torch.no_grad():\n","            eval_loop_results = self._evaluation_loop.run()\n","\n","        # remove the tensors from the eval results\n","        for i, result in enumerate(eval_loop_results):\n","            if isinstance(result, dict):\n","                for k, v in result.items():\n","                    if isinstance(v, torch.Tensor):\n","                        result[k] = v.cpu().item()\n","\n","        return eval_loop_results\n","\n","    def _run_predict(self) -\u003e Optional[_PREDICT_OUTPUT]:\n","        self.reset_predict_dataloader(self.lightning_module)\n","        # reset trainer on this loop and all child loops in case user connected a custom loop\n","        self.predict_loop.trainer = self\n","        with torch.no_grad():\n","            return self.predict_loop.run()\n","\n","    def _run_sanity_check(self, ref_model):\n","        using_val_step = ref_model.val_dataloader is not None and is_overridden(\"validation_step\", ref_model)\n","        should_sanity_check = using_val_step and self.num_sanity_val_steps \u003e 0 and self.limit_val_batches \u003e 0\n","\n","        # run tiny validation (if validation defined)\n","        # to make sure program won't crash during val\n","        if should_sanity_check:\n","            stage = self.state.stage\n","            self.sanity_checking = True\n","\n","            # hook and callback\n","            self.on_sanity_check_start()\n","\n","            # reload dataloaders\n","            self._evaluation_loop.reload_evaluation_dataloaders()\n","\n","            # run eval step\n","            with torch.no_grad():\n","                self._evaluation_loop.run()\n","\n","            self.on_sanity_check_end()\n","\n","            # reset validation metrics\n","            self.logger_connector.reset()\n","\n","            # reset the seed to what it was before sanity check\n","            # prevents sanity check to affect random sampling in training\n","            reset_seed()\n","\n","            # restore the previous stage when the sanity check if finished\n","            self.state.stage = stage\n","\n","    def __load_ckpt_weights(self, ckpt_path: Optional[str]) -\u003e Optional[str]:\n","        if ckpt_path is None:\n","            return\n","\n","        fn = self.state.fn.value\n","\n","        if ckpt_path == \"best\":\n","            # if user requests the best checkpoint but we don't have it, error\n","            if not self.checkpoint_callback.best_model_path:\n","                if self.fast_dev_run:\n","                    raise MisconfigurationException(\n","                        f\"You cannot execute `.{fn}()` with `fast_dev_run=True` unless you do\"\n","                        f\" `.{fn}(ckpt_path=PATH)` as no checkpoint path was generated during fitting.\"\n","                    )\n","                raise MisconfigurationException(\n","                    f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.'\n","                )\n","            # load best weights\n","            ckpt_path = self.checkpoint_callback.best_model_path\n","\n","        if not ckpt_path:\n","            raise MisconfigurationException(\n","                f'`.{fn}()` found no path for the best weights: \"{ckpt_path}\". Please'\n","                f\" specify a path for a checkpoint `.{fn}(ckpt_path=PATH)`\"\n","            )\n","\n","        # only one process running at this point for TPUs, as spawn isn't triggered yet\n","        # todo: move this logic internally within the barrier.\n","        if not self._device_type == DeviceType.TPU:\n","            self.training_type_plugin.barrier()\n","\n","        self.checkpoint_connector.restore_model_weights(ckpt_path)\n","        return ckpt_path\n","\n","    def _call_setup_hook(self, model: \"pl.LightningModule\") -\u003e None:\n","        fn = self.state.fn._setup_fn\n","\n","        self.accelerator.barrier(\"pre_setup\")\n","\n","        if self.datamodule is not None:\n","            self.datamodule.setup(stage=fn)\n","        self.setup(model, stage=fn)\n","        model.setup(stage=fn)\n","\n","        self.accelerator.barrier(\"post_setup\")\n","\n","    def _call_configure_sharded_model(self, model: \"pl.LightningModule\") -\u003e None:\n","        # Call configure sharded model hook if accelerator requests. In some cases\n","        # we will not call the hook; the hook has initialized the sharded model for example.\n","\n","        # used on the model if the user re-create a trainer with resume_from_checkpoint\n","        model_call_configure_sharded_model_hook = getattr(model, \"call_configure_sharded_model_hook\", False)\n","        if self.accelerator.call_configure_sharded_model_hook and not model_call_configure_sharded_model_hook:\n","            with self.accelerator.model_sharded_context():\n","                model.configure_sharded_model()\n","                self.configure_sharded_model(model)\n","            model.call_configure_sharded_model_hook = True\n","            self.accelerator.call_configure_sharded_model_hook = False\n","\n","    def _call_teardown_hook(self, model: \"pl.LightningModule\") -\u003e None:\n","        fn = self.state.fn._setup_fn\n","\n","        if self.datamodule is not None:\n","            self.datamodule.teardown(stage=fn)\n","        self.profiler.teardown(stage=fn)\n","        self.teardown(stage=fn)\n","        model.teardown(stage=fn)\n","\n","        model._current_fx_name = None\n","        model._current_dataloader_idx = None\n","        # these could have become stale if metrics are defined in `setup`\n","        model._metric_attributes = None\n","\n","    def call_hook(self, hook_name: str, *args, **kwargs) -\u003e Any:\n","        # Note this implementation is copy/pasted into the TrainLoop class in TrainingEpochLoop._on_train_epoch_end_hook\n","        # This was done to manage the deprecation of the `outputs` argument to on_train_epoch_end\n","        # If making changes to this function, ensure that those changes are also made to\n","        # TrainingEpochLoop._on_train_epoch_end_hook\n","        if self.lightning_module:\n","            prev_fx_name = self.lightning_module._current_fx_name\n","            self.lightning_module._current_fx_name = hook_name\n","\n","        # always profile hooks\n","        with self.profiler.profile(hook_name):\n","\n","            # first call trainer hook\n","            if hasattr(self, hook_name):\n","                trainer_hook = getattr(self, hook_name)\n","                trainer_hook(*args, **kwargs)\n","\n","            # next call hook in lightningModule\n","            output = None\n","            model_ref = self.lightning_module\n","            if is_overridden(hook_name, model_ref):\n","                hook_fx = getattr(model_ref, hook_name)\n","                output = hook_fx(*args, **kwargs)\n","\n","            # call the accelerator hook\n","            if hasattr(self.accelerator, hook_name):\n","                accelerator_hook = getattr(self.accelerator, hook_name)\n","                accelerator_output = accelerator_hook(*args, **kwargs)\n","                # Rely on the accelerator output if lightningModule hook returns nothing\n","                # Required for cases such as DataParallel where we reduce the output for the user\n","                # todo: move this data parallel logic into the data parallel plugin\n","                output = accelerator_output if output is None else output\n","\n","        if self.lightning_module:\n","            # restore current_fx when nested context\n","            self.lightning_module._current_fx_name = prev_fx_name\n","\n","        return output\n","\n","    def _parse_devices(\n","        self,\n","        gpus: Optional[Union[List[int], str, int]],\n","        auto_select_gpus: bool,\n","        tpu_cores: Optional[Union[List[int], str, int]],\n","    ) -\u003e Tuple[Optional[List[int]], Optional[Union[List[int], int]]]:\n","        if auto_select_gpus and isinstance(gpus, int):\n","            gpus = pick_multiple_gpus(gpus)\n","\n","        # TODO (@seannaren, @kaushikb11): Include IPU parsing logic here\n","        gpu_ids = device_parser.parse_gpu_ids(gpus)\n","        tpu_cores = device_parser.parse_tpu_cores(tpu_cores)\n","        return gpu_ids, tpu_cores\n","\n","    @staticmethod\n","    def _log_api_event(event: str) -\u003e None:\n","        torch._C._log_api_usage_once(\"lightning.trainer.\" + event)\n","\n","    def __init_profiler(self, profiler: Optional[Union[BaseProfiler, str]]) -\u003e None:\n","        if isinstance(profiler, str):\n","            PROFILERS = {\n","                \"simple\": SimpleProfiler,\n","                \"advanced\": AdvancedProfiler,\n","                \"pytorch\": PyTorchProfiler,\n","                \"xla\": XLAProfiler,\n","            }\n","            profiler = profiler.lower()\n","            if profiler not in PROFILERS:\n","                raise MisconfigurationException(\n","                    \"When passing string value for the `profiler` parameter of `Trainer`,\"\n","                    f\" it can only be one of {list(PROFILERS.keys())}\"\n","                )\n","            profiler_class = PROFILERS[profiler]\n","            profiler = profiler_class()\n","        self.profiler: BaseProfiler = profiler or PassThroughProfiler()\n","\n","    def __setup_profiler(self) -\u003e None:\n","        local_rank = self.local_rank if self.world_size \u003e 1 else None\n","        self.profiler._lightning_module = proxy(self.lightning_module)\n","        self.profiler.setup(stage=self.state.fn._setup_fn, local_rank=local_rank, log_dir=self.log_dir)\n","\n","    def _log_device_info(self) -\u003e None:\n","        rank_zero_info(f\"GPU available: {torch.cuda.is_available()}, used: {self._device_type == DeviceType.GPU}\")\n","\n","        num_tpu_cores = self.tpu_cores if self.tpu_cores is not None and self._device_type == DeviceType.TPU else 0\n","        rank_zero_info(f\"TPU available: {_TPU_AVAILABLE}, using: {num_tpu_cores} TPU cores\")\n","\n","        num_ipus = self.ipus if self.ipus is not None else 0\n","        rank_zero_info(f\"IPU available: {_IPU_AVAILABLE}, using: {num_ipus} IPUs\")\n","\n","        if torch.cuda.is_available() and self._device_type != DeviceType.GPU:\n","            rank_zero_warn(\n","                \"GPU available but not used. Set the gpus flag in your trainer\"\n","                \" `Trainer(gpus=1)` or script `--gpus=1`.\"\n","            )\n","\n","        if _TPU_AVAILABLE and self._device_type != DeviceType.TPU:\n","            rank_zero_warn(\n","                \"TPU available but not used. Set the `tpu_cores` flag in your trainer\"\n","                \" `Trainer(tpu_cores=8)` or script `--tpu_cores=8`.\"\n","            )\n","\n","        if _IPU_AVAILABLE and self._device_type != DeviceType.IPU and not isinstance(self.accelerator, IPUAccelerator):\n","            rank_zero_warn(\n","                \"IPU available but not used. Set the `ipus` flag in your trainer\"\n","                \" `Trainer(ipus=8)` or script `--ipus=8`.\"\n","            )\n","\n","    def _on_expection(self):\n","        if not self.is_global_zero or not _fault_tolerant_enabled():\n","            return\n","        # save a checkpoint for fault tolerant training. we don't use `log_dir` to minimize the chances of failure.\n","        file_path = os.path.join(self.default_root_dir, \".pl_auto_save.ckpt\")\n","        self.save_checkpoint(file_path)\n"]},{"cell_type":"markdown","metadata":{"id":"dy4kGKYQg__z"},"source":["# Build Forecast System"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1016,"status":"ok","timestamp":1659489403364,"user":{"displayName":"Khoa Tran Nguyen Anh","userId":"10391428868079651273"},"user_tz":-420},"id":"rdtRPRjO1lJ8","outputId":"7a9f34fb-1875-406f-c52b-b54902b1c8b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","\n","# import necesary libraries and modules\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import leafmap.foliumap as leafmap\n","from time import sleep\n","from bigdl.orca import init_orca_context, stop_orca_context\n","from bigdl.orca import OrcaContext\n","from bigdl.chronos.data import TSDataset\n","from bigdl.chronos.forecaster.lstm_forecaster import LSTMForecaster\n","from bigdl.orca.automl.metrics import Evaluator\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from PIL import Image\n","\n","\n","st.set_page_config(\n","     page_title=\"Demo Khóa luận tốt nghiệp\",\n","     page_icon=\"✅\",\n","     layout=\"wide\",\n","     initial_sidebar_state=\"expanded\"\n"," )\n","\n","title = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 38px; text-align:center;\"\u003eDEMO HỆ THỐNG DỰ BÁO LUỒNG GIAO THÔNG VỚI MÔ HÌNH CHUỖI THỜI GIAN ĐA BIẾN SỬ DỤNG BIGDL\u003c/p\u003e'\n","st.markdown(title, unsafe_allow_html=True)\n","\n","# Nội dung lề trái\n","with st.sidebar:\n","  col1, col2, col3 = st.columns([2, 4, 2])\n","\n","  with col1:\n","      st.write('')\n","\n","  with col2:\n","    image_path='/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Notebook/Notebook Demo/Logo_UIT_Web_Transparent.png'\n","    image = Image.open(image_path)\n","    st.image(image, width=145, output_format=\"PNG\")\n","\n","  with col3:\n","      st.write('')\n","\n","  # Thêm tên bên lề trái\n","  st.text(\"\")\n","  st.text(\"\")\n","  st.text(\"\")\n","  original_title1 = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 17px; text-align:center; background-color:#90ee90;\"\u003eSinh viên thực hiện\u003c/p\u003e'\n","  st.markdown(original_title1, unsafe_allow_html=True)\n","\n","  # Sinh viên thực hiện\n","  original_name1 = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\"\u003eTrịnh Ngọc Pháp - 18521227\u003c/p\u003e'\n","  st.markdown(\"- \" + original_name1, unsafe_allow_html=True)\n","  # original_mail1 = '\u003cp style=\"font-family:Nunito; font-weight:normal; color:Blue; font-size: 15px; text-align:left;\"\u003e18521227@gm.uit.edu.vn\u003c/p\u003e'\n","  # st.markdown(original_mail1, unsafe_allow_html=True)\n","\n","  original_name2 = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\"\u003eTrần Nguyễn Anh Khoa - 18520938\u003c/p\u003e'\n","  st.markdown(\"- \" + original_name2, unsafe_allow_html=True)\n","\n","  # Giảng viên hướng dẫn  \n","  st.text(\"\")\n","  original_title2 = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 17px; text-align:center; background-color:#f4a460;\"\u003eGiảng viên hướng dẫn\u003c/p\u003e'\n","  st.markdown(original_title2, unsafe_allow_html=True)\n","\n","  original_name3 = '\u003cp style=\"font-family:Nunito; font-weight:Bold; color:Black; font-size: 16px; text-align:left;\"\u003eTS. Đỗ Trọng Hợp\u003c/p\u003e'\n","  st.markdown(\"- \" + original_name3, unsafe_allow_html=True)\n","\n","#submit = st.button('Load model')\n","col1, col2, col3 , col4, col5 = st.columns(5)\n","\n","with col1:\n","    pass\n","with col2:\n","    pass\n","with col4:\n","    pass\n","with col5:\n","    pass\n","with col3 :\n","    submit = st.button('Load model')\n","if submit:\n","  placeholder = st.empty()\n","  with placeholder.container():\n","    st.info('Loading...')\n","  df = pd.read_csv(\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Dataset/final_data_6.csv\")\n","\n","  # recommended to set it to True when running bigdl-chronos in Jupyter notebook \n","  OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n","  init_orca_context(cluster_mode=\"local\", cores=4, init_ray_on_spark=True)\n","\n","  # create list feature\n","  location_ft = ['lat', 'long']\n","  link_ft = ['20223', 'GL1', '1255', '1405', '1404', '1403', 'GL2', '1271','1253', '1401', 'GL3', '1283', '1258', '1256']\n","  weather_ft = ['rhum', 'sun', 'vis']\n","\n","  # components to make a evaluate table\n","  def s_mape(a, f):\n","    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f)))\n","\n","\n","  tsdata_train, _, tsdata_test = TSDataset.from_pandas(df, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft , with_split=True, val_ratio=0.1, test_ratio=0.1)\n","\n","  minmax_scaler = MinMaxScaler()\n","\n","  for tsdata in [tsdata_train, tsdata_test]:\n","      tsdata.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","\n","  X_train, y_train = tsdata_train.to_numpy()\n","  X_test, y_test = tsdata_test.to_numpy()\n","  #X_train.shape, y_train.shape, X_test.shape, y_test.shape\n","\n","  feature_dim = X_train.shape[-1]\n","  target_dim = 1\n","  learning_rate = 0.01\n","  batch_size = 128\n","  epochs = 3\n","\n","  # build model\n","  forecaster = LSTMForecaster(past_seq_len=X_train.shape[1],\n","                              input_feature_num=feature_dim,\n","                              output_feature_num=target_dim,\n","                              hidden_dim=32,\n","                              lr=learning_rate, layer_num=2, dropout=0.2,\n","                              seed=17)\n","\n","  forecaster.load(checkpoint_file=\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Notebook/Notebook Model/Saved_Pipelines/multivariate_forecaster_lstm.ckpt\", quantize_checkpoint_file=None)\n","  placeholder.empty()\n","  st.success('Success loading!')\n","  y_pred = forecaster.predict(X_test)\n","  y_pred_unscale = tsdata_test.unscale_numpy(y_pred)\n","  y_test_unscale = tsdata_test.unscale_numpy(y_test)\n","\n","  rmse =  Evaluator.evaluate(\"rmse\", y_test_unscale, y_pred_unscale, multioutput='raw_values')[0][0]\n","  smape = s_mape(y_test_unscale.reshape(-1), y_pred_unscale.reshape(-1))\n","  print(\"Current - rmse: \" + str(rmse) + \"\\tsmape: \" + str(smape))\n","\n","  df_demo = pd.read_csv(\"/content/drive/MyDrive/Courses/Khoá luận tốt nghiệp/Dataset/final_data_demo_17_6_21_6.csv\")\n","\n","  colors = ['blue', 'lime', 'red']\n","  vmin = df_demo.value.min()\n","  vmax = df_demo.value.max()\n","\n","  list_id = ['000000001253A',\n","  '000000001253B',\n","  '000000001255A',\n","  '000000001255B',\n","  '000000001256A',\n","  '000000001256B',\n","  '000000001258A',\n","  '000000001258B',\n","  '000000001271A',\n","  '000000001271B',\n","  '000000001283A',\n","  '000000001283B',\n","  '000000001401A',\n","  '000000001401B',\n","  '000000001403A',\n","  '000000001403B',\n","  '000000001404A',\n","  '000000001404B',\n","  '000000001405A',\n","  '000000001405B',\n","  '000000020223A',\n","  '000000020223B']\n","\n","  with st.empty():\n","    for i in range(60):\n","      df_demo_batch = pd.DataFrame()\n","      df_input = pd.DataFrame()\n","      for id in list_id:\n","        df_filter = df_demo[df_demo['id'] == id].iloc[i:51+i,:]\n","        df_demo_batch = pd.concat([df_demo_batch, df_filter], ignore_index=True)\n","\n","        df_filter_2 = df_demo[df_demo['id'] == id].iloc[i:50+i,:]\n","        df_input = pd.concat([df_input, df_filter_2], ignore_index=True)\n","\n","      current_time = df_demo_batch.iloc[-2,:].datetime\n","      forecast_time = df_demo_batch.iloc[-1,:].datetime\n","\n","      tsdata_demo = TSDataset.from_pandas(df_demo_batch, dt_col=\"datetime\", id_col=\"id\", target_col=\"value\", extra_feature_col=location_ft+link_ft+weather_ft, with_split=False)\n","      tsdata_demo.scale(minmax_scaler, fit=(tsdata is tsdata_train)).roll(lookback=50, horizon=1)\n","      X_demo, y_demo = tsdata_demo.to_numpy()\n","      y_pred_demo = forecaster.predict(X_demo)\n","\n","      y_pred_demo_unscale = tsdata_demo.unscale_numpy(y_pred_demo)\n","      print(y_pred_demo_unscale.reshape(-1))\n","      # y_demo_unscale = tsdata_demo.unscale_numpy(y_demo)\n","      \n","      df_visualize = tsdata_demo.unscale().to_pandas()\n","\n","      result = pd.DataFrame()\n","      for id in list_id:\n","        df_filter = df_visualize[df_visualize['id'] == id].iloc[50:,:]\n","        result = pd.concat([result, df_filter])\n","\n","      result['pred'] = y_pred_demo_unscale.reshape(-1)\n","\n","      m = leafmap.Map(center=[51.872913, -8.477261], zoom=12.3, tiles='stamentoner')\n","      m.add_heatmap(\n","          result,\n","          latitude=\"lat\",\n","          longitude='long',\n","          value=\"pred\",\n","          name=\"Heat map\",\n","          radius=30,\n","      )\n","\n","      m.add_colorbar(colors=colors, vmin=vmin, vmax=vmax)\n","      m.add_title(f\"Current time:   {current_time}\", font_size=\"16px\", align=\"left\")\n","      m.add_title(f\"Forecast time: {forecast_time}\", font_size=\"16px\", align=\"left\")\n","\n","      with st.container():\n","        st.subheader(\"Heatmap\")\n","        m.to_streamlit()\n","\n","        st.subheader(\"Input\")\n","        st.dataframe(df_input)\n","\n","        st.subheader(\"Output\")\n","        st.dataframe(result[['id', 'datetime', 'pred']])\n","\n","      sleep(10)"]},{"cell_type":"markdown","metadata":{"id":"xcGWyklwgOc9"},"source":["# Run App"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"R1JZD7DPXF29"},"outputs":[{"name":"stdout","output_type":"stream","text":["NgrokTunnel: \"http://fe39-34-87-134-232.ngrok.io\" -\u003e \"http://localhost:80\"\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.87.134.232:80\u001b[0m\n","\u001b[0m\n","2022-08-03 02:53:36.650 Prepending /usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\n","Initializing orca context\n","Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n","Start to getOrCreate SparkContext\n","pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.0.0-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.0.0-jar-with-dependencies.jar pyspark-shell \n","2022-08-03 02:53:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","2022-08-03 02:53:58 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.11-2.4.6.jar) to method java.nio.Bits.unaligned()\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n","2022-08-03 02:54:00,008 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-08-03 02:54:00,011 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-08-03 02:54:00,012 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","2022-08-03 02:54:00,014 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n","22-08-03 02:54:00 [Thread-3] INFO  Engine$:121 - Auto detect executor number and executor cores number\n","22-08-03 02:54:00 [Thread-3] INFO  Engine$:123 - Executor number is 1 and executor cores number is 4\n","\n","User settings:\n","\n","   KMP_AFFINITY=granularity=fine,compact,1,0\n","   KMP_BLOCKTIME=0\n","   KMP_DUPLICATE_LIB_OK=True\n","   KMP_INIT_AT_FORK=FALSE\n","   KMP_SETTINGS=1\n","   OMP_NUM_THREADS=1\n","\n","Effective settings:\n","\n","   KMP_ABORT_DELAY=0\n","   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n","   KMP_ALIGN_ALLOC=64\n","   KMP_ALL_THREADPRIVATE=128\n","   KMP_ATOMIC_MODE=2\n","   KMP_BLOCKTIME=0\n","   KMP_CPUINFO_FILE: value is not defined\n","   KMP_DETERMINISTIC_REDUCTION=false\n","   KMP_DEVICE_THREAD_LIMIT=2147483647\n","   KMP_DISP_HAND_THREAD=false\n","   KMP_DISP_NUM_BUFFERS=7\n","   KMP_DUPLICATE_LIB_OK=true\n","   KMP_FORCE_REDUCTION: value is not defined\n","   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n","   KMP_FORKJOIN_BARRIER='2,2'\n","   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n","   KMP_FORKJOIN_FRAMES=true\n","   KMP_FORKJOIN_FRAMES_MODE=3\n","   KMP_GTID_MODE=3\n","   KMP_HANDLE_SIGNALS=false\n","   KMP_HOT_TEAMS_MAX_LEVEL=1\n","   KMP_HOT_TEAMS_MODE=0\n","   KMP_INIT_AT_FORK=true\n","   KMP_ITT_PREPARE_DELAY=0\n","   KMP_LIBRARY=throughput\n","   KMP_LOCK_KIND=queuing\n","   KMP_MALLOC_POOL_INCR=1M\n","   KMP_MWAIT_HINTS=0\n","   KMP_NUM_LOCKS_IN_BLOCK=1\n","   KMP_PLAIN_BARRIER='2,2'\n","   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n","   KMP_REDUCTION_BARRIER='1,1'\n","   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n","   KMP_SCHEDULE='static,balanced;guided,iterative'\n","   KMP_SETTINGS=true\n","   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n","   KMP_STACKOFFSET=64\n","   KMP_STACKPAD=0\n","   KMP_STACKSIZE=8M\n","   KMP_STORAGE_MAP=false\n","   KMP_TASKING=2\n","   KMP_TASKLOOP_MIN_TASKS=0\n","   KMP_TASK_STEALING_CONSTRAINT=1\n","   KMP_TEAMS_THREAD_LIMIT=2\n","   KMP_TOPOLOGY_METHOD=all\n","   KMP_USER_LEVEL_MWAIT=false\n","   KMP_USE_YIELD=1\n","   KMP_VERSION=false\n","   KMP_WARNINGS=true\n","   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n","   OMP_ALLOCATOR=omp_default_mem_alloc\n","   OMP_CANCELLATION=false\n","   OMP_DEBUG=disabled\n","   OMP_DEFAULT_DEVICE=0\n","   OMP_DISPLAY_AFFINITY=false\n","   OMP_DISPLAY_ENV=false\n","   OMP_DYNAMIC=false\n","   OMP_MAX_ACTIVE_LEVELS=2147483647\n","   OMP_MAX_TASK_PRIORITY=0\n","   OMP_NESTED=false\n","   OMP_NUM_THREADS='1'\n","   OMP_PLACES: value is not defined\n","   OMP_PROC_BIND='intel'\n","   OMP_SCHEDULE='static'\n","   OMP_STACKSIZE=8M\n","   OMP_TARGET_OFFLOAD=DEFAULT\n","   OMP_THREAD_LIMIT=2147483647\n","   OMP_TOOL=enabled\n","   OMP_TOOL_LIBRARIES: value is not defined\n","   OMP_WAIT_POLICY=PASSIVE\n","   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n","\n","22-08-03 02:54:00 [Thread-3] INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 16\n","2022-08-03 02:54:00 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.\n","22-08-03 02:54:00 [Thread-3] INFO  Engine$:446 - Find existing spark context. Checking the spark conf...\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.Sample\n","BigDLBasePickler registering: bigdl.dllib.utils.common  Sample\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.EvaluatedResult\n","BigDLBasePickler registering: bigdl.dllib.utils.common  EvaluatedResult\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JTensor\n","BigDLBasePickler registering: bigdl.dllib.utils.common  JTensor\n","cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JActivity\n","BigDLBasePickler registering: bigdl.dllib.utils.common  JActivity\n","Successfully got a SparkContext\n","2022-08-03 02:54:01.000 Failed to set SIGTERM handler, processes mightnot be cleaned up properly on exit.\n","2022-08-03 02:54:03,778\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n","{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-08-03_02-54-01_038934_2105/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-03_02-54-01_038934_2105/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-08-03_02-54-01_038934_2105', 'metrics_export_port': 42559, 'node_id': '1d165ec8824c79fdb311dce42de3a8b4377109ec9eb26333b205afaf'}\n","2022-08-03 02:54:10.369 Global seed set to 17\n","Current - rmse: 121.68792863825587\tsmape: 0.21307325835257448\n","[225.41191101 205.02703857  99.65496063  56.92583847 147.240448\n"," 123.22531891 160.87075806 149.25160217  43.92776108  13.27688313\n","  94.44584656  81.64414978 138.67526245 176.75830078 140.36550903\n"," 193.04351807 183.79420471 111.37934113  71.6651535  113.63848877\n","  53.57184601  35.89027786]\n","[140.9793396  129.28567505  58.71998978  30.84440804  44.72618484\n","  85.66932678 134.87071228  76.38288879  41.22337341  19.11067772\n","  73.89661407  47.57675552  62.22636414 106.88049316  85.33971405\n"," 124.65931702  98.73029327  62.69411469  55.63476944  58.43251801\n","  64.42237091  40.2940979 ]\n","[126.2676239  173.60015869  17.71733284  72.09815979 135.34991455\n","  59.46630096 114.59092712 155.69155884  71.78421021 123.79088593\n","  74.00282288  36.0815773  137.08821106 110.47071838 181.94720459\n","  66.01079559  54.46644592 149.86352539  99.45549011  11.41968727\n","  50.95471573  32.18053055]\n","[145.73377991 172.16677856 105.44076538 216.80809021 373.80703735\n"," 144.18699646 186.56192017 340.34143066 134.24980164 197.27799988\n"," 108.72638702  95.77692413 151.42909241 153.90461731 273.43734741\n"," 193.826828   197.18516541 214.55436707 185.03851318 156.4190979\n","  84.83383942  65.90975952]\n","[187.67503357 333.60238647  80.90969849 182.75428772 234.31312561\n"," 243.70463562 237.25706482 275.36584473 146.64778137 168.06315613\n"," 174.4163208   50.99004745 284.45013428 154.53912354 238.67127991\n"," 163.44810486 118.55947876 183.8870697  140.40435791  73.88896942\n"," 106.10575867  78.13666534]\n","[508.759552   636.4029541  224.936203   284.86547852 563.86004639\n"," 506.35385132 515.38543701 620.28216553 171.89425659 172.41040039\n"," 451.99951172 283.78167725 544.03674316 461.80206299 588.29449463\n"," 502.57626343 351.78326416 412.45458984 315.67221069 276.36373901\n"," 136.26516724 137.03309631]\n","[654.16619873 868.18676758 294.3152771  481.18023682 633.34851074\n"," 649.1472168  647.73400879 667.43939209 173.58502197 180.76428223\n"," 588.25738525 148.82937622 683.93682861 498.57833862 747.23046875\n"," 838.75915527 548.26342773 525.15551758 427.85577393 431.48648071\n"," 212.1368866  180.98599243]\n","2022-08-03 02:55:14,983\tWARNING worker.py:1245 -- (ip=172.28.0.2) The agent on node 266854ea249f failed to be restarted 5 times. There are 3 possible problems if you see this error.\n","  1. The dashboard might not display correct information on this node.\n","  2. Metrics on this node won't be reported.\n","  3. runtime_env APIs won't work.\n","Check out the `dashboard_agent.log` to see the detailed failure messages.\n","[ 900.38562012 1085.3425293   443.09042358  719.24865723  914.69976807\n","  953.06652832  874.88879395  949.05578613  260.49560547  279.12832642\n","  635.13720703  345.11264038  871.31671143  686.59020996 1043.36340332\n"," 1107.45202637  965.44140625  845.47442627  652.69226074  764.73883057\n","  269.08416748  213.77003479]\n","[1478.93933105 1705.12780762  641.56811523 1086.59411621 1367.29077148\n"," 1338.74694824 1350.00537109 1432.8326416   325.44137573  394.39382935\n"," 1145.21704102  617.59509277 1462.7487793  1106.34277344 1529.72363281\n"," 1567.99304199 1486.86975098 1295.90698242  971.2444458  1040.67297363\n","  345.23959351  245.94142151]\n","[2031.06774902 2230.13745117 1011.31567383 1768.04272461 1836.55773926\n"," 1840.05102539 1969.95349121 1800.27697754  406.23379517  393.43121338\n"," 1576.35705566  836.56304932 1951.04602051 1582.94775391 2072.42382812\n"," 2257.5534668  2062.09545898 1819.18115234 1363.23095703 1505.02087402\n","  582.0057373   358.8755188 ]\n","[2570.63061523 2753.40454102 1450.60559082 2003.15026855 2255.90649414\n"," 2120.33056641 2403.23388672 2216.50854492  587.31420898  493.40655518\n"," 1618.25488281 1042.31970215 2401.81445312 2004.36816406 2414.7253418\n"," 2684.32836914 2377.32080078 2085.16674805 1617.56091309 1625.78942871\n","  601.46331787  415.85940552]\n","[2907.52661133 3007.95068359 1509.98144531 1733.1784668  2491.52709961\n"," 2349.33764648 2564.09423828 2558.12353516  565.17315674  505.54638672\n"," 1704.06555176 1417.70068359 2694.1315918  2344.94067383 2763.21826172\n"," 2943.8203125  2658.02392578 2382.82495117 1893.24255371 1686.54699707\n","  675.83752441  538.75415039]\n","[3035.67382812 2992.91259766 1724.7869873  1904.14257812 2493.67724609\n"," 2484.77978516 2659.06005859 2624.7265625   593.5881958   628.3739624\n"," 1727.23425293 1506.92919922 2673.58886719 2407.36987305 2927.59082031\n"," 2913.77807617 2563.57910156 2496.34130859 2008.75280762 1866.63659668\n","  712.82141113  558.08190918]\n","[3029.72753906 2814.88647461 1569.56359863 1822.47058105 2331.65576172\n"," 2402.48046875 2598.39453125 2523.60644531  636.61065674  613.07159424\n"," 1556.18164062 1574.0826416  2484.97705078 2438.0390625  2842.40893555\n"," 2665.45336914 2339.39477539 2414.93554688 1975.9197998  1724.64367676\n","  615.25        588.72137451]\n","[2968.49194336 2609.54882812 1302.79504395 1781.25891113 2179.74780273\n"," 2258.31005859 2411.58007812 2352.046875    560.34796143  518.16766357\n"," 1399.85913086 1488.05725098 2262.38061523 2283.47583008 2805.84912109\n"," 2476.07910156 2102.49243164 2408.92138672 1948.55822754 1640.44970703\n","  566.38909912  511.02615356]\n","[3010.83911133 2457.03125    1325.35217285 1680.33850098 2016.06945801\n"," 2223.82543945 2364.47119141 2239.72583008  591.54779053  500.57052612\n"," 1245.29321289 1530.05480957 2060.43847656 2328.22924805 2848.44458008\n"," 2197.31982422 1887.95080566 2561.34008789 2145.81933594 1561.64855957\n","  565.17541504  537.83496094]\n","[2670.19213867 2350.57324219 1283.89233398 1534.7980957  1835.75708008\n"," 1936.38220215 2028.71118164 2108.67138672  525.59857178  386.66998291\n"," 1165.04528809 1494.03442383 2081.09130859 2018.38415527 2667.0612793\n"," 2139.0300293  1899.26794434 2424.5390625  2074.515625   1534.01672363\n","  526.65472412  539.11499023]\n","[2215.59570312 1997.82312012 1023.97576904 1238.55529785 1507.13879395\n"," 1609.79174805 1667.91625977 1698.2434082   445.16174316  377.08853149\n"," 1017.36999512 1272.21130371 1683.92163086 1702.48291016 2274.10473633\n"," 1656.0065918  1429.80566406 2016.69897461 1615.20800781 1100.65222168\n","  448.06445312  490.88565063]\n","[1536.54956055 1492.87390137  727.6942749   804.06402588 1048.76745605\n"," 1044.32312012 1190.29516602 1184.9855957   402.48397827  302.90985107\n","  778.19573975  871.98834229 1190.33642578 1173.75183105 1546.39257812\n"," 1299.59326172 1047.94543457 1298.96862793  991.08612061  825.71551514\n","  350.92330933  347.85110474]\n","[1045.77001953 1013.61358643  511.72027588  571.44403076  732.17224121\n","  655.21380615  793.76470947  769.96728516  278.25662231  227.96928406\n","  511.46499634  626.27154541  772.3807373   794.25079346 1089.69580078\n","  885.44403076  735.953125    896.52008057  663.84387207  579.08752441\n","  259.35412598  244.04716492]\n","[678.67706299 678.04992676 383.48614502 369.39358521 458.9960022\n"," 397.34091187 472.66540527 496.50186157 234.68507385 149.26646423\n"," 298.77661133 381.98144531 510.45089722 491.61834717 662.89990234\n"," 601.1595459  507.06430054 571.42053223 431.39682007 404.86468506\n"," 175.13449097 145.52436829]\n","[857.53045654 739.57922363 336.51934814 281.12753296 399.537323\n"," 502.91604614 642.32989502 443.04180908 176.50764465 140.65440369\n"," 354.35266113 318.64129639 595.29937744 642.04571533 494.78985596\n"," 558.03393555 499.56399536 404.675354   322.07220459 355.41159058\n"," 158.31410217 141.22920227]\n","[650.09613037 322.77084351 273.48403931 159.46101379 175.77972412\n"," 402.56103516 488.83148193 209.19708252 141.58328247 116.16656494\n"," 177.52848816 235.63897705 196.26657104 473.89746094 275.60379028\n"," 417.14227295 362.65557861 228.28895569 194.86108398 269.4480896\n"," 107.75772095  98.90412903]\n","[236.63609314 182.38937378 109.93286133  90.95719147 118.92956543\n"," 100.08159637 136.14492798 132.70379639 154.63864136  68.35466003\n","  66.59119415  68.01080322 126.84836578 142.72660828 171.13293457\n"," 159.17947388 147.79533386 149.75886536 119.02153015 110.28037262\n","  57.63053131  37.95320129]\n","[168.01538086 134.84394836  75.15641022  52.47244644  78.38407135\n","  98.25053406 125.50310516  89.24047852  71.9371109   26.77683449\n","  61.46159744  28.24059486  89.07655334 116.15065002 100.3102951\n"," 128.95252991 118.67636871 100.64044189  77.78137207  76.79815674\n","  44.06499863  26.93648911]\n","[120.66234589 108.94644928  35.84872437  31.07819176  86.38854218\n","  81.03609467 128.32640076  88.91776276  23.36880684  -2.38861036\n","  45.93628311  13.16361427  69.47003937  98.12754059  91.73699951\n","  83.27848816  64.79190826  83.9592514   56.0160675   33.40722656\n","  46.26026535  17.31460571]\n","[106.66290283 132.40103149  16.46642303  48.69749069 153.40164185\n"," 138.08836365 157.95742798 144.35585022  34.60506058  59.30361176\n","  71.75826263  -1.53578293 111.84879303 110.55698395 117.17250824\n","  90.46921539  84.39838409 106.55393982  66.96054077  17.10677147\n","  36.83327484  16.24329376]\n","[267.56011963 603.85638428 166.66033936 411.52075195 688.01574707\n"," 358.60897827 356.49105835 597.27606201 170.48233032 277.38034058\n"," 288.42724609  84.78132629 565.31854248 256.74819946 379.20095825\n"," 414.390625   339.55078125 344.16424561 334.98358154 230.07836914\n"," 107.87999725  89.07810211]\n","[1051.90307617 1281.80639648  297.85595703  933.14477539 1432.76037598\n"," 1013.46740723  881.53216553 1395.45581055  236.4850769   278.06240845\n","  651.16467285  830.61981201 1174.98095703  916.75061035 1241.02038574\n"," 1187.67687988  880.23321533 1158.11279297  821.60015869  427.08413696\n","  211.17749023  165.11369324]\n","[2465.1652832  2482.36572266  818.30322266 1813.14013672 2456.14624023\n"," 2100.49169922 2089.93896484 2561.9284668   300.67718506  299.52658081\n"," 1965.13647461 1730.43237305 2227.02709961 2143.06738281 2845.41674805\n"," 2255.12402344 1472.29382324 2479.97705078 2066.76171875  894.40911865\n","  491.51287842  368.7305603 ]\n","[2538.84301758 3085.45214844 1299.93444824 2061.62915039 2155.29614258\n"," 2014.1829834  2408.81811523 2048.09130859  551.26098633  487.54241943\n"," 2119.44775391 1393.46691895 2668.9753418  1977.7791748  3229.91918945\n"," 2572.42211914 2138.70800781 2873.87988281 2402.74291992 1533.92272949\n","  767.48443604  877.27801514]\n","[2306.21557617 2627.31567383 1063.52502441 1646.17932129 2101.57617188\n"," 1736.14453125 1916.23669434 2108.60986328  621.42150879  630.15228271\n"," 1610.54321289 1102.78198242 2308.15991211 1759.73461914 2547.18994141\n"," 2276.10717773 1799.14953613 2267.39086914 1788.79309082 1345.67492676\n","  509.69488525  607.20581055]\n","[2300.25073242 2436.75854492 1066.4342041  1460.5        1996.48278809\n"," 1754.76025391 1909.96789551 2063.52050781  540.42529297  565.34857178\n"," 1427.22692871 1065.72888184 2117.85205078 1787.98059082 2458.00610352\n"," 2242.24072266 1748.27807617 2136.18334961 1629.16064453 1247.92297363\n","  520.94244385  515.52459717]\n","[2505.61279297 2412.94873047 1175.29382324 1410.50305176 2020.5090332\n"," 1953.75256348 2077.83447266 2146.1640625   548.42584229  521.91369629\n"," 1410.61694336 1235.00024414 2100.58227539 2018.11962891 2510.73071289\n"," 2258.00537109 1842.11669922 2020.45397949 1523.47631836 1324.63598633\n","  526.14025879  495.28640747]\n","[2751.69287109 2498.50878906 1242.64978027 1425.85925293 1940.90197754\n"," 2179.30078125 2342.625      2065.90942383  569.37091064  543.77172852\n"," 1510.52697754 1278.046875   2147.52709961 2170.28686523 2607.42089844\n"," 2411.94995117 2009.55944824 2074.31420898 1566.17602539 1409.14929199\n","  589.75592041  526.12268066]\n","[2882.98364258 2589.57666016 1340.64318848 1462.86291504 2036.34326172\n"," 2214.86645508 2374.45947266 2247.63964844  535.99346924  568.4642334\n"," 1524.1817627  1402.43811035 2223.53344727 2214.57373047 2719.74145508\n"," 2454.23828125 2102.28686523 2172.82446289 1604.09191895 1534.60522461\n","  562.25823975  526.73937988]\n","[2852.28125    2790.90454102 1456.16955566 1438.73535156 2117.57470703\n"," 2259.29541016 2386.25       2386.32958984  624.67889404  630.72827148\n"," 1633.69641113 1462.6060791  2337.60791016 2233.31054688 2699.95678711\n"," 2783.2644043  2315.53979492 2158.4152832  1568.23156738 1647.65979004\n","  577.92633057  573.97283936]\n","[3105.40893555 2928.27001953 1713.52319336 1451.91638184 2245.72265625\n"," 2422.81445312 2569.10668945 2461.04516602  563.05804443  629.81488037\n"," 1806.64575195 1574.45568848 2508.03759766 2448.18774414 2950.21777344\n"," 2974.41894531 2565.3828125  2279.16137695 1581.82324219 1958.07580566\n","  654.65856934  587.56677246]\n","[3171.71020508 3155.68798828 2060.28076172 1457.40039062 2541.76171875\n"," 2595.00683594 2763.82861328 2677.30712891  575.92315674  644.31628418\n"," 1977.73254395 1768.18334961 2893.27050781 2549.91357422 3058.62597656\n"," 3153.51733398 2981.046875   2300.75585938 1558.87304688 2288.93286133\n","  701.44836426  680.30273438]\n","[3279.74804688 3255.63891602 2281.54003906 1327.80419922 2556.9831543\n"," 2456.75       2766.66601562 2629.71557617  560.10040283  538.8795166\n"," 1869.43164062 2102.04101562 2964.86645508 2577.02099609 3098.40258789\n"," 3823.79370117 3369.36791992 2191.06884766 1445.07983398 2654.1784668\n","  737.01593018  782.33917236]\n","[2574.66992188 2346.97192383 1480.80407715 1266.92382812 1869.22265625\n"," 1930.81848145 1895.39904785 2088.49072266  501.78359985  510.38330078\n"," 1393.18969727 1799.26049805 2022.16589355 1921.89587402 2450.16503906\n"," 2621.33227539 2325.53759766 1945.47717285 1402.13293457 1738.85253906\n","  604.9552002   574.08135986]\n","[2083.24365234 1913.28637695 1028.83056641  996.42285156 1337.23596191\n"," 1426.53442383 1514.65490723 1549.60351562  401.74777222  434.84585571\n"," 1168.22949219 1101.70812988 1560.93798828 1489.75817871 1929.24023438\n"," 1853.75695801 1581.54943848 1463.96008301 1086.33178711 1165.39501953\n","  426.86004639  381.63250732]\n","[1672.77001953 1517.44592285  735.41113281  778.56628418  942.15258789\n"," 1059.37963867 1210.22338867 1070.08776855  350.64178467  311.05316162\n","  938.41729736  882.04046631 1195.31237793 1174.12609863 1575.12475586\n"," 1463.87023926 1207.20349121 1235.41894531  927.69805908  911.49121094\n","  347.01254272  295.35617065]\n","[1216.93286133  992.48413086  523.16223145  511.50717163  551.17504883\n","  656.4776001   789.29656982  618.10424805  326.1529541   230.84963989\n","  579.84069824  638.79193115  720.22375488  832.36883545 1146.66418457\n","  970.65411377  797.27215576  831.59295654  572.05499268  619.5055542\n","  267.24282837  233.99667358]\n","[717.71295166 743.95220947 382.89706421 332.15563965 383.82775879\n"," 399.30358887 486.71102905 411.42181396 235.63420105 155.17662048\n"," 372.05712891 390.64956665 511.01989746 478.57910156 684.51239014\n"," 732.5534668  601.13635254 533.07525635 341.94500732 443.306427\n"," 191.30491638 176.93086243]\n","[442.22097778 615.45910645 225.37246704 237.18621826 262.2565918\n"," 241.83009338 302.0765686  308.18460083 167.05619812 105.41103363\n"," 272.4649353  216.46961975 456.09234619 302.41281128 447.71337891\n"," 557.88513184 474.09777832 325.92379761 251.0018158  391.11251831\n"," 134.85627747 110.37664795]\n","[420.24472046 253.96258545 137.21318054 118.28002167 124.42705536\n"," 222.53288269 288.12701416 130.66943359 170.94876099  95.86386871\n"," 122.04733276 147.43652344 167.06634521 308.65472412 393.82739258\n"," 225.3470459  218.19387817 351.63198853 335.68826294 157.70825195\n","  79.81500244  92.44782257]\n","[145.63526917 166.92224121  83.58023834  52.06693649  96.34267426\n","  84.26821136 116.45270538  95.39038849  96.16983032  38.48313141\n","  91.09857178  61.73399353 124.58209229 104.39874268 121.45036316\n"," 148.81307983 124.6639328   82.68644714  48.66197205  90.03862\n","  60.17179871  48.44246674]\n","[131.19793701 103.25045013  34.80335617  24.19748306  71.54736328\n"," 110.66672516 130.83905029  74.39712524  41.07499313  12.44597816\n","  31.59666252  47.1736908   73.31407928 116.11791992 134.85568237\n","  95.94168854  73.38384247 116.80031586  45.93773651  41.86945343\n","  52.25420761  36.58976746]\n","[105.32300568 119.19326019  43.84527206  19.91897774 103.50238037\n","  78.79657745 119.77217865  87.00411987  24.14453316  17.20022392\n","  47.60295105  37.4449501   84.67824554  97.0630722  102.35359192\n","  81.91248322  61.38935852  89.61260986  51.6523819   31.80078125\n","  41.11196518  32.80663681]\n","[ 86.26734924 138.74517822  46.55786514  53.06275558 124.23937988\n"," 159.0919342  175.67996216 153.42163086  43.74934387  75.23701477\n"," 106.965271   -12.48096848 120.6137619   95.23751831 101.59975433\n","  99.17726898  81.59618378  55.33140945  37.02884674  47.60561371\n","  41.22972107  29.68484497]\n","[373.81060791 440.95202637 178.63986206 333.78643799 499.14212036\n"," 433.41461182 457.43151855 481.57849121 137.18132019 296.16949463\n"," 242.48091125 166.8631897  381.21221924 378.16125488 405.4072876\n"," 420.08197021 333.31634521 363.92770386 297.72842407 165.72450256\n"," 104.76313019  92.13913727]\n","[1045.15600586 1477.58349609  436.31207275  968.56304932 1697.24829102\n"," 1116.21191406 1000.01965332 1589.11474609  221.13031006  287.33407593\n","  797.34185791 1012.20526123 1433.16882324 1002.3536377  1204.5592041\n"," 1308.1373291  1112.38623047 1145.04907227  766.44366455  538.83984375\n","  212.32330322  158.60743713]\n","[2743.6105957  2652.88085938  911.88592529 1955.33972168 2546.9909668\n"," 2252.140625   2231.79760742 2590.1640625   334.79721069  326.87030029\n"," 2160.18969727 1797.67712402 2344.89819336 2344.38476562 2937.34619141\n"," 2367.26318359 1645.07946777 2429.18969727 2011.91625977 1074.3651123\n","  558.02923584  463.74893188]\n","[2895.35546875 3286.46044922 1216.04541016 2037.93920898 2320.76318359\n"," 2197.07592773 2724.10107422 2139.33520508  658.51318359  598.49694824\n"," 2306.20874023 1548.22644043 2842.07885742 2259.97460938 3365.45776367\n"," 2853.59741211 2223.76464844 2905.88012695 2282.01977539 1584.04736328\n","  777.0848999   877.55718994]\n","[2331.78198242 2703.23999023 1161.95922852 1652.05419922 2076.25024414\n"," 1835.6640625  1997.05773926 2135.65820312  570.98303223  758.69958496\n"," 1657.47509766 1212.33410645 2331.7434082  1817.33093262 2603.99389648\n"," 2363.17773438 1864.66174316 2286.86010742 1700.84899902 1359.57189941\n","  494.03930664  638.16204834]\n","[2254.70117188 2256.15258789 1074.78417969 1413.86523438 1957.10717773\n"," 1762.75964355 1912.82275391 2008.58288574  573.97277832  651.68218994\n"," 1490.72387695 1195.37976074 1850.61877441 1750.74572754 2461.26879883\n"," 2177.47875977 1718.21276855 2052.68774414 1506.17541504 1222.88525391\n","  526.04077148  508.05075073]\n","[2470.13232422 2545.01098633 1298.15490723 1368.35314941 1854.17541504\n"," 1926.52331543 2057.25341797 1979.68493652  565.73925781  601.04742432\n"," 1416.87304688 1148.37194824 2155.54272461 1974.18286133 2462.96679688\n"," 2537.2890625  2051.7722168  1920.21289062 1394.85046387 1462.58093262\n","  500.3258667   500.10327148]\n","[2675.30297852 2465.73144531 1248.31323242 1356.14660645 1884.82714844\n"," 2047.6496582  2204.10913086 2080.99975586  545.74688721  602.9005127\n"," 1436.43933105 1269.02124023 2087.25952148 2083.13476562 2634.60693359\n"," 2399.98681641 2013.25146484 1971.87463379 1373.89562988 1436.4822998\n","  558.84576416  522.65216064]\n","[2841.37963867 2603.44628906 1357.93029785 1448.01574707 1958.31970215\n"," 2116.43994141 2299.58081055 2152.33349609  589.69750977  612.66870117\n"," 1571.39648438 1408.16650391 2190.92358398 2128.83056641 2729.21704102\n"," 2496.13769531 2113.43579102 2113.07519531 1513.1217041  1575.80895996\n","  595.90234375  559.85723877]\n","2022-08-03 03:04:29,060\tERROR worker.py:1247 -- listen_error_messages_raylet: Connection closed by server.\n","2022-08-03 03:04:29,060\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n","2022-08-03 03:04:29,063\tERROR worker.py:478 -- print_logs: Connection closed by server.\n","[2022-08-03 03:14:28,463 E 2105 2402] gcs_server_address_updater.cc:76: Failed to receive the GCS address for 600 times without success. The worker will exit ungracefully. It is because GCS has died. It could be because there was an issue that kills GCS, such as high memory usage triggering OOM killer to kill GCS. Cluster will be highly likely unavailable if you see this log. Please check the log from gcs_server.err.\n"]}],"source":["from pyngrok import ngrok\n","ngrok.set_auth_token(\"2AmJisrnaxPzbUIbd3wBsboq4TJ_5NKxMJqNdMHTSJzN6RWKi\") #phap\n","# ngrok.set_auth_token(\"2B3iiliqK9Am9l2P7Nd2n1cr3iz_zLr4PBzMofF7Z8fiTfXK\")  #khoa\n","public_url = ngrok.connect(port='80')\n","print(public_url)\n","\n","!streamlit run --theme.base \"light\" --server.port 80 app.py"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"khoa_streamlit_demo_KLTN.ipynb","toc_visible":true,"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}